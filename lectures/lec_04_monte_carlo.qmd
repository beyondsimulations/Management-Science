---
title: "Dealing with Uncertainty"
subtitle: "Lecture 4 - Management Science"
author: "Dr. Tobias Vlćek"
format:
  revealjs:
    footer: " {{< meta title >}} | {{< meta author >}} | [Home](lec_04_monte_carlo.qmd)"
    output-file: lec_04_presentation.html
---


# [Introduction]{.flow} {.title}

## **[Client Briefing: TechVenture Innovation Fund]{.invert-font}** {background-image="https://unsplash.com/photos/K5DY18hy5JQ/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzYxNDU4NjYzfA&force=true&w=2400" background-size="cover"}

. . .

[CEO's Dilemma:]{.invert-font}

["We have €2M to invest in [2 of 4 startups]{.highlight}. Each promises great returns, but the future is uncertain. How do we make the best choice without just gambling?"]{.invert-font .fragment}

## Business: Valuing Uncertainty

[Question]{.question}: [Why can't we just pick the two startups with the highest average returns?]{.highlight}

. . .

::: incremental
- **Hidden Risk:** A startup with 30% average return but 50% chance of failure might be worse than 20% return with 5% failure chance
- **Portfolio Effects:** Two risky startups together might amplify risk beyond acceptable levels
- **Tail Events:** The worst-case scenario can matter as much as the average case
:::

. . .

:::{.callout-warning}
**Common Pitfall:** Optimizing on averages ignores the distribution of outcomes.
:::

## Real-World Examples

[Where uncertainty modeling is critical:]{.highlight}

::: columns
::: {.column width="50%"}
**Netflix Series Decisions**

- Will a show hit 10M viewers?
- Range: 500K to 50M
- Investment: €20M per season
:::

::: {.column width="50%"}
**Pharmaceutical R&D**

- Will the drug pass trials?
- Success rate: 10-20%
- Investment: €1B over 10 years
:::
:::

. . .

::: callout-important
When decisions are expensive and outcomes are uncertain, **Monte Carlo simulation** can be helpful to **reduce risk** and **maximize value**!
:::

# [Core Concepts]{.flow} {.title}

## Rolling the Dice 10,000 Times I

[Question]{.question}: If you roll two dice, what's the probability of getting exactly 7 as result?

. . .

**Method 1: Math**

- Count combinations: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1)
- Total combinations: 36
- Probability: 6/36 = 16.67%

## Rolling the Dice 10,000 Times II

[Question]{.question}: If you roll two dice, what's the probability of getting exactly 7 as result?

. . .


**Method 2: Simulation**
```{python}
#| eval: true
#| echo: true
#| output-location: fragment
import numpy as np
np.random.seed(42)

# Roll two dice 10,000 times
dice1 = np.random.randint(1, 7, size=10_000)
dice2 = np.random.randint(1, 7, size=10_000)
total = dice1 + dice2

# What fraction equals 7?
probability = (total == 7).mean()
print(f"Simulated probability of rolling 7: {probability:.1%}")
```

## How Probability Converges

```{python}
#| echo: false
#| eval: true
import sys
sys.path.append('../helpers')
from plot_utils import BRAND_COLORS, setup_clean_style
import matplotlib.pyplot as plt

setup_clean_style()

# Pre-generate all rolls for consistency
np.random.seed(42)
n_rolls = 10_000
all_dice1 = np.random.randint(1, 7, size=n_rolls)
all_dice2 = np.random.randint(1, 7, size=n_rolls)
all_sums = all_dice1 + all_dice2

# Calculate cumulative probability at each point
prob_history = []
for i in range(1, n_rolls + 1):
    current_sums = all_sums[:i]
    prob_seven = (current_sums == 7).mean()
    prob_history.append(prob_seven)

# Create the figure with brand styling
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Left plot - Evolution of probability estimate
ax1.plot(range(1, n_rolls + 1), prob_history, color=BRAND_COLORS["twoDark"],
         linewidth=2.5, label='Observed Probability', alpha=0.8)
ax1.axhline(y=1/6, color=BRAND_COLORS["threeDark"], linestyle='--',
            linewidth=2, label=f'True Probability: {1/6:.3f}', alpha=0.8)
ax1.set_xlabel('Number of Rolls')
ax1.set_ylabel('Estimated Probability of Rolling 7')
ax1.set_title('Evolution of Probability Estimate', fontsize=14, weight='bold')
ax1.set_xscale('log')
ax1.grid(True, alpha=0.15)
ax1.legend(loc='upper right')

# Right plot - Final distribution
dice_sums = np.arange(2, 13)
theoretical_probs = np.array([1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1]) / 36

# Calculate observed distribution from all rolls
counts = np.bincount(all_sums, minlength=13)[2:13]
observed_probs = counts / len(all_sums)

ax2.plot(dice_sums, theoretical_probs, color=BRAND_COLORS["threeDark"],
         linestyle='--', linewidth=2.5, label='Theoretical', marker='o', markersize=8)
ax2.bar(dice_sums, observed_probs, width=0.6, alpha=0.7,
        color=BRAND_COLORS["twoLight"], label='Observed (10,000 rolls)',
        edgecolor=BRAND_COLORS["twoDark"], linewidth=1.5)
ax2.set_xlabel('Sum of Two Dice')
ax2.set_ylabel('Probability')
ax2.set_title('Distribution of Dice Sums', fontsize=14, weight='bold')
ax2.set_xticks(dice_sums)
ax2.grid(True, alpha=0.15)
ax2.legend(loc='upper right')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
As we roll more dice, the estimated probability converges to the true value (16.7%)
:::

## The Law of Large Numbers

[Fundamental Principle:]{.highlight} **As sample size increases, sample average converges to the true expected value**

. . .

If $X_1, X_2, \ldots, X_n$ are independent random samples from the same distribution with mean $\mu$:

$$\text{As } n \to \infty, \quad \bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i \to \mu$$

. . .

:::{.callout-note}
This is WHY simulations works. More simulations = better estimates!
:::

## The Central Limit Theorem

[Another Fundamental Principle:]{.highlight} **The sum of many random variables tends toward a normal distribution**

. . .

**What it means:**

- Even if individual returns are [NOT]{.highlight} normally distributed...
- The portfolio of many assets [WILL]{.highlight} be approximately normal
- The average of many simulations [WILL]{.highlight} be approximately normal

. . .

:::{.callout-tip}
**For Business:** This is why we can use normal distributions to model portfolio returns, even when individual assets have skewed or unusual distributions!
:::

## Why This Matters for Business

[Question]{.question}: How many simulations do we need for reliable results?

. . .

```{python}
#| eval: true
#| echo: true
#| output-location: fragment
# Test convergence with different sample sizes
sample_sizes = [10, 100, 1000, 10000, 100000]
estimates = []

for n in sample_sizes:
    dice1 = np.random.randint(1, 7, size=n)
    dice2 = np.random.randint(1, 7, size=n)
    total = dice1 + dice2
    prob = (total == 7).mean()
    estimates.append(prob)
    print(f"n={n:6d}: Estimated probability = {prob:.4f}")
```

## Practical Guidelines

[How many simulations should you run?]{.highlight}

::: incremental
- **Quick exploration:** 10,000 simulations
  - Good for initial insights, prototyping
- **Critical decisions:** 100,000+ simulations
  - Financial risk models, regulatory compliance
- **When to stop:** When more simulations [don't change]{.highlight} conclusion
:::

. . .

:::{.callout-important}
If your decision changes with 10x more simulations, you didn't run enough!
:::

# [Monte Carlo Method]{.flow} {.title}

## The Monte Carlo Method

[Three Simple Steps:]{.highlight}

::: incremental
1. **Model the Uncertainty:**
   - Define probability distributions for unknown variables
2. **Simulate Many Scenarios:**
   - Generate thousands of possible outcomes
3. **Analyze the Results:**
   - Calculate statistics from the simulation
:::

. . .

:::{.callout-note}
Monte Carlo Casino in Monaco inspired the method's development in the 1940s.
:::

## Step 1: Model the Uncertainty

[Key Function:]{.highlight} `np.random.normal(loc, scale, size)`

- **loc**: The center (mean/average)
- **scale**: The spread (standard deviation)
- **size**: How many samples to generate

. . .

```{python}
#| eval: true
#| echo: true
#| output-location: fragment
# AI-Growth: average 38% return, ±25% volatility
returns = np.random.normal(loc=0.38, scale=0.25, size=10_000)
print(f"Mean return: {returns.mean():.1%}")
print(f"Std deviation: {returns.std():.1%}")
print(f"Minimum: {returns.min():.1%}")
print(f"Maximum: {returns.max():.1%}")
```

## Expected Returns

Let's calculate percentiles with `np.percentile()`.

. . .

[Question:]{.question} Do you still know what a percentile is?

. . .

```{python}
#| eval: true
#| echo: true
#| output-location: fragment
print(f"\nPercentiles:")
print(f"  5th: {np.percentile(returns, 5):.1%} (worst 5% of scenarios)")
print(f" 25th: {np.percentile(returns, 25):.1%} (worst 25% of scenarios)")
print(f" 50th: {np.percentile(returns, 50):.1%} (median)")
print(f" 75th: {np.percentile(returns, 75):.1%} (best 25% of scenarios)")
print(f" 95th: {np.percentile(returns, 95):.1%} (best 5% of scenarios)")
```

## Understanding the Distribution

[Question]{.question}: Before we plot, what shape do you expect for `np.random.normal()`?

. . .

```{python}
#| eval: true
#| echo: false
import matplotlib.pyplot as plt

# Apply brand styling
setup_clean_style()
fig, ax = plt.subplots(figsize=(10, 5))
ax.hist(returns, bins=50, edgecolor='black', alpha=0.7, color=BRAND_COLORS["twoDark"])
ax.axvline(returns.mean(), color=BRAND_COLORS["oneDark"], linestyle='--',
           linewidth=2, label=f'Mean: {returns.mean():.1%}')
ax.axvline(0, color=BRAND_COLORS["threeDark"], linestyle='-',
           linewidth=2, label='Break-even')
ax.set_xlabel('Return Rate', fontsize=12)
ax.set_ylabel('Frequency', fontsize=12)
ax.legend()
ax.grid(True, alpha=0.2)
plt.show()
```

## Risk Analysis

[Question]{.question}: What's the probability that AI-Growth loses money?

. . .

```{python}
#| eval: true
#| echo: true
#| output-location: fragment
# Calculate risk metrics
prob_loss = (returns < 0).mean() # proportion of returns that are less than zero
prob_double = (returns > 1.0).mean()  # proportion greater than 100%

print(f"Probability of loss: {prob_loss:.1%}")
print(f"Probability of doubling money: {prob_double:.1%}")
```

. . .

:::{.callout-important}
With 6 % chance of loss, AI-Growth is relatively safe. Easy for one startup, right?
:::

## Different Distributions

[Attention: Not everything follows a normal distribution!]{.highlight}

```{python}
#| eval: true
#| echo: false
# Import plotting utilities for brand-consistent styling
import sys
sys.path.append('../helpers')
from plot_utils import create_plot, BRAND_COLORS, setup_clean_style

# Generate samples for each distribution
np.random.seed(42)
n_samples = 10000

# Normal distribution
normal_samples = np.random.normal(0.25, 0.15, n_samples)

# Uniform distribution
uniform_samples = np.random.uniform(0.10, 0.35, n_samples)

# Exponential distribution (scaled to similar range)
exponential_samples = np.random.exponential(0.20, n_samples)
exponential_samples = exponential_samples[exponential_samples < 1]  # Clip for visualization

# Create comparison plot
setup_clean_style()
fig, axes = plt.subplots(1, 3)

# Normal Distribution
axes[0].hist(normal_samples, bins=50, alpha=0.7, color=BRAND_COLORS["twoDark"], edgecolor='black', linewidth=0.5)
axes[0].axvline(normal_samples.mean(), color=BRAND_COLORS["threeDark"], linestyle='--', linewidth=2, label=f'Mean: {normal_samples.mean():.1%}')
axes[0].set_title('Normal Distribution', fontweight='bold')
axes[0].set_xlabel('Return Rate')
axes[0].set_ylabel('Frequency')
axes[0].legend()
axes[0].grid(True, alpha=0.2)

# Uniform Distribution
axes[1].hist(uniform_samples, bins=50, alpha=0.7, color=BRAND_COLORS["oneDark"], edgecolor='black', linewidth=0.5)
axes[1].axvline(uniform_samples.mean(), color=BRAND_COLORS["threeDark"], linestyle='--', linewidth=2, label=f'Mean: {uniform_samples.mean():.1%}')
axes[1].set_title('Uniform Distribution', fontweight='bold')
axes[1].set_xlabel('Return Rate')
axes[1].set_ylabel('Frequency')
axes[1].legend()
axes[1].grid(True, alpha=0.2)

# Exponential Distribution
axes[2].hist(exponential_samples, bins=50, alpha=0.7, color=BRAND_COLORS["twoLight"], edgecolor='black', linewidth=0.5)
axes[2].axvline(exponential_samples.mean(), color=BRAND_COLORS["threeDark"], linestyle='--', linewidth=2, label=f'Mean: {exponential_samples.mean():.1%}')
axes[2].set_title('Exponential Distribution', fontweight='bold')
axes[2].set_xlabel('Time/Return')
axes[2].set_ylabel('Frequency')
axes[2].legend()
axes[2].grid(True, alpha=0.2)

plt.tight_layout()
plt.show()
```

## Overview

::: {.panel-tabset}

## Normal

```{python}
#| eval: false
#| echo: true
# Most common in nature/business
# Bell-shaped, symmetric
returns = np.random.normal(mean, std, size)

# Example: CloudAI startup returns
cloudai = np.random.normal(0.25, 0.15, 10000)  # 25% ± 15%
```

**Main Characteristics:**

- Symmetric bell curve
- Most values cluster around mean
- Common in nature and business

## Uniform

```{python}
#| eval: false
#| echo: true
# Equal probability across range
# Example: FinFlow returns between 10-35%
returns = np.random.uniform(0.10, 0.35, size)

# Example: FinFlow startup returns
finflow = np.random.uniform(0.10, 0.35, 10000)  # 10-35% equally likely
```

**Main Characteristics:**

- All values equally likely
- Hard boundaries (min/max)
- Good for modeling complete uncertainty within range

## Exponential

```{python}
#| eval: false
#| echo: true
# Time between events
# Example: Customer arrivals, equipment failure
times = np.random.exponential(scale, size)

# Example: Time between customer arrivals (minutes)
arrivals = np.random.exponential(5, 10000)  # Average 5 minutes
```

**Main Characteristics:**

- Many small values, few large ones
- Always positive
- Common for waiting times and rare events

:::

## When NOT to Use Monte Carlo

[Monte Carlo is powerful, but not always the right tool:]{.highlight}

. . .

::: incremental
- **You have a simple analytical solution**
  - Use math directly: no need for 10,000 simulations!

- **You can't reasonably estimate input distributions**
  - Garbage in = garbage out, need basis for assumptions

- **The problem is deterministic (no uncertainty)**
  - Simulation adds complexity without value
:::

. . .

:::{.callout-warning}
Simulation is a tool for managing uncertainty, not creating false precision!
:::

# [Portfolios]{.flow} {.title}

## Combining Investments

**Suppose we have the following startups:**

[CloudAI, GreenGrid, HealthTrack, FinFlow]{.highlight}

. . .

[Question]{.question}: If we must pick 2 of 4, how many unique pairs exist?

. . .

**The Math:**

$$\binom{4}{2} = \frac{4!}{2! \times 2!} = \frac{4 \times 3 \times 2 \times 1}{(2 \times 1) \times (2 \times 1)} = \frac{24}{4} = 6$$

. . .

:::callout-tip
Each combination has different risk-return characteristics!
:::

## Four Startup Profiles

```{python}
#| eval: true
#| echo: false
#| fig-width: 12
#| fig-height: 3
# Simulate all startups for visualization
np.random.seed(42)
n_sims = 10_000

startup_returns = {
    'CloudAI': np.random.normal(0.25, 0.15, n_sims),
    'GreenGrid': np.random.normal(0.18, 0.08, n_sims),
    'HealthTrack': np.random.normal(0.30, 0.25, n_sims),
    'FinFlow': np.random.uniform(0.10, 0.35, n_sims)
}
```

```{python}
#| eval: true
#| echo: false
#| output-location: fragment
# Visualize all four startup distributions
setup_clean_style()
fig, axes = plt.subplots(2, 2)
axes = axes.flatten()

startup_colors = {
    'CloudAI': BRAND_COLORS["twoDark"],
    'GreenGrid': BRAND_COLORS["twoLight"],
    'HealthTrack': BRAND_COLORS["threeDark"],
    'FinFlow': BRAND_COLORS["oneDark"]
}

for idx, (name, returns_data) in enumerate(startup_returns.items()):
    ax = axes[idx]

    # Create histogram
    ax.hist(returns_data, bins=50, alpha=0.7, color=startup_colors[name],
            edgecolor='black', linewidth=0.5)

    # Add vertical lines for key metrics
    ax.axvline(returns_data.mean(), color='red', linestyle='--', linewidth=2,
               label=f'Mean: {returns_data.mean():.1%}')
    ax.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.5,
               label='Break-even')

    # Calculate and display risk metrics
    prob_loss = (returns_data < 0).mean()
    var_5 = np.percentile(returns_data, 5)

    # Add text box with metrics
    textstr = f'P(Loss): {prob_loss:.1%}\nVaR 5%: {var_5:.1%}'
    props = dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='gray')
    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', bbox=props)

    # Styling
    ax.set_xlabel('Return Rate', fontsize=11)
    ax.set_ylabel('Frequency', fontsize=11)
    ax.set_title(f'{name}', fontsize=12, fontweight='bold')
    ax.legend(loc='upper right', fontsize=9)
    ax.grid(True, alpha=0.2)
    ax.set_xlim(-0.5, 1.0)

plt.tight_layout()
plt.show()
```

```{python}
#| eval: true
#| echo: false
# Calculate metrics for all pairs
from itertools import combinations
results = []

for pair in combinations(['CloudAI', 'GreenGrid', 'HealthTrack', 'FinFlow'], 2):
    portfolio_returns = 0.5 * startup_returns[pair[0]] + 0.5 * startup_returns[pair[1]]
    results.append({
        'Pair': f"{pair[0]} + {pair[1]}",
        'Mean Return': portfolio_returns.mean(),
        'Std Dev': portfolio_returns.std(),
        'P(Loss)': (portfolio_returns < 0).mean(),
        'P(>50%)': (portfolio_returns > 0.50).mean()
    })

import pandas as pd
df_results = pd.DataFrame(results)
df_results = df_results.sort_values('Mean Return', ascending=False)
```

. . .

[Question]{.question}: Which startup is the best choice?

## Key Metrics for Decision Making

[Question]{.question}: Which metrics matter most for investment decisions?

::: incremental
- **Expected Return:** Average outcome across all scenarios
- **Volatility (Risk):** Standard deviation of returns
- **Probability of Loss:** How often do we lose money?
- **Upside Potential:** Chance of exceptional returns (>50%)
- **Tail Risk:** What happens in the worst 10% of cases?
:::

. . .

:::{.callout-important}
No metric tells the whole story. Investors consider multiple dimensions of risk and return.
:::

## Understanding Tail Risk

[Tail Risk:]{.highlight} The danger lurking in worst-case scenarios

**Expected Shortfall (ES)**

- Average loss in worst X% of cases
- Goes beyond simple probability
- Measures depth of potential losses
- Critical for risk management

. . .

:::{.callout-warning}
A portfolio with higher average returns might have catastrophic tail risk. Always look at the extremes!
:::

# [Correlation & Dependence]{.flow} {.title}

## The Independence Assumption

[So far, we've assumed startups succeed or fail independently.]{.highlight}

. . .

**Independent Events:**

- CloudAI's success doesn't affect GreenGrid's success
- Each startup faces separate, unrelated risks
- Portfolio risk = Average of individual risks

. . .

[Question]{.question}: Is this realistic in the real world?

. . .

:::{.callout-warning}
**Reality Check:** Many business risks are correlated! Economic downturns, market trends, and technology shifts affect multiple companies simultaneously.
:::

## What is Correlation?

[Correlation measures how two variables move together.]{.highlight}

$$\rho_{X,Y} = \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y} \quad \text{where } -1 \leq \rho \leq 1$$

. . .

**Interpreting Correlation:**

- **ρ = +1:** Perfect positive correlation (move together)
- **ρ = 0:** No correlation (independent)
- **ρ = -1:** Perfect negative correlation (move opposite)

## Correlation in Practice

```{python}
#| eval: true
#| echo: false
#| fig-width: 12
#| fig-height: 4
# Create three scenarios showing different correlations
np.random.seed(42)
n = 1000

# Generate correlated returns
x = np.random.normal(0.25, 0.15, n)

# Positive correlation
y_positive = 0.8 * x + 0.2 * np.random.normal(0.25, 0.15, n)

# No correlation
y_independent = np.random.normal(0.25, 0.15, n)

# Negative correlation
y_negative = -0.8 * x + 0.5 + 0.2 * np.random.normal(0, 0.15, n)

# Create scatter plots
setup_clean_style()
fig, axes = plt.subplots(1, 3)

# Positive correlation
axes[0].scatter(x, y_positive, alpha=0.5, s=20, color=BRAND_COLORS["twoDark"])
axes[0].set_xlabel('Startup A Return', fontsize=11)
axes[0].set_ylabel('Startup B Return', fontsize=11)
axes[0].set_title(f'Positive Correlation\nρ = {np.corrcoef(x, y_positive)[0,1]:.2f}',
                  fontsize=12, fontweight='bold')
axes[0].grid(True, alpha=0.2)
axes[0].axhline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)
axes[0].axvline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)

# Independent
axes[1].scatter(x, y_independent, alpha=0.5, s=20, color=BRAND_COLORS["oneDark"])
axes[1].set_xlabel('Startup A Return', fontsize=11)
axes[1].set_ylabel('Startup B Return', fontsize=11)
axes[1].set_title(f'No Correlation\nρ = {np.corrcoef(x, y_independent)[0,1]:.2f}',
                  fontsize=12, fontweight='bold')
axes[1].grid(True, alpha=0.2)
axes[1].axhline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)
axes[1].axvline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)

# Negative correlation
axes[2].scatter(x, y_negative, alpha=0.5, s=20, color=BRAND_COLORS["twoLight"])
axes[2].set_xlabel('Startup A Return', fontsize=11)
axes[2].set_ylabel('Startup B Return', fontsize=11)
axes[2].set_title(f'Negative Correlation\nρ = {np.corrcoef(x, y_negative)[0,1]:.2f}',
                  fontsize=12, fontweight='bold')
axes[2].grid(True, alpha=0.2)
axes[2].axhline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)
axes[2].axvline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

:::{.callout-tip}
In Python: `np.corrcoef(returns1, returns2)` calculates correlation
:::

## Why Correlation Matters

[Two AI startups in your portfolio:]{.highlight}

**Scenario 1: Independent (ρ = 0)**

- One fails due to technical issues, other succeeds
- Risk is averaged out

**Scenario 2: Positively Correlated (ρ = 0.8)**

- Both rely on same AI infrastructure provider - risk is amplified!

. . .

:::{.callout-warning}
Diversification only reduces risk when investments are not highly correlated!
:::

## Impact on Portfolio Risk

```{python}
#| eval: true
#| echo: false
# Compare portfolios with different correlations
np.random.seed(42)
n_sims = 10_000

correlations = [0.0, 0.5, 0.9]
portfolio_results = {}

for rho in correlations:
    # Generate correlated returns
    cov_matrix = [[0.15**2, rho*0.15*0.20],
                  [rho*0.15*0.20, 0.20**2]]
    returns = np.random.multivariate_normal([0.25, 0.30], cov_matrix, n_sims)

    # Calculate portfolio returns (50-50 split)
    portfolio = 0.5 * returns[:, 0] + 0.5 * returns[:, 1]
    portfolio_results[rho] = portfolio

# Visualize the impact
setup_clean_style()
fig, ax = plt.subplots(figsize=(10, 5))

colors = [BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"]]
for i, (rho, portfolio) in enumerate(portfolio_results.items()):
    ax.hist(portfolio, bins=50, alpha=0.5, label=f'ρ = {rho:.1f}',
            color=colors[i], edgecolor='black', linewidth=0.5)

ax.set_xlabel('Portfolio Return', fontsize=12)
ax.set_ylabel('Frequency', fontsize=12)
ax.set_title('Portfolio Risk Increases with Correlation', fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.2)
ax.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.3, label='Break-even')
plt.tight_layout()
plt.show()
```

. . .

:::{.callout-important}
Higher correlation = Wider distribution = More risk!
:::

## Real-World Correlation Examples

[Common sources of correlation in business:]{.highlight}

::: incremental
- **Industry-specific:** All tech startups affected by downturn
- **Geographic:** All European companies affected by EU regulations
- **Supply chain:** Multiple companies relying on same supplier
- **Macroeconomic:** Interest rates, inflation affect most businesses
:::

. . .

:::{.callout-tip}
**Diversification:** Choose investments with LOW correlation to reduce portfolio risk!
:::

## When Diversification Fails

```{python}
#| eval: true
#| echo: false
# Show that diversification fails with high correlation
np.random.seed(42)
n_sims = 10_000
n_assets_range = range(1, 21)

correlation_scenarios = [0.0, 0.5, 0.9]
scenario_results = {}

for rho in correlation_scenarios:
    portfolio_stds = []

    for n_assets in n_assets_range:
        # Generate correlated returns using common factor model
        # Returns = common_factor + idiosyncratic
        common_factor = np.random.normal(0.25, 0.20, n_sims)

        returns = []
        for _ in range(n_assets):
            idiosyncratic = np.random.normal(0, 0.20 * np.sqrt(1 - rho**2), n_sims)
            asset_return = rho * common_factor + (1 - rho) * idiosyncratic
            returns.append(asset_return)

        returns = np.column_stack(returns)
        portfolio = returns.mean(axis=1)
        portfolio_stds.append(portfolio.std())

    scenario_results[rho] = portfolio_stds

# Plot all scenarios
setup_clean_style()
fig, ax = plt.subplots(figsize=(10, 5))

colors = [BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"]]
for i, (rho, stds) in enumerate(scenario_results.items()):
    ax.plot(list(n_assets_range), stds, marker='o', linewidth=2.5,
            markersize=5, color=colors[i], label=f'ρ = {rho:.1f}', alpha=0.8)

ax.set_xlabel('Number of Assets in Portfolio', fontsize=12)
ax.set_ylabel('Portfolio Volatility', fontsize=12)
ax.set_title('Diversification Effect Decreases with Correlation', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.2)
ax.legend(fontsize=11)
plt.tight_layout()
plt.show()
```

. . .

:::{.callout-warning}
**2008 Financial Crisis:** Many "diversified" portfolios collapsed due to correlations!
:::

# [Making Smart Decisions]{.flow} {.title}

## Decision Framework

1. [Define Your Risk Tolerance]{.highlight}
   - Can you afford to lose money and what's your time horizon?
   - Are you risk-averse or risk-seeking?

2. [Evaluate Multiple Metrics]{.highlight}
   - Don't just maximize returns, consider volatility and risk
   - Look at probability of achieving goals

3. [Scenario Test]{.highlight}
   - What if distributions change or a company fails?

## The Plan for the Day

:::: columns
::: {.column width="33%"}
**Hour 1:**

**Lecture**

- Concepts
- Examples
- Visualization
:::

::: {.column width="33%"}
**Hour 2:**

**Practice Notebook**

- Simulation
- Hands-on coding
- Build your skills
:::

::: {.column width="33%"}
**Hours 3-4:**

**Competition**

- TechVenture
- Team collaboration
- €2M investment
:::
::::

. . .

[Remember:]{.highlight} The lecture gives you concepts. The notebook gives you practice. The competition tests your skills!

## Hour 2: Simulation

**Your Practice Case: Bean Counter Expansion**

- Model uncertain variables (customers, spending)
- Combine multiple uncertainties
- Calculate business metrics (VaR, profit probability)
- Make data-driven recommendations

## Hours 3-4: The Challenge

[TechVenture Investment Competition]{.highlight}

::: incremental
- **Your Budget:** €2 million
- **Your Choice:** Pick 2 of 4 startups
- **Your Goal:** Maximize risk-adjusted returns
- **Your Deliverable:** One-slide recommendation + 3-minute pitch
:::

. . .

:::{.callout-tips}
Consider multiple risk metrics and prepare a clear justification!
:::

. . .

[Prizes:]{.highlight} **10 / 6 / 3 bonus points** for top three teams!

# [Key Takeaways]{.flow} {.title}

## What You've Learned Today

:::: columns
::: {.column width="50%"}
**Concepts**

- Monte Carlo simulation
- Probability distributions
- Risk has multiple dimensions
- Expected Value vs. Variance
- Correlation and dependence
:::

::: {.column width="50%"}
**Skills**

- Using `np.random` for simulation
- Calculating risk metrics
- Visualizing uncertainty
- Comparing portfolios
- Understanding correlation
:::
::::

. . .

:::{.callout-warning}
Monte Carlo doesn't predict [THE]{.highlight} future - it shows possible futures! And correlation can amplify or reduce risk!
:::

## Next Week

[Forecasting the Future]{.highlight}

- Moving from simulation to prediction
- Time series analysis
- Trend and seasonality detection
- Measuring forecast accuracy

. . .

[Now, short break and then we start coding!]{.highlight}
