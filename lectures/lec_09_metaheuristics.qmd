---
title: "Introduction to Metaheuristics"
subtitle: "Lecture 9 - Management Science"
author: "Dr. Tobias Vlćek"
format:
  revealjs:
    footer: " {{< meta title >}} | {{< meta author >}} | [Home](lec_09_metaheuristics.qmd)"
    output-file: lec_09_presentation.html
---

# [Introduction]{.flow} {.title}

## **[Client Briefing: La Étoile]{.invert-font}** {background-image="https://unsplash.com/photos/N_Y88TWmGwA/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8Mnx8ZmluZSUyMGRpbmluZ3xlbnwwfHx8fDE3NjM3OTIzNjZ8MA&force=true&w=2400" background-size="cover"}

. . .

[Restaurant Manager's Crisis:]{.invert-font}

["I need to schedule my [18 servers across 6 shifts]{.highlight} this weekend. Shifts have [different lengths (4-6 hours)]{.highlight}, and if I don't have enough experienced servers on busy shifts, we face [penalties ranging from €150 to €400]{.highlight} per missing experienced server from our parent company!"]{.invert-font .fragment}

## The Staffing Challenge

[A restaurant facing a weekend scheduling crisis:]{.highlight}

**La Étoile's Problem:**

::: {.incremental}
- 18 servers available (6 experienced @ €75/hr, 12 junior @ €25/hr)
- 6 shifts with **varying lengths** (4-6 hours each)
- Each shift needs 3 servers (at least 1 experienced)
- Server **preferences** matter (1-10 scale, affects quality)
:::

. . .

[Question:]{.question} How to balance labor costs, penalties, AND staff?

## The Cost Impact: Why This Matters

[The financial stakes are significant with these large penalties:]{.highlight}

::: {.incremental}
- **Minimum Labor Cost**: ~€3,500 (everyone works once)
- **Experience Penalties**: €0-€1,200 per missing experienced server
- **Preference Penalties**: €0-€180 per unhappy assignment
- **Worst Case**: Over €7,000 if poorly scheduled!
- **Best Case**: ??? with smart optimization
:::

. . .

:::{.callout-important}
Potentially up to **€3,500 difference** between good and bad scheduling!
:::

## Restaurant Staffing: The Numbers

[The real-world complexity we're dealing with:]{.highlight}

```{python}
#| echo: false
#| eval: true

import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, create_plot, BRAND_COLORS, PLOT_COLORS

# Apply clean brand style
setup_clean_style()

# Calculate the combinatorial explosion
from math import comb

# Problem parameters with new complexity
n_servers = 18
n_shifts = 6
servers_per_shift = 3
shift_hours = [5, 4, 4, 6, 5, 6]  # Varying shift lengths
penalties = [800, 0, 500, 1200, 600, 1000]  # Large penalties per shift

# Calculate possibilities
ways_per_shift = comb(18, 3)
total_ways = ways_per_shift ** 6

# Create visualization
fig, axes = plt.subplots(1, 3)

# Left: Shift complexity
ax = axes[0]
shift_names = ['Fri D', 'Fri L', 'Sat L', 'Sat D', 'Sun L', 'Sun D']
x = range(len(shift_names))
width = 0.35
bars1 = ax.bar([i - width/2 for i in x], shift_hours, width, 
               label='Hours', color=BRAND_COLORS["oneDark"], alpha=0.7)
bars2 = ax.bar([i + width/2 for i in x], [p/100 for p in penalties], width,
               label='Penalty (€100s)', color=BRAND_COLORS["threeDark"], alpha=0.7)
ax.set_xlabel('Shift', fontsize=12)
ax.set_ylabel('Value', fontsize=12)
ax.set_title('Varying Complexity by Shift', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(shift_names)

# Add value labels
for bar, val in zip(bars1, shift_hours):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{val}h', ha='center', va='bottom', fontsize=10, fontweight='bold')
for bar, val in zip(bars2, penalties):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=10, fontweight='bold')

# Middle: Constraint satisfaction
ax = axes[1]
categories = ['Total\nServers', 'Experienced\nNeeded', 'Experienced\nAvailable']
values = [18, 8, 6]
colors = [BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"]]
bars = ax.bar(categories, values, color=colors, alpha=0.7)
ax.set_ylabel('Count', fontsize=12)
ax.set_title('The Constraint Violation', fontsize=14, fontweight='bold')
ax.axhline(y=6, color='red', linestyle='--', linewidth=2, alpha=0.5)
ax.text(1, 6.5, 'Shortage!', ha='center', fontsize=11, color='red', fontweight='bold')

# Add value labels on bars
for bar, val in zip(bars, values):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

# Right: Three cost components
ax = axes[2]
components = ['Labor\nCost', 'Experience\nPenalties', 'Preference\nPenalties']
typical_costs = [3500, 1600, 800]  # Typical costs in euros
colors = [BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"], BRAND_COLORS["threeDark"]]
bars = ax.bar(components, typical_costs, color=colors, alpha=0.7)
ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('Three-Way Cost Optimization', fontsize=14, fontweight='bold')

# Add value labels
for bar, val in zip(bars, typical_costs):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
```

. . .

::: callout-warning
With varying shifts, preferences, and penalties, this is will be a real challenge!
:::

## Today's Objectives

[What you'll understand after this lecture:]{.highlight}

::: {.incremental}
1. **Why local search fails:** Recap on the local optima trap
2. **Escape mechanisms:** How to accept worse solutions strategically
3. **Four powerful metaheuristics:** SA, GA, Tabu Search, ACO
4. **Selection criteria:** When to use which algorithm
:::

## Hiking in Fog

[Remember the metaphor with blindfolded eyes from last lecture?]{.highlight}

::: incremental
- **Goal**: Find the highest peak in a mountain range
- **Challenge**: You're hiking in thick fog (can only see 10 meters)
- **Position**: Your X,Y coordinates = your decisions
- **Altitude**: Your current solution quality
- **Problem**: You might climb a small hill and think it's the summit!
:::

. . .

::: callout-tip
This metaphor will guide us through all metaheuristics today!
:::

## Recap: Local Optima

[Real problems often have thousands of local optima!]{.highlight}

```{python}
#| eval: true
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.append('../helpers')
from plot_utils import BRAND_COLORS, setup_clean_style

setup_clean_style()

# Create a complex optimization landscape with many local optima
fig, ax = plt.subplots()

x = np.linspace(0, 20, 1000)
# Build a complex function with many peaks and valleys
# Start with a base trend
y = 5 + 0.1*x
# Add multiple sine/cosine waves of different frequencies
y += 1.5*np.sin(0.5*x)  # Long wavelength
y += 0.8*np.sin(2*x)     # Medium wavelength
y += 0.4*np.sin(5*x)     # Short wavelength
y += 0.3*np.cos(8*x)     # Even shorter
y += 0.2*np.sin(12*x)    # Very short wavelength
# Add some Gaussian valleys for local minima
y -= 0.8*np.exp(-(x-3)**2/0.3)   # Small local minimum
y -= 1.2*np.exp(-(x-7)**2/0.4)   # Medium local minimum
y -= 0.9*np.exp(-(x-11)**2/0.3)  # Another local minimum
y -= 5*np.exp(-(x-16)**2/0.5)    # Deep global minimum

ax.plot(x, y, color=BRAND_COLORS["twoDark"], linewidth=2, alpha=0.8)

# Find and mark several local minima
local_minima_x = [2.0, 7.27, 11.34, 13.55]
local_minima_labels = ['Local 1', 'Local 2', 'Local 3', 'Local 4']

for x_loc, label in zip(local_minima_x, local_minima_labels):
    y_loc = 5 + 0.1*x_loc
    y_loc += 1.5*np.sin(0.5*x_loc) + 0.8*np.sin(2*x_loc) + 0.4*np.sin(5*x_loc)
    y_loc += 0.3*np.cos(8*x_loc) + 0.2*np.sin(12*x_loc)
    y_loc -= 0.8*np.exp(-(x_loc-3)**2/0.3)
    y_loc -= 1.2*np.exp(-(x_loc-7)**2/0.4)
    y_loc -= 0.9*np.exp(-(x_loc-11)**2/0.3)
    y_loc -= 5*np.exp(-(x_loc-16)**2/0.5)

    ax.scatter([x_loc], [y_loc], color=BRAND_COLORS["threeDark"], s=200, zorder=3)

# Mark the global minimum
x_global = 16.05
y_global = 5 + 0.1*x_global
y_global += 1.5*np.sin(0.5*x_global) + 0.8*np.sin(2*x_global) + 0.4*np.sin(5*x_global)
y_global += 0.3*np.cos(8*x_global) + 0.2*np.sin(12*x_global)
y_global -= 0.8*np.exp(-(x_global-3)**2/0.3)
y_global -= 1.2*np.exp(-(x_global-7)**2/0.4)
y_global -= 0.9*np.exp(-(x_global-11)**2/0.3)
y_global -= 5*np.exp(-(x_global-16)**2/0.5)

ax.scatter([x_global], [y_global], color=BRAND_COLORS["oneDark"], s=200, zorder=4)
ax.annotate('GLOBAL\nMINIMUM', xy=(x_global, y_global), xytext=(x_global, y_global - 2),
            fontsize=11, ha='center', fontweight='bold',
            arrowprops=dict(arrowstyle='->', color=BRAND_COLORS["oneDark"], lw=2))

# Add shaded regions to show quality differences
ax.axhspan(ymin=ax.get_ylim()[0], ymax=y_global + 0.5, alpha=0.1, color='green', label='Excellent')
ax.axhspan(ymin=y_global + 0.5, ymax=4, alpha=0.1, color='yellow', label='Good')
ax.axhspan(ymin=4, ymax=6, alpha=0.1, color='orange', label='Mediocre')
ax.axhspan(ymin=6, ymax=ax.get_ylim()[1], alpha=0.1, color='red', label='Poor')

ax.set_xlabel('Solution Space (Different Route Configurations)', fontsize=12)
ax.set_ylabel('Total Distance (km)', fontsize=12)
ax.grid(True, alpha=0.3)

# Add text box with key insight
plt.tight_layout()
plt.show()
```

. . .

[Question:]{.question} Any idea how to escape local optima?


# [Why Simple Methods Fail]{.flow} {.title}

## The Silo Problem

[Why neighborhood optimization fails:]{.highlight}

::: columns
::: {.column width="50%"}
**Technical View: Local Optima**

- Algorithm climbs nearest hill
- Gets stuck on "foothill"
- Can't see the mountain beyond
- Every move looks worse
- Believes it found the best
:::

::: {.column width="50%"}
**Analogy: Department Silos**

- Sales optimizes sales metrics
- Engineering optimizes quality
- Finance optimizes costs
- Each department "wins"
- **Company performance looses!**
:::
:::

. . .

::: {.callout-important}
Sum of local bests ≠ Global best
:::

## Why Greedy Gets Stuck

[Greedy algorithms can simply trap themselves:]{.highlight}

. . .

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Simulate greedy staffing
np.random.seed(42)

# Create schedule visualization
fig, axes = plt.subplots(1, 2)

# Left: Greedy assignment
ax = axes[0]
shifts = ['Fri L', 'Fri D', 'Sat L', 'Sat D', 'Sun L', 'Sun D']
experienced_assignment = [2, 1, 1, 1, 1, 0]  # Greedy uses best first
junior_assignment = [1, 2, 2, 2, 2, 3]

x = np.arange(len(shifts))
width = 0.35

bars1 = ax.bar(x - width/2, experienced_assignment, width, label='Experienced', 
               color=BRAND_COLORS["oneDark"], alpha=0.8)
bars2 = ax.bar(x + width/2, junior_assignment, width, label='Junior',
               color=BRAND_COLORS["twoLight"], alpha=0.8)

ax.set_xlabel('Shift', fontsize=12)
ax.set_ylabel('Servers Assigned', fontsize=12)
ax.set_title('Greedy Assignment (Front-loaded)', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(shifts)
ax.legend()
ax.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Min Experienced Required')

# Highlight problem
ax.add_patch(plt.Rectangle((4.5, -0.5), 1, 4, fill=True, 
                          color='red', alpha=0.2))
ax.text(5, 3.5, 'No experienced\nfor Sunday!', ha='center', fontsize=10, 
        color='red', fontweight='bold')

# Right: Cost breakdown
ax = axes[1]
costs = ['Labor\n(€1,140)', 'Penalty\n(€500)', 'Total\n(€1,640)']
values = [1140, 500, 1640]
colors = [BRAND_COLORS["twoLight"], BRAND_COLORS["threeDark"], BRAND_COLORS["darker"]]
bars = ax.bar(costs, values, color=colors, alpha=0.7)

for bar, val in zip(bars, values):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('Greedy Solution Cost', fontsize=14, fontweight='bold')
ax.grid(True, axis='y', alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-warning
Greedy allocates resources early, creating problems later!
:::

## Local Search Also Struggles

[Because we only ever accept better solutions during search:]{.highlight}

. . .

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Visualize local search getting stuck
fig, axes = plt.subplots(1, 2)

# Left: Solution landscape
ax = axes[0]
x = np.linspace(0, 10, 200)

# Define the cost function - more complex landscape with multiple local minima
def cost_func(x_val):
    return (1600 
            - 120*np.sin(x_val) 
            - 80*np.sin(2.5*x_val) 
            - 60*np.sin(4*x_val) 
            - 40*np.sin(6.5*x_val)
            + 15*np.cos(8*x_val))

y = cost_func(x)

ax.plot(x, y, color=BRAND_COLORS["twoDark"], linewidth=2, alpha=0.7)
ax.fill_between(x, 1200, y, alpha=0.1, color=BRAND_COLORS["twoLight"])

# Mark positions - compute actual y-values from the function
greedy_x = 4.8
greedy_y = cost_func(greedy_x)

# Find actual local minimum around x=4.8
from scipy.optimize import minimize_scalar
local_result = minimize_scalar(cost_func, bounds=(4.0, 6.0), method='bounded')
local_x = local_result.x
local_y = local_result.fun

# Find global minimum
global_result = minimize_scalar(cost_func, bounds=(0, 10), method='bounded')
global_x = global_result.x
global_y = global_result.fun

ax.scatter([greedy_x], [greedy_y], color=BRAND_COLORS["oneDark"], s=200, marker='o', zorder=5, label='Greedy Start')
ax.scatter([local_x], [local_y], color=BRAND_COLORS["threeDark"], s=200, marker='*', zorder=5, label='Local Optimum')
ax.scatter([global_x], [global_y], color=BRAND_COLORS["twoDark"], s=200, marker='*', zorder=5, label='Global Optimum')

# Show local search path
ax.arrow(greedy_x, greedy_y, local_x-greedy_x-0.1, local_y-greedy_y+5,
         head_width=0.2, head_length=5, fc=BRAND_COLORS["oneDark"], ec=BRAND_COLORS["oneDark"], alpha=0.7)

# Show barrier
ax.axvspan(local_x+0.5, global_x-0.5, alpha=0.2, color=BRAND_COLORS["darker"])
ax.text(6, 1700, 'Can\'t climb\nthis hill!', ha='center', fontsize=10, 
        color=BRAND_COLORS["threeDark"], fontweight='bold')

ax.set_xlabel('Solution Space', fontsize=12)
ax.set_ylabel('Total Cost (€)', fontsize=12)
ax.set_title('Local Search Trapped in Local Minimum', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# Right: Neighborhood structure
ax = axes[1]
# Create network of neighbors
from matplotlib.patches import Circle, FancyArrow

center = (0.5, 0.5)
neighbors = [(0.3, 0.7), (0.7, 0.7), (0.3, 0.3), (0.7, 0.3),
             (0.5, 0.8), (0.5, 0.2), (0.2, 0.5), (0.8, 0.5)]

# Draw center
circle = Circle(center, 0.08, color=BRAND_COLORS["twoDark"])
ax.add_patch(circle)
ax.text(center[0], center[1], 'Current\n€1520', ha='center', va='center', 
        fontsize=9, fontweight='bold', color='white')

# Draw neighbors
for i, (x, y) in enumerate(neighbors):
    cost = 1520 + np.random.randint(10, 100)
    circle = Circle((x, y), 0.06, color=BRAND_COLORS["threeLight"])
    ax.add_patch(circle)
    ax.text(x, y, f'€{cost}', ha='center', va='center', fontsize=8)
    
    # Draw edge
    ax.plot([center[0], x], [center[1], y], 'k-', alpha=0.1, linewidth=1)

ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_aspect('equal')
ax.axis('off')
ax.set_title('All Neighbors Worse → Stuck!', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()
```

. . .

[Question:]{.question} What can we do to cope with this situation?

# [Metaheuristic #1: Simulated Annealing]{.flow} {.title}

## Core Concepts

[The fundamental components:]{.highlight}

::: incremental
- **Solution** = One complete schedule/route/plan
- **Neighbor** = A slightly modified version
- **Cost** = How good/bad the solution is
:::

. . .

**The Strategy**

- Always accept improvements
- Sometimes accept worse solutions (the change!)

. . .

[Think of it as strategic risk-taking that decreases over time!]{.highlight}

## The Metallurgy Metaphor

[How annealing steel inspired an optimization algorithm:]{.highlight}

::: columns
::: {.column width="50%"}
**Annealing Metal:**

1. Heat to high temperature
2. Atoms move freely
3. Slowly cool down
4. Forms crystal structure
:::

::: {.column width="50%"}
**Optimization:**

1. Start with high "temperature"
2. Accept bad moves often
3. Gradually reduce temperature
4. Converge to good solution
:::
:::

. . .

::: callout-important
The willingness to temporarily accept worse solutions is what enables finding the summit!
:::

## Temperature Controls Acceptance

[Probability of accepting worse solutions lowers with temp:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(1, 1)

# Cost increases we might encounter (worse solutions)
delta_costs = np.linspace(0, 300, 200)

# Three temperature scenarios
temperatures = [500, 100, 10]
colors = [BRAND_COLORS["threeDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"]]
labels = ['HOT (T=500)', 
          'WARM (T=100)', 
          'COLD (T=10)']
alphas = [0.9, 0.7, 0.5]

for T, color, label, alpha in zip(temperatures, colors, labels, alphas):
    probabilities = np.exp(-delta_costs / T)
    ax.plot(delta_costs, probabilities, linewidth=4, color=color, label=label, alpha=alpha)

# Mark specific examples
example_cost = 150
for T, color in zip(temperatures, colors):
    prob = np.exp(-example_cost / T)
    ax.plot([example_cost], [prob], 'o', markersize=12, color=color, 
            markeredgewidth=2, markeredgecolor='white', zorder=5)
    ax.annotate(f'{prob:.0%}', xy=(example_cost, prob), 
                xytext=(example_cost + 30, prob + 0.05),
                fontsize=11, fontweight='bold', color=color,
                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor=color, linewidth=2),
                arrowprops=dict(arrowstyle='->', color=color, linewidth=2))

# Styling
ax.set_xlabel('Cost Increase (€)', fontsize=14)
ax.set_ylabel('Acceptance Probability', fontsize=14)
ax.set_title('Formula: P(accept) = exp(-Δcost / T)', 
             fontsize=16, fontweight='bold', pad=20)
ax.set_ylim(-0.05, 1.1)
ax.set_xlim(0, 300)
ax.grid(True, alpha=0.3, linestyle='--')
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)

# Add reference line
ax.axvline(x=example_cost, color='gray', linestyle=':', alpha=0.5, linewidth=2)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
We essentially compare the cost of the new schedule to the current cost and decide whether to accept the change based on the temperature and the difference in cost.
:::

## Concept

[How Simulated Annealing Works (Pseudocode)]{.highlight}

```python
def simulated_annealing_concept(current_schedule):
    temperature = 500  # Start "hot" (adventurous)
    best_schedule = current_schedule
    
    while temperature > 1:
        # Step 1: Try a random change (like swapping two shifts)
        new_schedule = make_random_change(current_schedule)
        
        # Step 2: Is it better?
        if cost(new_schedule) < cost(current_schedule):
            current_schedule = new_schedule  # Always accept improvements
        else:
            # NEW: Sometimes accept worse solutions!
            # Hot temperature = more likely to accept
            # Cold temperature = less likely to accept
            if random() < acceptance_probability(temperature):
                current_schedule = new_schedule  # Accept anyway!
        
        # Step 3: Cool down (become less adventurous)
        temperature = temperature * 0.95
        
        # Remember the best we've ever seen
        if cost(current_schedule) < cost(best_schedule):
            best_schedule = current_schedule
    
    return best_schedule
```

## SA in Action: Restaurant Staffing

[A simplified weekend scheduling problem we'll use throughout:]{.highlight}

```{python}
#| echo: true
#| eval: false

# SIMPLIFIED PROBLEM (used across ALL metaheuristics today)
"""
La Étoile's Weekend Challenge:
- 12 servers: 4 experienced (E1-E4), 8 junior (J1-J8)
- 6 shifts: Need 2 servers each
- Everyone works exactly 1 shift
"""
```

. . .

**The initial greedy schedule has the following results:**

. . .

```{python}
#| echo: false
#| eval: true
import numpy as np
import random

# Server costs (per shift, varying shift lengths!)
COSTS = {
    'E1': 375, 'E2': 375, 'E3': 300, 'E4': 300,  # Experienced: €75/hr × 4-5hr
    'J1': 100, 'J2': 100, 'J3': 125, 'J4': 125,  # Junior: €25/hr × 4-5hr
    'J5': 100, 'J6': 100, 'J7': 125, 'J8': 125
}

# Shift requirements & penalties (tighter constraints now!)
SHIFTS = {
    'Fri_Dinner': {'min_exp': 1, 'penalty': 500},
    'Fri_Late':   {'min_exp': 0, 'penalty': 0},
    'Sat_Lunch':  {'min_exp': 1, 'penalty': 400},
    'Sat_Dinner': {'min_exp': 2, 'penalty': 800},
    'Sun_Lunch':  {'min_exp': 1, 'penalty': 400},
    'Sun_Dinner': {'min_exp': 1, 'penalty': 600}
}

# Server preferences (1-10 scale, 10=loves this shift)
# More conflicting preferences to make optimization harder!
PREFERENCES = {
    'E1': [9, 2, 7, 8, 5, 6],  # Loves Fri dinner, hates Fri late
    'E2': [6, 4, 5, 9, 7, 8],  # Prefers Sat/Sun dinners
    'E3': [5, 8, 9, 4, 8, 5],  # Loves lunches and late shift
    'E4': [7, 3, 6, 7, 6, 9],  # Prefers Sun dinner
    'J1': [4, 7, 8, 3, 9, 5],  # Prefers lunches
    'J2': [8, 9, 5, 6, 4, 7],  # Loves late shifts
    'J3': [6, 5, 9, 4, 8, 6],  # Loves Sat lunch
    'J4': [7, 8, 6, 7, 5, 8],  # Flexible
    'J5': [5, 9, 4, 8, 6, 7],  # Loves Fri late, Sat dinner
    'J6': [9, 6, 7, 5, 8, 4],  # Loves Fri dinner
    'J7': [4, 7, 8, 6, 9, 5],  # Loves Sun lunch
    'J8': [6, 8, 5, 7, 6, 9]   # Prefers late/dinner shifts
}

def calculate_cost(schedule):
    """
    Schedule = [[shift1_servers], [shift2_servers], ...]
    Returns: (total_cost, labor, penalties, preference_cost)
    """
    labor_cost = 0
    penalty_cost = 0
    preference_cost = 0
    shift_names = list(SHIFTS.keys())
    
    for shift_idx, servers in enumerate(schedule):
        # Labor costs
        for server in servers:
            labor_cost += COSTS[server]
        
        # Experience penalties
        exp_count = sum(1 for s in servers if s.startswith('E'))
        min_exp = SHIFTS[shift_names[shift_idx]]['min_exp']
        if exp_count < min_exp:
            penalty_cost += SHIFTS[shift_names[shift_idx]]['penalty']
        
        # Preference penalties (unhappiness cost)
        for server in servers:
            pref = PREFERENCES[server][shift_idx]
            preference_cost += (10 - pref) * 30  # €30 per unhappiness point
    
    return labor_cost + penalty_cost + preference_cost, labor_cost, penalty_cost, preference_cost

# Example: Greedy schedule (assign cheapest available, ignoring preferences)
greedy_schedule = [
    ['J1', 'J2'],  # Fri Dinner (need 1 exp - PENALTY!)
    ['J3', 'J4'],  # Fri Late
    ['J5', 'J6'],  # Sat Lunch (need 1 exp - PENALTY!)
    ['J7', 'E1'],  # Sat Dinner (need 2 exp, only have 1 - PENALTY!)
    ['J8', 'E2'],  # Sun Lunch
    ['E3', 'E4']   # Sun Dinner
]

cost, labor, penalty, pref = calculate_cost(greedy_schedule)
print(f"Greedy Schedule Cost: €{cost:,.0f}")
print(f"  Labor: €{labor}, Penalties: €{penalty}, Unhappiness: €{pref}")
```

. . .

::: callout-tip
Let's see how Simulated Annealing can improve the solution!
:::

## Visualizing SA Performance

[How temperature affects the search behavior:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS
import math

# Apply clean brand style
setup_clean_style()

# Helper function: Make a neighbor by swapping two servers
def make_neighbor(schedule):
    """Swap two random servers from different shifts"""
    new_schedule = [shift[:] for shift in schedule]  # Deep copy
    
    # Pick two different shifts
    num_shifts = len(schedule)
    shift1, shift2 = random.sample(range(num_shifts), 2)
    # Pick random servers from each
    pos1, pos2 = random.randint(0, 1), random.randint(0, 1)
    
    # Swap them
    new_schedule[shift1][pos1], new_schedule[shift2][pos2] = \
        new_schedule[shift2][pos2], new_schedule[shift1][pos1]
    
    return new_schedule

# Simulated Annealing Implementation
def simulated_annealing(initial_schedule, max_iterations=500, initial_temp=1000, cooling_rate=0.99):
    """Run SA and track cost history"""
    current = [shift[:] for shift in initial_schedule]
    current_cost = calculate_cost(current)[0]
    
    best = [shift[:] for shift in current]
    best_cost = current_cost
    
    temperature = initial_temp
    cost_history = [current_cost]
    temp_history = [temperature]
    best_history = [best_cost]
    
    random.seed(42)
    
    for iteration in range(max_iterations):
        # Generate neighbor
        neighbor = make_neighbor(current)
        neighbor_cost = calculate_cost(neighbor)[0]
        
        # Acceptance criterion
        delta = neighbor_cost - current_cost
        
        if delta < 0:  # Better solution
            current = neighbor
            current_cost = neighbor_cost
        else:  # Worse solution - maybe accept
            acceptance_prob = math.exp(-delta / temperature) if temperature > 0 else 0
            if random.random() < acceptance_prob:
                current = neighbor
                current_cost = neighbor_cost
        
        # Track best ever seen
        if current_cost < best_cost:
            best = [shift[:] for shift in current]
            best_cost = current_cost
        
        # Cool down
        temperature *= cooling_rate
        
        # Record history
        cost_history.append(current_cost)
        temp_history.append(temperature)
        best_history.append(best_cost)
    
    return best, best_cost, cost_history, temp_history, best_history

# Run SA from greedy starting point
np.random.seed(42)
random.seed(42)
best_schedule, best_cost_sa, costs, temps, best_costs = simulated_annealing(greedy_schedule)

# Create visualization
fig, axes = plt.subplots(2, 1, sharex=True)

greedy_cost_value = calculate_cost(greedy_schedule)[0]
iterations = list(range(len(costs)))

# Top: Cost over time
ax = axes[0]
ax.axhline(y=greedy_cost_value, color=BRAND_COLORS["threeDark"], linestyle='--', 
           linewidth=2, label=f'Greedy Start', alpha=0.7)
ax.plot(iterations, costs, color=BRAND_COLORS["twoLight"], linewidth=2, 
        alpha=0.7, label='SA Current Solution')
ax.plot(iterations, best_costs, color=BRAND_COLORS["twoDark"], linewidth=2, 
        label=f'SA Best')
ax.set_ylabel('Total Cost (€)', fontsize=12)
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)

# Add annotations for phases
total_iters = len(iterations)
ax.axvspan(0, total_iters*0.3, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(total_iters*0.3, total_iters*0.7, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(total_iters*0.7, total_iters, alpha=0.1, color=BRAND_COLORS["twoDark"])

# Bottom: Temperature
ax = axes[1]
ax.plot(iterations, temps, color=BRAND_COLORS["twoDark"], linewidth=3)
ax.axvspan(0, total_iters*0.3, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(total_iters*0.3, total_iters*0.7, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(total_iters*0.7, total_iters, alpha=0.1, color=BRAND_COLORS["twoDark"])
ax.set_xlabel('Iteration', fontsize=12)
ax.set_ylabel('Temperature', fontsize=12)
ax.grid(True, alpha=0.3)

# Add phase labels
ax.text(total_iters*0.15, max(temps)*0.2, 'EXPLORE\n(Accept bad moves)', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["threeDark"])
ax.text(total_iters*0.5, max(temps)*0.2, 'TRANSITION\n(Balance)', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["oneDark"])
ax.text(total_iters*0.85, max(temps)*0.2, 'EXPLOIT\n(Refine best)', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["twoDark"])

plt.tight_layout()
plt.show()
``` 

. . .

::: callout-important
See how SA accepts worse solutions early, enabling escape from local optima!
:::

## Common SA Mistakes

[Avoid these common implementation errors:]{.highlight}

. . .

**Mistake #1: Starting Too Cold**

- If temperature is too low → Acts like greedy (no exploration)
- Fix: Start hot enough to accept bad moves

. . .

**Mistake #2: Cooling Too Quickly**

- If you cool fast → Get stuck early
- Fix: Cool slowly (multiply by 0.95-0.99, not 0.5)

. . .

::: {.callout-warning}
Quick cooling is tempting for speed, but defeats the purpose of SA!
:::

## Temperature Parameter Impact

```{python}
#| echo: false
#| eval: true

# Compare different temperature settings
np.random.seed(42)

# Run SA with different parameters
configs = [
    {'name': 'Too Cold Start', 'temp': 100, 'cooling': 0.99, 'color': BRAND_COLORS["threeDark"]},
    {'name': 'Too Fast Cooling', 'temp': 1000, 'cooling': 0.1, 'color': BRAND_COLORS["oneDark"]},
    {'name': 'Good Balance', 'temp': 1000, 'cooling': 0.99, 'color': BRAND_COLORS["twoDark"]},
]

fig, ax = plt.subplots(1, 1)

greedy_cost_value = calculate_cost(greedy_schedule)[0]

for config in configs:
    random.seed(42)
    _, best_cost, costs, temps, best_costs = simulated_annealing(
        greedy_schedule, 
        max_iterations=500, 
        initial_temp=config['temp'], 
        cooling_rate=config['cooling']
    )
    
    iterations = list(range(len(best_costs)))
    ax.plot(iterations, best_costs, linewidth=3, color=config['color'], 
            label=f"{config['name']}: Final €{best_cost:.0f}", alpha=0.8)

# Add greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle='--', 
           linewidth=2, label=f'Greedy Baseline: €{greedy_cost_value:.0f}', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Best Cost Found (€)', fontsize=14, fontweight='bold')
ax.set_title('Impact of Temperature Parameters on SA Performance (Same problem, different settings)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='best', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
The "Good Balance" explores widely early, then refines carefully. Often you need to balance exploration and exploitation by experimenting with different parameters.
:::

# [Metaheuristic #2: Genetic Algorithms]{.flow} {.title}

## Evolution as Optimization

[How natural selection inspires computational optimization:]{.highlight}

::: columns
::: {.column width="50%"}
**Natural Selection:**

1. Population of individuals
2. Fittest survive & reproduce
3. Offspring inherit traits
4. Mutations create diversity
5. Evolution finds adaptation
:::

::: {.column width="50%"}
**Optimization:**

1. Population of solutions
2. Best solutions selected
3. Crossover combines solutions
4. Mutation adds variation
5. Evolution finds optimum
:::
:::

. . .

::: callout-tip
Just like successful products get more market share, better solutions get more "offspring" in the next generation. It's survival of the fittest, but for schedules, routes, or designs!
:::


```{python}
#| echo: false
#| eval: true

# Genetic Algorithm Implementation (run early so data is available for later slides)
def create_random_schedule():
    """Create a random valid schedule"""
    servers = list(COSTS.keys())
    random.shuffle(servers)
    return [servers[i:i+2] for i in range(0, 12, 2)]

def tournament_selection(population, pop_costs, tournament_size=3):
    """Select parent via tournament selection"""
    tournament = random.sample(list(zip(population, pop_costs)), tournament_size)
    return min(tournament, key=lambda x: x[1])[0]

def crossover(parent1, parent2):
    """Order crossover - maintain valid assignments"""
    # Flatten parents
    p1_flat = [s for shift in parent1 for s in shift]
    p2_flat = [s for shift in parent2 for s in shift]
    
    # Take first 3 shifts from parent1, fill rest from parent2
    child_flat = p1_flat[:6]  # First 3 shifts (6 servers)
    for server in p2_flat:
        if server not in child_flat:
            child_flat.append(server)
    
    # Reconstruct schedule
    return [child_flat[i:i+2] for i in range(0, 12, 2)]

def mutate(schedule, mutation_rate=0.2):
    """Swap two servers with some probability"""
    if random.random() < mutation_rate:
        return make_neighbor(schedule)
    return schedule

def genetic_algorithm(pop_size=20, generations=100, mutation_rate=0.2):
    """Run GA and track best/average fitness"""
    # Initialize population
    population = [create_random_schedule() for _ in range(pop_size)]
    
    best_history = []
    avg_history = []
    best_overall = None
    best_overall_cost = float('inf')
    
    random.seed(42)
    
    for gen in range(generations):
        # Evaluate fitness
        pop_costs = [calculate_cost(ind)[0] for ind in population]
        
        # Track statistics
        best_idx = np.argmin(pop_costs)
        best_history.append(pop_costs[best_idx])
        avg_history.append(np.mean(pop_costs))
        
        if pop_costs[best_idx] < best_overall_cost:
            best_overall = [shift[:] for shift in population[best_idx]]
            best_overall_cost = pop_costs[best_idx]
        
        # Create next generation
        new_population = []
        
        # Elitism: keep best 2
        sorted_pop = sorted(zip(population, pop_costs), key=lambda x: x[1])
        new_population.extend([ind for ind, _ in sorted_pop[:2]])
        
        # Generate offspring
        while len(new_population) < pop_size:
            parent1 = tournament_selection(population, pop_costs)
            parent2 = tournament_selection(population, pop_costs)
            child = crossover(parent1, parent2)
            child = mutate(child, mutation_rate)
            new_population.append(child)
        
        population = new_population
    
    return best_overall, best_overall_cost, best_history, avg_history

# Run GA
np.random.seed(42)
random.seed(42)
ga_best_schedule, ga_best_cost, ga_best_hist, ga_avg_hist = genetic_algorithm(
    pop_size=20, generations=500, mutation_rate=0.2
)

```

## The Genetic Process

[Four stages repeat each generation:]{.highlight}

::: incremental
1. **Selection:** Choose parents based on fitness
2. **Crossover:** Combine to create children
3. **Mutation:** Randomly modify children
4. **Replacement:** New generation replaces old
5. **Population Evolution:** Improve population quality
:::

. . .

::: callout-tip
Let's see each stage in detail with our restaurant problem!
:::

## Stage 1: Selection (Tournament)

[How to choose which schedules get to "reproduce":]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Create realistic population costs
np.random.seed(42)
population_size = 20
costs = np.random.randint(3700, 4600, population_size)
costs = sorted(costs)

fig, axes = plt.subplots(1, 2)

# Left: Full population
ax = axes[0]
colors = [BRAND_COLORS["twoLight"] for _ in range(population_size)]
bars = ax.barh(range(population_size), costs, color=colors, alpha=0.6, edgecolor='black', linewidth=1)

ax.set_ylabel('Individual Schedule ID', fontsize=12)
ax.set_xlabel('Cost (€)', fontsize=12)
ax.set_title('Current Population (20 schedules)', fontsize=14, fontweight='bold')
ax.set_yticks(range(0, population_size, 5))
ax.grid(True, alpha=0.3, axis='x')

# Right: Tournament selection
ax = axes[1]

# Pick 3 random individuals for tournament
tournament_indices = [5, 12, 17]
tournament_costs = [costs[i] for i in tournament_indices]
winner_idx = tournament_indices[np.argmin(tournament_costs)]
winner_cost = min(tournament_costs)

# Show tournament
colors_tournament = ['green' if costs[i] == winner_cost else 'orange' for i in tournament_indices]
ax.barh(range(3), tournament_costs, color=colors_tournament, alpha=0.8, edgecolor='black', linewidth=2)

ax.set_ylabel('Tournament Contestant', fontsize=12)
ax.set_xlabel('Cost (€)', fontsize=12)
ax.set_title('Tournament Selection (size=3)', fontsize=14, fontweight='bold')
ax.set_yticks(range(3))
ax.set_yticklabels([f'Schedule #{i}' for i in tournament_indices])
ax.grid(True, alpha=0.3, axis='x')

# Annotate winner
ax.text(winner_cost + 30, 0, '← WINNER!\nSelected as parent', va='center', fontsize=11, 
        fontweight='bold', color='green')

plt.tight_layout()
plt.show()
```

. . .

::: callout-important
Each tournament selects one parent, then we pair them up sequentially for crossover.
:::


## Stage 2: Crossover (Recombination)

[Combine two parent schedules to create offspring:]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(1, 1)
ax.set_xlim(0, 14)
ax.set_ylim(0, 10)
ax.axis('off')

# Define shift labels
shifts = ['Fri\nDinner', 'Fri\nLate', 'Sat\nLunch', 'Sat\nDinner', 'Sun\nLunch', 'Sun\nDinner']

# Parent 1 - shown as colored blocks
y_parent1 = 8

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    # Draw colored block
    rect = plt.Rectangle((x, y_parent1), 1.5, 0.8, facecolor=BRAND_COLORS["oneLight"], 
                         edgecolor='black', linewidth=2, alpha=0.7)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_parent1 + 0.4, shift, ha='center', va='center', fontsize=9, fontweight='bold')

# Parent 2 - shown as colored blocks
y_parent2 = 6.5

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    # Draw colored block
    rect = plt.Rectangle((x, y_parent2), 1.5, 0.8, facecolor=BRAND_COLORS["twoLight"], 
                         edgecolor='black', linewidth=2, alpha=0.7)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_parent2 + 0.4, shift, ha='center', va='center', fontsize=9, fontweight='bold')

# Crossover point indicator
crossover_point = 3  # After 3rd shift
x_cross = 1 + crossover_point * 2 - 0.1
ax.plot([x_cross, x_cross], [y_parent2 - 0.5, y_parent1 + 1.2], color=BRAND_COLORS["threeDark"], linewidth=3, alpha=0.7)
ax.text(x_cross + 0.2, y_parent1 + 1.4, 'Cut here', fontsize=11, color=BRAND_COLORS["threeDark"], fontweight='bold')

# Arrows showing inheritance
ax.annotate('', xy=(4, 3.8), xytext=(4, y_parent1 - 0.3),
            arrowprops=dict(arrowstyle='->', lw=2, color=BRAND_COLORS["oneDark"]))
ax.annotate('', xy=(10, 3.8), xytext=(10, y_parent2 - 0.3),
            arrowprops=dict(arrowstyle='->', lw=2, color=BRAND_COLORS["twoDark"]))

# Child - combination
y_child = 2

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    # Color based on which parent
    if i < crossover_point:
        color = BRAND_COLORS["oneLight"]
        label_color = BRAND_COLORS["oneDark"]
    else:
        color = BRAND_COLORS["twoLight"]
        label_color = BRAND_COLORS["twoDark"]
    
    # Draw colored block
    rect = plt.Rectangle((x, y_child), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=3, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_child + 0.4, shift, ha='center', va='center', fontsize=9, fontweight='bold')

# Add explanation
ax.text(7, 0.5, 'First 3 shifts from Parent 1, last 3 from Parent 2', 
        ha='center', fontsize=12, style='italic')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Crossover randomly combines good building blocks from both parents!
:::

## Stage 3: Mutation

[Random changes maintain diversity and explore new solutions:]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(1, 1)
ax.set_xlim(0, 14)
ax.set_ylim(0, 8)
ax.axis('off')

# Define shift labels (these stay the same!)
shifts = ['Fri\nDinner', 'Fri\nLate', 'Sat\nLunch', 'Sat\nDinner', 'Sun\nLunch', 'Sun\nDinner']

# Color palette for each shift - each shift gets its own distinct color
shift_colors = [
    BRAND_COLORS["oneLight"],    
    BRAND_COLORS["oneDark"],     
    BRAND_COLORS["twoLight"],   
    BRAND_COLORS["twoDark"],     
    BRAND_COLORS["threeDark"],   
    BRAND_COLORS["threeLight"]   
]

# Before mutation - original color assignment represents which servers work which shift
y_before = 5.5
ax.text(0.5, y_before + 1.7, 'Before Mutation', fontsize=14, fontweight='bold', ha='left')

# Positions that will swap their server assignments (swap colors)
swap_pos1, swap_pos2 = 1, 4  # Fri Late ↔ Sun Lunch

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    color = shift_colors[i]
    
    rect = plt.Rectangle((x, y_before), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_before + 0.4, shift, ha='center', va='center', 
            fontsize=9, fontweight='bold', color='black')

# Draw swap arrows between the highlighted blocks
x1 = 1 + swap_pos1 * 2 + 0.75
x2 = 1 + swap_pos2 * 2 + 0.75
y_arrow = y_before - 0.5

# Curved arrow showing swap
ax.annotate('', xy=(x2, y_arrow), xytext=(x1, y_arrow),
            arrowprops=dict(arrowstyle='<->', lw=3, color=BRAND_COLORS["threeDark"], 
                          connectionstyle="arc3,rad=.3"))
ax.text((x1 + x2) / 2, y_arrow - 0.8, 'SWAP ASSIGNMENTS!', ha='center', fontsize=12, 
        fontweight='bold', color='red', alpha=0.7)

# After mutation - COLORS are swapped (representing different server assignments)
y_after = 1.5
ax.text(0.5, y_after + 1.7, 'After Mutation', fontsize=14, fontweight='bold', ha='left')

# Create color array with swapped assignments
after_colors = shift_colors.copy()
after_colors[swap_pos1], after_colors[swap_pos2] = after_colors[swap_pos2], after_colors[swap_pos1]

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    color = after_colors[i]  # Color represents the server assignment
    
    rect = plt.Rectangle((x, y_after), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_after + 0.4, shift, ha='center', va='center', 
            fontsize=9, fontweight='bold', color='black')

# Add explanation
ax.text(7, 0, 'Mutation rate: 20% (happens to 1 in 5 offspring)', 
        ha='center', fontsize=11, style='italic')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Mutation adds random exploration, like trying something completely new occasionally!
:::

## Stage 4: Replacement I

[How do offspring join the population?]{.highlight}

::: incremental
- **Generational:** Replace entire population with offspring
- **Steady-State:** Replace only worst individuals
- **Elitism:** Always keep the best solutions
:::

. . .

::: callout-note
Our approach: **Generational with Elitism**, we create 20 offspring via repeated selection/crossover/mutation, but preserve the 2 best from current generation.
:::

## Stage 4: Replacement II

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(1, 1)
ax.set_xlim(0, 14)
ax.set_ylim(0, 11)
ax.axis('off')

# Arrows showing replacement strategy
y_next = 2
y_current = 8.5
ax.annotate('', xy=(4.25, y_next + 1.0), xytext=(2.25, y_current - 0.8),
            arrowprops=dict(arrowstyle='->', lw=2, color=BRAND_COLORS["oneDark"], alpha=0.6))
ax.annotate('', xy=(6.25, y_next + 1.0), xytext=(4.25, y_current - 0.8),
            arrowprops=dict(arrowstyle='->', lw=2, color=BRAND_COLORS["oneDark"], alpha=0.6))

# Current generation (top)
ax.text(0.5, y_current + 1.2, 'Current Generation (Population = 6)', fontsize=14, fontweight='bold', ha='left')
ax.text(6.5, y_current + 1.2, 'After 3 parent pairs → 6 offspring created via crossover/mutation', 
        fontsize=10, style='italic', ha='left', color='gray')

# Current population with costs
current_costs = [3800, 3900, 4100, 4200, 4400, 4500]
for i, cost in enumerate(current_costs):
    x = 1.5 + i * 2
    color = BRAND_COLORS["oneLight"] if i < 2 else BRAND_COLORS["twoLight"]  # Best 2 are highlighted
    rect = plt.Rectangle((x, y_current), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.7)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_current + 0.4, f'€{cost}', ha='center', va='center', 
            fontsize=10, fontweight='bold')

# Mark elite
ax.text(2.25, y_current - 0.5, 'Elite', ha='center', fontsize=9, 
        fontweight='bold', color=BRAND_COLORS["oneDark"])
ax.text(4.25, y_current - 0.5, 'Elite', ha='center', fontsize=9, 
        fontweight='bold', color=BRAND_COLORS["oneDark"])

# Offspring created (middle)
y_offspring = 5.5
ax.text(0.5, y_offspring + 1.2, 'Offspring Created (6 new solutions)', fontsize=14, fontweight='bold', ha='left')
ax.text(6.5, y_offspring + 1.2, 'Tournament selection ran 6 times to get parents for 3 crossovers', 
        fontsize=10, style='italic', ha='left', color='gray')

offspring_costs = [3750, 3950, 4050, 4150, 4300, 4600]
for i, cost in enumerate(offspring_costs):
    x = 1.5 + i * 2
    color = BRAND_COLORS["threeDark"] if i == 0 else BRAND_COLORS["threeLight"]  # Best offspring highlighted
    rect = plt.Rectangle((x, y_offspring), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.7)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_offspring + 0.4, f'€{cost}', ha='center', va='center', 
            fontsize=10, fontweight='bold')

# Mark best new
ax.text(2.25, y_offspring - 0.5, 'Best new!', ha='center', fontsize=9, 
        fontweight='bold', color=BRAND_COLORS["threeDark"])

# Next generation (bottom) - with elitism
y_next = 2
ax.text(0.5, y_next + 1.2, 'Next Generation (Elitism: keep 2 best)', fontsize=14, fontweight='bold', ha='left')
ax.text(6.5, y_next + 1.2, '2 elite preserved + 4 best offspring = 6 total (same population size)', 
        fontsize=10, style='italic', ha='left', color='gray')

next_costs = [3750, 3800, 3900, 3950, 4050, 4150]  # Best offspring + 2 elite
for i, cost in enumerate(next_costs):
    x = 1.5 + i * 2
    # Color coding: elite from previous (oneLight) vs new offspring (threeDark/threeLight)
    if cost in [3800, 3900]:  # Elite kept
        color = BRAND_COLORS["oneLight"]
        marker = '★'
    elif cost == 3750:  # Best new
        color = BRAND_COLORS["threeDark"]
        marker = '✓'
    else:
        color = BRAND_COLORS["threeLight"]
        marker = ''
    
    rect = plt.Rectangle((x, y_next), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_next + 0.4, f'€{cost}', ha='center', va='center', 
            fontsize=10, fontweight='bold')

ax.text(13.5, 4, 'Elite preserved ↓', rotation=-90, fontsize=11, 
        fontweight='bold', color=BRAND_COLORS["oneDark"], va='center')

plt.tight_layout()
plt.show()
```

. . .

::: callout-note
Elitism ensures we never lose our best solutions while exploring new ones!
:::

## Stage 5. Population Evolution

[How the population improves over generations:]{.highlight}

```{python}
#| echo: false
#| eval: true

# Use same plot style as head-to-head comparison
fig, ax = plt.subplots(1, 1)

# Plot GA data
generations = list(range(len(ga_best_hist)))
ax.plot(generations, ga_best_hist, color=BRAND_COLORS["twoDark"], linewidth=3, 
        label=f'GA Best (€{ga_best_cost:.0f})', alpha=0.9)
ax.plot(generations, ga_avg_hist, color=BRAND_COLORS["twoLight"], linewidth=2, 
        linestyle='--', label='GA Population Average', alpha=0.6)

# Greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy Start (€{greedy_cost_value:.0f})', alpha=0.6)

# Annotate phases
ax.axvspan(0, 30, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(30, 70, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(70, len(generations), alpha=0.1, color=BRAND_COLORS["twoDark"])

ax.text(15, max(ga_avg_hist)*0.98, 'EXPLORATION\nHigh diversity', ha='center', 
        fontsize=10, fontweight='bold', color=BRAND_COLORS["threeDark"])
ax.text(50, max(ga_avg_hist)*0.88, 'REFINEMENT\nConverging', ha='center', 
        fontsize=10, fontweight='bold', color=BRAND_COLORS["oneDark"])
ax.text(85, max(ga_avg_hist)*0.78, 'EXPLOITATION\nFine-tuning', ha='center', 
        fontsize=10, fontweight='bold', color=BRAND_COLORS["twoDark"])

ax.set_xlabel('Generation', fontsize=14, fontweight='bold')
ax.set_ylabel('Cost (€)', fontsize=14, fontweight='bold')
ax.set_title('Genetic Algorithm: Population Improvement Over Time', fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='best', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-note
Notice how population average also improves (not just the best)!
:::

## GA vs SA: Head-to-Head

[Comparing exploration strategies on the restaurant problem:]{.highlight}

```{python}
#| echo: false
#| eval: true

# GA already ran earlier - just create comparison visualization
fig, ax = plt.subplots(1, 1)

# Plot both algorithms
generations = list(range(len(ga_best_hist)))
ax.plot(generations, ga_best_hist, color=BRAND_COLORS["twoDark"], linewidth=3, 
        label=f'GA Best (€{ga_best_cost:.0f})', alpha=0.9)
ax.plot(generations, ga_avg_hist, color=BRAND_COLORS["twoLight"], linewidth=2, 
        linestyle='--', label='GA Population Average', alpha=0.6)

# SA already ran - use those results (pad to same length for comparison)
sa_iterations = range(len(best_costs))
ax.plot(sa_iterations, best_costs, color=BRAND_COLORS["oneDark"], linewidth=3,
        label=f'SA Best (€{best_cost_sa:.0f})', alpha=0.9)

# Greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy Start (€{greedy_cost_value:.0f})', alpha=0.6)

ax.set_xlabel('Iteration / Generation', fontsize=14, fontweight='bold')
ax.set_ylabel('Best Cost Found (€)', fontsize=14, fontweight='bold')
ax.set_title('Genetic Algorithm vs Simulated Annealing\n(Same Restaurant Problem)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='best', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
GA maintains population diversity, SA explores single solution path!
:::

## GA Mistakes: Population Issues

[Avoid these population-related errors:]{.highlight}

. . .

**Mistake #1: Everyone Becomes Identical**

- If all solutions look the same → Lost diversity
- Fix: More mutation, bigger population, tournament selection

. . .

**Mistake #2: Too Greedy in Selection**

- Only keeping the very best → Premature convergence  
- Fix: Keep some variety, even if not perfect (elitism of 10-20%)

## GA Mistakes: Implementation

[Technical pitfalls to watch out for:]{.highlight}

. . .

**Mistake #3: Breaking the Rules**

- Crossover might create invalid schedules
- Fix: Always check and repair after crossover/mutation

. . .

**Mistake #4: Evolution Too Slow**

- Population too large or too many generations
- Fix: Start small (50-100), tune based on convergence

# [Metaheuristic #3: Tabu Search]{.flow} {.title}

## Core Idea

[Using memory to avoid cycling through bad solutions:]{.highlight}

::: columns
::: {.column width="50%"}
**Analogy:**

- Keep a list of recent dates
- "Not going back there!"
- Forces you to meet new people
- After time, memory fades
:::

::: {.column width="50%"}
**In Optimization:**

- Recent solutions = "tabu"
- Don't revisit same schedules
- Forces exploration of new areas
- Tabu list has limited size
:::
:::

. . .

::: {.callout-tip}
Like keeping "lessons learned", you remember not to use them again, but after a while, you might reconsider!
:::

## Concept

[How Tabu Search Works (Pseudocode)]{.highlight}

```python
def tabu_search_concept():
    tabu_list = []  # Our "never again" list
    current_solution = initial_schedule
    best_solution = current_solution
    
    while not done:
        # Look at all possible moves
        possible_moves = get_all_neighbor_moves(current_solution)
        
        # Filter out the "forbidden" moves
        allowed_moves = []
        for move in possible_moves:
            if move not in tabu_list:  # Not forbidden
                allowed_moves.append(move)
        
        # Pick the best allowed move (even if worse!)
        best_move = select_best(allowed_moves)
        current_solution = apply(best_move)
        
        # Update best if improved
        if cost(current_solution) < cost(best_solution):
            best_solution = current_solution
        
        # Remember this move (add to tabu list)
        tabu_list.append(best_move)
        if len(tabu_list) > 10:  # Keep list size manageable
            tabu_list.pop(0)  # Forget oldest
    
    return best_solution
```

## Tabu Search on Restaurant Problem

[Real implementation with memory-based exploration:]{.highlight}

```{python}
#| echo: false
#| eval: true

def get_all_neighbors(schedule, sample_size=20):
    """Generate multiple neighbor solutions"""
    neighbors = []
    for _ in range(sample_size):
        neighbors.append(make_neighbor(schedule))
    return neighbors

def schedule_to_tuple(schedule):
    """Convert schedule to hashable tuple for tabu list"""
    return tuple(tuple(shift) for shift in schedule)

def tabu_search(initial_schedule, max_iterations=150, tabu_tenure=15):
    """Tabu Search with short-term memory"""
    current = [shift[:] for shift in initial_schedule]
    current_cost = calculate_cost(current)[0]
    
    best = [shift[:] for shift in current]
    best_cost = current_cost
    
    tabu_list = []
    cost_history = [current_cost]
    best_history = [best_cost]
    
    random.seed(42)
    
    for iteration in range(max_iterations):
        # Generate neighbors
        neighbors = get_all_neighbors(current, sample_size=20)
        
        # Evaluate and filter by tabu status
        best_neighbor = None
        best_neighbor_cost = float('inf')
        
        for neighbor in neighbors:
            neighbor_tuple = schedule_to_tuple(neighbor)
            neighbor_cost = calculate_cost(neighbor)[0]
            
            # Aspiration criterion: accept tabu move if it's better than best ever
            if neighbor_tuple not in tabu_list or neighbor_cost < best_cost:
                if neighbor_cost < best_neighbor_cost:
                    best_neighbor = neighbor
                    best_neighbor_cost = neighbor_cost
        
        # Move to best allowed neighbor (even if worse!)
        if best_neighbor is not None:
            current = best_neighbor
            current_cost = best_neighbor_cost
            
            # Add to tabu list
            tabu_list.append(schedule_to_tuple(current))
            if len(tabu_list) > tabu_tenure:
                tabu_list.pop(0)
            
            # Update best
            if current_cost < best_cost:
                best = [shift[:] for shift in current]
                best_cost = current_cost
        
        cost_history.append(current_cost)
        best_history.append(best_cost)
    
    return best, best_cost, cost_history, best_history

# Run Tabu Search
np.random.seed(42)
random.seed(42)
tabu_best, tabu_best_cost, tabu_costs, tabu_best_hist = tabu_search(
    greedy_schedule, max_iterations=150, tabu_tenure=15
)

# Visualize Tabu Search performance
fig, ax = plt.subplots(1, 1)

iterations = list(range(len(tabu_costs)))
ax.plot(iterations, tabu_costs, color=BRAND_COLORS["twoLight"], linewidth=1, 
        alpha=0.5, label='Tabu Current Solution')
ax.plot(iterations, tabu_best_hist, color=BRAND_COLORS["oneDark"], linewidth=3,
        label=f'Tabu Best (€{tabu_best_cost:.0f})', alpha=0.9)

# Add greedy baseline and SA/GA results for comparison
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy (€{greedy_cost_value:.0f})', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Cost (€)', fontsize=14, fontweight='bold')
ax.set_title('Tabu Search on Restaurant Staffing Problem\n(Memory prevents cycling back to poor solutions)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Tabu Search's memory prevents revisiting bad solutions!
:::

# [Metaheuristic #4: Ant Colony Optimization]{.flow} {.title}

## The Core Idea

[Collective intelligence through chemical signals:]{.highlight}

::: columns
::: {.column width="50%"}
**Reviews:**

- Popular choices get more 5-star reviews
- More reviews → more visibility
- But old reviews fade over time
- New patterns can emerge
:::

::: {.column width="50%"}
**In Optimization:**

- Good assignments get "pheromones"
- Stronger choosen more likely
- Evaporation against stagnation
- Colony finds patterns
:::
:::

::: {.callout-tip}
Imagine each server-shift pairing has a "rating" that increases when it works well in a schedule. Over time, the best pairings naturally get chosen more often!
:::

## How ACO Works on Scheduling

[Four key stages in each iteration:]{.highlight}

::: incremental
1. **Construction:** Each ant builds a schedule probabilistically
2. **Evaluation & Evaporation:** Measure quality, then fade all pheromones
3. **Reinforcement:** Good schedules deposit pheromones
4. **Evolution:** Repeat until colony converges
:::

. . .

::: callout-tip
Let's see each stage visually!
:::

## ACO: Key Parameters

[Two critical parameters control the balance:]{.highlight}

::: columns
::: {.column width="50%"}
**Evaporation Rate (ρ)**

- Higher ρ → More forgetting
- Lower ρ → Stronger memory
- Typical: 0.1 - 0.5
- **Too high**: Colony never learns
- **Too low**: Gets stuck early
:::

::: {.column width="50%"}
**Number of Ants**

- More ants → More exploration
- Fewer ants → Faster iterations
- Typical: 10 - 50
- **Too many**: Slow, redundant
- **Too few**: Miss good patterns
:::
:::

. . .

::: {.callout-tip}
Start with ρ=0.3 and n_ants=20, then tune based on problem size.
:::

## Stage 1: Pheromone Construction

[Ants don't pick randomly, they follow the chemical trails]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS
setup_clean_style()

# Simulate pheromone strengths for visualization
servers = ['E1', 'E2', 'E3', 'E4', 'J1', 'J2', 'J3', 'J4']
shifts_short = ['Fri\nDinner', 'Fri\nLate', 'Sat\nLunch', 'Sat\nDinner', 'Sun\nLunch', 'Sun\nDinner']

# Create pheromone matrix (higher = stronger signal)
np.random.seed(42)
pheromone_matrix = np.random.uniform(0.5, 3.0, size=(len(servers), len(shifts_short)))

# Make experienced servers slightly preferred for high-penalty shifts
pheromone_matrix[0:4, [0, 3, 5]] *= 1.5  # E1-E4 preferred for Fri/Sat/Sun Dinner

fig, ax = plt.subplots()

# Create custom colormap using brand colors (light to dark progression)
from matplotlib.colors import LinearSegmentedColormap
brand_cmap = LinearSegmentedColormap.from_list(
    'brand_gradient',
    [BRAND_COLORS["lighter"], BRAND_COLORS["oneLight"], BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"]],
    N=256
)

# Create heatmap
im = ax.imshow(pheromone_matrix, cmap=brand_cmap, aspect='auto', vmin=0, vmax=4)

# Add colorbar
cbar = plt.colorbar(im, ax=ax)
cbar.set_label('Pheromone Strength\n(Higher = More Attractive)', 
               rotation=270, labelpad=25, fontsize=12, fontweight='bold')

# Set ticks
ax.set_xticks(range(len(shifts_short)))
ax.set_yticks(range(len(servers)))
ax.set_xticklabels(shifts_short, fontsize=11)
ax.set_yticklabels(servers, fontsize=11)

# Add values
for i in range(len(servers)):
    for j in range(len(shifts_short)):
        text = ax.text(j, i, f'{pheromone_matrix[i, j]:.1f}',
                      ha="center", va="center", color="black", fontsize=9,
                      fontweight='bold' if pheromone_matrix[i, j] > 2.5 else 'normal')

# Highlight one ant's probabilistic choice for Sat Dinner
sat_dinner_idx = 3
ax.add_patch(plt.Rectangle((sat_dinner_idx - 0.5, -0.5), 1, len(servers), 
                          fill=False, edgecolor=BRAND_COLORS["threeDark"], linewidth=4))

ax.set_xlabel('Shifts', fontsize=13, fontweight='bold')
ax.set_ylabel('Servers', fontsize=13, fontweight='bold')
ax.set_title('ACO Stage 1: Pheromone Matrix Guides Construction\n(Each ant probabilistically selects servers based on pheromone strength)', 
             fontsize=14, fontweight='bold', pad=15)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
To build the initial pheromone matrix, each cell is initialized with a small positive value.
:::

## Stage 2: Evaluation & Evaporation

[After all ants build schedules:]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, (ax1, ax2) = plt.subplots(1, 2)

# Left: Ant solutions distribution
n_ants = 20
ant_costs = np.random.normal(4200, 300, n_ants)
ant_costs = np.clip(ant_costs, 3600, 4800)
ant_costs = sorted(ant_costs)

colors = [BRAND_COLORS["threeDark"] if cost < 3900 else 
          BRAND_COLORS["oneDark"] if cost < 4200 else 
          BRAND_COLORS["darker"] for cost in ant_costs]

ax1.barh(range(n_ants), ant_costs, color=colors, alpha=0.8)
ax1.set_xlabel('Cost (€)', fontsize=12, fontweight='bold')
ax1.set_ylabel('Ant #', fontsize=12, fontweight='bold')
ax1.set_title('EVALUATION\nAll 20 ants build schedules', fontsize=12, fontweight='bold')
ax1.grid(True, alpha=0.3, axis='x')

# Right: Evaporation visualization
evaporation_rate = 0.3
before_levels = [3.0, 2.5, 1.8, 1.2, 0.8]
after_levels = [x * (1 - evaporation_rate) for x in before_levels]

x_pos = np.arange(len(before_levels))
width = 0.35

ax2.bar(x_pos - width/2, before_levels, width, label='Before Evaporation',
        color=BRAND_COLORS["oneLight"], alpha=0.9, edgecolor='black', linewidth=1.5)
ax2.bar(x_pos + width/2, after_levels, width, label='After Evaporation (ρ=0.3)',
        color=BRAND_COLORS["oneDark"], alpha=0.9, edgecolor='black', linewidth=1.5)

# Add arrows showing reduction
for i, (before, after) in enumerate(zip(before_levels, after_levels)):
    ax2.annotate('', xy=(i + width/2, after + 0.1), xytext=(i - width/2, before - 0.1),
                arrowprops=dict(arrowstyle='->', color='red', lw=2))

ax2.set_xlabel('Server-Shift Pairing', fontsize=12, fontweight='bold')
ax2.set_ylabel('Pheromone Level', fontsize=12, fontweight='bold')
ax2.set_title('EVAPORATION\nAll pheromones fade 30%', fontsize=12, fontweight='bold')
ax2.set_xticks(x_pos)
ax2.set_xticklabels(['E1-Fri\nDinner', 'E2-Sat\nDinner', 'J1-Fri\nLate', 'J3-Sun\nLunch', 'J5-Sun\nDinner'], 
                    fontsize=9)
ax2.legend(fontsize=10, loc='upper right')
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Evaporation prevents premature convergence as old patterns can fade away!
:::

## Stage 3: Reinforcement

[Good ants deposit more pheromones:]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots()

# Three ants with different quality
ant_data = [
    {'id': 'Ant #7', 'cost': 3800, 'deposit': 0.42, 'color': BRAND_COLORS["threeDark"]},
    {'id': 'Ant #12', 'cost': 4100, 'deposit': 0.36, 'color': BRAND_COLORS["oneDark"]},
    {'id': 'Ant #18', 'cost': 4400, 'deposit': 0.29, 'color': BRAND_COLORS["darker"]},
]

# Show pheromone deposits for one pairing
pairing_name = "E1 → Sat Dinner"
y_positions = [2, 1, 0]

for i, (ant, y_pos) in enumerate(zip(ant_data, y_positions)):
    # Bar showing deposit amount
    ax.barh(y_pos, ant['deposit'], color=ant['color'], alpha=0.8, height=0.6,
           edgecolor='black', linewidth=2)
    
    # Ant emoji and label
    ax.text(0.5, y_pos, f"{ant['id']}\n€{ant['cost']}", fontsize=10, 
           ha='right', va='center', fontweight='bold')
    
    # Deposit value
    ax.text(ant['deposit'] + 0.01, y_pos, f"+{ant['deposit']:.2f}", 
           fontsize=11, va='center', fontweight='bold', color=ant['color'])

# Formula annotation
ax.text(0.21, -1.5, 'Deposit Formula: Δτ = Q / cost\n(Q=1000, so better solutions deposit more)', 
       fontsize=11, ha='center', style='italic')

ax.set_xlabel('Pheromone Deposited', fontsize=13, fontweight='bold')
ax.set_title(f'ACO Stage 3: Reinforcement', 
            fontsize=14, fontweight='bold', pad=15)
ax.set_yticks([])
ax.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()
```

[The best solutions leave the strongest trails for future iterations!]{.highlight}

## Stage 4: Evolution Over Iterations

[Full ACO implementation on restaurant staffing:]{.highlight}

```{python}
#| echo: false
#| eval: true

def ant_colony_optimization(n_ants=20, n_iterations=100, evaporation=0.5, alpha=1.0, beta=2.0):
    """
    ACO adapted for scheduling problem
    Pheromones represent desirability of server-shift assignments
    """
    # Initialize pheromones for each (server, shift) pair
    servers = list(COSTS.keys())
    shifts = list(SHIFTS.keys())
    pheromones = {}
    for server in servers:
        for shift_idx in range(len(shifts)):
            pheromones[(server, shift_idx)] = 1.0
    
    best_schedule = None
    best_cost = float('inf')
    cost_history = []
    avg_history = []  # Track average colony cost in each iteration
    
    random.seed(42)
    np.random.seed(42)
    
    for iteration in range(n_iterations):
        # Each ant constructs a solution
        iteration_schedules = []
        iteration_costs = []
        
        for ant in range(n_ants):
            # Construct schedule shift by shift
            available_servers = servers[:]
            schedule = []
            
            for shift_idx in range(len(shifts)):
                # Select 2 servers for this shift based on pheromones
                shift_servers = []
                
                for _ in range(2):
                    if not available_servers:
                        break
                    
                    # Calculate probabilities based on pheromones and heuristic
                    probabilities = []
                    for server in available_servers:
                        pheromone = pheromones[(server, shift_idx)]
                        # Heuristic: prefer experienced servers for high-penalty shifts
                        is_exp = 1 if server.startswith('E') else 0
                        penalty = SHIFTS[shifts[shift_idx]]['penalty']
                        heuristic = 1 + (is_exp * penalty / 1000)  # Higher for exp + high penalty
                        
                        prob = (pheromone ** alpha) * (heuristic ** beta)
                        probabilities.append(prob)
                    
                    # Normalize probabilities
                    total = sum(probabilities)
                    if total > 0:
                        probabilities = [p / total for p in probabilities]
                    else:
                        probabilities = [1/len(available_servers)] * len(available_servers)
                    
                    # Select server
                    selected_server = np.random.choice(available_servers, p=probabilities)
                    shift_servers.append(selected_server)
                    available_servers.remove(selected_server)
                
                schedule.append(shift_servers)
            
            # Evaluate solution
            cost = calculate_cost(schedule)[0]
            iteration_schedules.append(schedule)
            iteration_costs.append(cost)
            
            # Track best
            if cost < best_cost:
                best_schedule = [shift[:] for shift in schedule]
                best_cost = cost
        
        # Track best and average in this iteration
        cost_history.append(best_cost)
        avg_history.append(np.mean(iteration_costs))
        
        # Evaporate pheromones
        for key in pheromones:
            pheromones[key] *= (1 - evaporation)
        
        # Deposit pheromones (stronger for better solutions)
        for schedule, cost in zip(iteration_schedules, iteration_costs):
            deposit_amount = 1000 / cost  # Better solutions deposit more
            for shift_idx, servers_in_shift in enumerate(schedule):
                for server in servers_in_shift:
                    pheromones[(server, shift_idx)] += deposit_amount
    
    return best_schedule, best_cost, cost_history, avg_history

# Run ACO
np.random.seed(42)
random.seed(42)
aco_best, aco_best_cost, aco_history, aco_avg_history = ant_colony_optimization(
    n_ants=20, n_iterations=500, evaporation=0.3, alpha=1.0, beta=2.0
)

# Visualize ACO convergence with phase annotations
fig, ax = plt.subplots(1, 1)

iterations = list(range(len(aco_history)))

# Plot best and average (like GA visualization)
ax.plot(iterations, aco_history, color=BRAND_COLORS["threeDark"], linewidth=3,
        label=f'Best Ant (€{aco_best_cost:.0f})', alpha=0.9, zorder=3)
ax.plot(iterations, aco_avg_history, color=BRAND_COLORS["threeLight"], linewidth=2,
        label=f'Colony Average', alpha=0.7, linestyle='--', zorder=2)

# Phase annotations (similar to GA style)
ax.axvspan(0, 125, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(125, 300, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(300, 500, alpha=0.1, color=BRAND_COLORS["twoDark"])

ax.text(62, max(aco_avg_history)*0.98, 'EXPLORATION\nHigh diversity, trails forming', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["threeDark"])
ax.text(212, max(aco_avg_history)*0.98, 'INTENSIFICATION\nAverage improves, strong trails', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["oneDark"])
ax.text(400, max(aco_avg_history)*0.98, 'CONVERGENCE\nColony consensus', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["twoDark"])

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Cost (€)', fontsize=14, fontweight='bold')
ax.set_title('ACO Stage 4: Evolution Through Collective Learning\n(Average colony performance improves as pheromones strengthen)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
The colony learns collectively step by step.
:::

## ACO vs Other Algorithms

[How does the ant colony compare?]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(1, 1)

# Plot all algorithms
iterations_sa = list(range(len(best_costs)))
iterations_ga = list(range(len(ga_best_hist)))
iterations_aco = list(range(len(aco_history)))

ax.plot(iterations_sa, best_costs, color=BRAND_COLORS["twoDark"], linewidth=2.5,
        label=f'SA (€{best_cost_sa:.0f})', alpha=0.85)
ax.plot(iterations_ga, ga_best_hist, color=BRAND_COLORS["oneDark"], linewidth=2.5,
        label=f'GA (€{ga_best_cost:.0f})', alpha=0.85)
ax.plot(iterations_aco, aco_history, color=BRAND_COLORS["threeDark"], linewidth=2.5,
        label=f'ACO (€{aco_best_cost:.0f})', alpha=0.85)

# Add greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy (€{greedy_cost_value:.0f})', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Best Cost Found (€)', fontsize=14, fontweight='bold')
ax.set_title('ACO vs SA vs GA on Restaurant Staffing\n(Three different search philosophies, one problem)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Any idea why ACO fares worse?
:::

# [Decision Framework]{.flow} {.title}

## When to Use Which Metaheuristic?

[A decision guide for algorithm selection:]{.highlight}

```{python}
#| echo: false
#| eval: true

import pandas as pd

# Create comprehensive comparison table
comparison_data = {
    'Method': ['Random', 'Greedy', 'LS', 'SA', 
               'GA', 'TS', 'ACO'],
    'Time': ['xxxx', 'xxx', 'xx', 'xx', 'x', 'xx', 'x'],
    'Quality': ['x', 'xx', 'xxx', 'xxxx', 'xxxx', 'xxx', 'xxxx'],
    'Complexity': ['Trivial', 'Simple', 'Medium', 'Medium', 'High', 'Medium', 'High'],
    'Best For': ['Baseline', 'Quick decisions', 'Improvement', 'Single solution',
                 'Population', 'Avoid cycles', 'Paths'],
}

df = pd.DataFrame(comparison_data)

# Style the dataframe
styled_df = df.style.set_properties(**{
    'text-align': 'center',
    'font-size': '11pt',
})

from IPython.display import HTML, display
display(HTML(df.to_html(index=False, classes='table table-striped')))
```

## The No Free Lunch Theorem

[Why there's no universal best algorithm:]{.highlight}

**"No Free Lunch Theorem":** No single algorithm is best for all problems. Your choice must match your problem structure:

- **Path/Network Problems** → ACO (pheromones for paths)
- **Scheduling Problems** → SA or Tabu (neighborhood swaps)
- **Complex Design** → GA (population diversity)


## Implementation Strategy

[Guidelines for successful implementation:]{.highlight}

::: {.incremental}
1. **Start Simple**: Always try greedy first as baseline
2. **Profile Your Problem**: Understand constraints before choosing
3. **Tune Incrementally**: Don't optimize all parameters at once
4. **Track Progress**: Monitor convergence to know when to stop
5. **Hybrid Approaches**: Combine methods (e.g., GA + Local Search)
6. **Use AI Assistance**: Bridge the "knowledge gap" with GenAI
:::

# [Today's Briefing]{.flow} {.title}

## Today

:::: columns
::: {.column width="33%"}
**Hour 2: This Lecture**

- Metaheuristics
- Simulated annealing
- Genetic algorithms
- Tabu search & ACO
:::

::: {.column width="33%"}
**Hour 3: Notebook**

- Bean Counter delivery
- Implement SA & GA
- Tune parameters
- Compare performance
:::

::: {.column width="33%"}
**Hour 4: Competition**

- Restaurant staffing
- Multi-objective
- Schedule optimization
- Justify choice!
:::
::::

## The Competition Challenge

[La Étoile Restaurant Weekend Staffing]{.highlight}

. . .

1. **Schedule** 18 servers across 6 shifts (different lengths)
2. **Minimize** labor + experience penalties + preference costs
3. **Ensure** experienced coverage (strategic placement)
4. **Respect** 2 servers per shift requirement

. . .

:::{.callout-important}
Choose your metaheuristic wisely as this is a tough problem!
:::

## Implementation Pitfalls to Avoid

[Common bugs that cost you time:]{.highlight}

::: incremental
1. **Wrong Cooling Schedule (SA)**
   - Too fast = stuck in local optimum
   - Too slow = wastes computation time
2. **Poor Population Management (GA)**
   - Too small = no diversity
   - Too large = slow evolution
4. **Not Tracking Best**
   - Current solution ≠ best ever found
:::

## Parameter Tuning Strategies

[How to find good parameters without wasting time:]{.highlight}

::: incremental
1. **Start with Rules of Thumb**
   - SA: Initial temp = max cost difference you'd accept
   - GA: Population = 10-20× number of decision variables
   - Tabu: Tenure (limit) = √(problem size)
   
2. **Grid Search on Small Instance**
   - Test 3-4 values per parameter
   - Use 10% of full dataset
   - Example: `temps = [100, 500]`, `cooling = [0.95, 0.99]`
:::

## Real-World Considerations

[Technical realities when putting metaheuristics into production:]{.highlight}

| Factor | Questions to Ask |
|--------|-----------------|
| **Time Budget** | How long can optimization run? |
| **Solution Quality** | Need optimal or "good enough"? |
| **Explainability** | Must justify decisions? |
| **Problem Changes** | Static or dynamic data? |
| **Team Skills** | Who maintains this code? |

. . .

:::{.callout-important}
Use the **simplest method** that meets your quality target. Complex metaheuristics are great but more costly to maintain!
:::

## Summary

[Key Takeaways:]{.highlight}

::: incremental
- Metaheuristics escape local optima when exact methods fail
- SA uses temperature, GA uses evolution, Tabu uses memory
- Parameter tuning is critical for performance
- No universal best - problem structure matters
- Start simple, add complexity only if needed
:::

## Break!

[Take 20 minutes, then we start the practice notebook]{.highlight}

**Next up:** You'll implement metaheuristics for Bean Counter
