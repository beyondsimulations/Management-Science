---
title: "Introduction to Metaheuristics"
subtitle: "Lecture 9 - Management Science"
author: "Dr. Tobias Vlćek"
format:
  revealjs:
    footer: " {{< meta title >}} | {{< meta author >}} | [Home](lec_09_metaheuristics.qmd)"
    output-file: lec_09_presentation.html
---

# [Introduction]{.flow} {.title}

## **[Client Briefing: La Étoile]{.invert-font}** {background-image="https://unsplash.com/photos/N_Y88TWmGwA/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8Mnx8ZmluZSUyMGRpbmluZ3xlbnwwfHx8fDE3NjM3OTIzNjZ8MA&force=true&w=2400" background-size="cover"}

. . .

[Restaurant Manager's Crisis:]{.invert-font}

["I need to schedule my [18 servers across 6 shifts]{.highlight} this weekend. Shifts have [different lengths (4-6 hours)]{.highlight}, and if I don't have enough experienced servers on busy shifts, we face [penalties ranging from €150 to €400]{.highlight} per missing experienced server from our parent company!"]{.invert-font .fragment}

## The Staffing Challenge

[A restaurant facing a weekend scheduling crisis:]{.highlight}

**La Étoile's Problem:**

::: {.incremental}
- 18 servers available (6 experienced @ €75/hr, 12 junior @ €25/hr)
- 6 shifts with **varying lengths** (4-6 hours each)
- Each shift needs 3 servers (at least 1 experienced)
- Server **preferences** matter (1-10 scale, affects quality)
:::

. . .

[Question:]{.question} How to balance labor costs, penalties, AND staff?

## The Cost Impact: Why This Matters

[The financial stakes are significant with these large penalties:]{.highlight}

::: {.incremental}
- **Minimum Labor Cost**: ~€3,500 (everyone works once)
- **Experience Penalties**: €0-€1,200 per missing experienced server
- **Preference Penalties**: €0-€180 per unhappy assignment
- **Worst Case**: Over €7,000 if poorly scheduled!
- **Best Case**: ??? with smart optimization
:::

. . .

:::{.callout-important}
Potentially up to **€3,500 difference** between good and bad scheduling!
:::

## Restaurant Staffing: The Numbers

[The real-world complexity we're dealing with:]{.highlight}

```{python}
#| echo: false
#| eval: true

import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, create_plot, BRAND_COLORS, PLOT_COLORS

# Apply clean brand style
setup_clean_style()

# Calculate the combinatorial explosion
from math import comb

# Problem parameters with new complexity
n_servers = 18
n_shifts = 6
servers_per_shift = 3
shift_hours = [5, 4, 4, 6, 5, 6]  # Varying shift lengths
penalties = [800, 0, 500, 1200, 600, 1000]  # Large penalties per shift

# Calculate possibilities
ways_per_shift = comb(18, 3)
total_ways = ways_per_shift ** 6

# Create visualization
fig, axes = plt.subplots(1, 3)

# Left: Shift complexity
ax = axes[0]
shift_names = ['Fri D', 'Fri L', 'Sat L', 'Sat D', 'Sun L', 'Sun D']
x = range(len(shift_names))
width = 0.35
bars1 = ax.bar([i - width/2 for i in x], shift_hours, width, 
               label='Hours', color=BRAND_COLORS["oneDark"], alpha=0.7)
bars2 = ax.bar([i + width/2 for i in x], [p/100 for p in penalties], width,
               label='Penalty (€100s)', color=BRAND_COLORS["threeDark"], alpha=0.7)
ax.set_xlabel('Shift', fontsize=12)
ax.set_ylabel('Value', fontsize=12)
ax.set_title('Varying Complexity by Shift', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(shift_names)

# Add value labels
for bar, val in zip(bars1, shift_hours):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{val}h', ha='center', va='bottom', fontsize=10, fontweight='bold')
for bar, val in zip(bars2, penalties):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=10, fontweight='bold')

# Middle: Constraint satisfaction
ax = axes[1]
categories = ['Total\nServers', 'Experienced\nNeeded', 'Experienced\nAvailable']
values = [18, 8, 6]
colors = [BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"]]
bars = ax.bar(categories, values, color=colors, alpha=0.7)
ax.set_ylabel('Count', fontsize=12)
ax.set_title('The Constraint Violation', fontsize=14, fontweight='bold')
ax.axhline(y=6, color='red', linestyle='--', linewidth=2, alpha=0.5)
ax.text(1, 6.5, 'Shortage!', ha='center', fontsize=11, color='red', fontweight='bold')

# Add value labels on bars
for bar, val in zip(bars, values):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

# Right: Three cost components
ax = axes[2]
components = ['Labor\nCost', 'Experience\nPenalties', 'Preference\nPenalties']
typical_costs = [3500, 1600, 800]  # Typical costs in euros
colors = [BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"], BRAND_COLORS["threeDark"]]
bars = ax.bar(components, typical_costs, color=colors, alpha=0.7)
ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('Three-Way Cost Optimization', fontsize=14, fontweight='bold')

# Add value labels
for bar, val in zip(bars, typical_costs):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
```

. . .

::: callout-warning
With varying shifts, preferences, and penalties, this is will be a real challenge!
:::

## Today's Objectives

[What you'll understand after this lecture:]{.highlight}

::: {.incremental}
1. **Why local search fails:** Recap on the local optima trap
2. **Escape mechanisms:** How to accept worse solutions strategically
3. **Four powerful metaheuristics:** SA, GA, Tabu Search, ACO
4. **Selection criteria:** When to use which algorithm
:::

## Hiking in Fog

[Remember the metaphor with blindfolded eyes from last lecture?]{.highlight}

::: incremental
- **Goal**: Find the highest peak in a mountain range
- **Challenge**: You're hiking in thick fog (can only see 10 meters)
- **Position**: Your X,Y coordinates = your decisions
- **Altitude**: Your current solution quality
- **Problem**: You might climb a small hill and think it's the summit!
:::

. . .

::: callout-tip
This metaphor will guide us through all metaheuristics today!
:::

## Recap: Local Optima

[Real problems often have thousands of local optima!]{.highlight}

```{python}
#| eval: true
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.append('../helpers')
from plot_utils import BRAND_COLORS, setup_clean_style

setup_clean_style()

# Create a complex optimization landscape with many local optima
fig, ax = plt.subplots()

x = np.linspace(0, 20, 1000)
# Build a complex function with many peaks and valleys
# Start with a base trend
y = 5 + 0.1*x
# Add multiple sine/cosine waves of different frequencies
y += 1.5*np.sin(0.5*x)  # Long wavelength
y += 0.8*np.sin(2*x)     # Medium wavelength
y += 0.4*np.sin(5*x)     # Short wavelength
y += 0.3*np.cos(8*x)     # Even shorter
y += 0.2*np.sin(12*x)    # Very short wavelength
# Add some Gaussian valleys for local minima
y -= 0.8*np.exp(-(x-3)**2/0.3)   # Small local minimum
y -= 1.2*np.exp(-(x-7)**2/0.4)   # Medium local minimum
y -= 0.9*np.exp(-(x-11)**2/0.3)  # Another local minimum
y -= 5*np.exp(-(x-16)**2/0.5)    # Deep global minimum

ax.plot(x, y, color=BRAND_COLORS["twoDark"], linewidth=2, alpha=0.8)

# Find and mark several local minima
local_minima_x = [2.0, 7.27, 11.34, 13.55]
local_minima_labels = ['Local 1', 'Local 2', 'Local 3', 'Local 4']

for x_loc, label in zip(local_minima_x, local_minima_labels):
    y_loc = 5 + 0.1*x_loc
    y_loc += 1.5*np.sin(0.5*x_loc) + 0.8*np.sin(2*x_loc) + 0.4*np.sin(5*x_loc)
    y_loc += 0.3*np.cos(8*x_loc) + 0.2*np.sin(12*x_loc)
    y_loc -= 0.8*np.exp(-(x_loc-3)**2/0.3)
    y_loc -= 1.2*np.exp(-(x_loc-7)**2/0.4)
    y_loc -= 0.9*np.exp(-(x_loc-11)**2/0.3)
    y_loc -= 5*np.exp(-(x_loc-16)**2/0.5)

    ax.scatter([x_loc], [y_loc], color=BRAND_COLORS["threeDark"], s=200, zorder=3)

# Mark the global minimum
x_global = 16.05
y_global = 5 + 0.1*x_global
y_global += 1.5*np.sin(0.5*x_global) + 0.8*np.sin(2*x_global) + 0.4*np.sin(5*x_global)
y_global += 0.3*np.cos(8*x_global) + 0.2*np.sin(12*x_global)
y_global -= 0.8*np.exp(-(x_global-3)**2/0.3)
y_global -= 1.2*np.exp(-(x_global-7)**2/0.4)
y_global -= 0.9*np.exp(-(x_global-11)**2/0.3)
y_global -= 5*np.exp(-(x_global-16)**2/0.5)

ax.scatter([x_global], [y_global], color=BRAND_COLORS["oneDark"], s=200, zorder=4)
ax.annotate('GLOBAL\nMINIMUM', xy=(x_global, y_global), xytext=(x_global, y_global - 2),
            fontsize=11, ha='center', fontweight='bold',
            arrowprops=dict(arrowstyle='->', color=BRAND_COLORS["oneDark"], lw=2))

# Add shaded regions to show quality differences
ax.axhspan(ymin=ax.get_ylim()[0], ymax=y_global + 0.5, alpha=0.1, color='green', label='Excellent')
ax.axhspan(ymin=y_global + 0.5, ymax=4, alpha=0.1, color='yellow', label='Good')
ax.axhspan(ymin=4, ymax=6, alpha=0.1, color='orange', label='Mediocre')
ax.axhspan(ymin=6, ymax=ax.get_ylim()[1], alpha=0.1, color='red', label='Poor')

ax.set_xlabel('Solution Space (Different Route Configurations)', fontsize=12)
ax.set_ylabel('Total Distance (km)', fontsize=12)
ax.grid(True, alpha=0.3)

# Add text box with key insight
plt.tight_layout()
plt.show()
```

. . .

[Question:]{.question} Any idea how to escape local optima?


# [Why Simple Methods Fail]{.flow} {.title}

## The Silo Problem

[Why neighborhood optimization fails:]{.highlight}

::: columns
::: {.column width="50%"}
**Technical View: Local Optima**

- Algorithm climbs nearest hill
- Gets stuck on "foothill"
- Can't see the mountain beyond
- Every move looks worse
- Believes it found the best
:::

::: {.column width="50%"}
**Analogy: Department Silos**

- Sales optimizes sales metrics
- Engineering optimizes quality
- Finance optimizes costs
- Each department "wins"
- **Company performance looses!**
:::
:::

. . .

::: {.callout-important}
Sum of local bests ≠ Global best
:::

## Why Greedy Gets Stuck

[Greedy algorithms can simply trap themselves:]{.highlight}

. . .

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Simulate greedy staffing
np.random.seed(42)

# Create schedule visualization
fig, axes = plt.subplots(1, 2)

# Left: Greedy assignment
ax = axes[0]
shifts = ['Fri L', 'Fri D', 'Sat L', 'Sat D', 'Sun L', 'Sun D']
experienced_assignment = [2, 1, 1, 1, 1, 0]  # Greedy uses best first
junior_assignment = [1, 2, 2, 2, 2, 3]

x = np.arange(len(shifts))
width = 0.35

bars1 = ax.bar(x - width/2, experienced_assignment, width, label='Experienced', 
               color=BRAND_COLORS["oneDark"], alpha=0.8)
bars2 = ax.bar(x + width/2, junior_assignment, width, label='Junior',
               color=BRAND_COLORS["twoLight"], alpha=0.8)

ax.set_xlabel('Shift', fontsize=12)
ax.set_ylabel('Servers Assigned', fontsize=12)
ax.set_title('Greedy Assignment (Front-loaded)', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(shifts)
ax.legend()
ax.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Min Experienced Required')

# Highlight problem
ax.add_patch(plt.Rectangle((4.5, -0.5), 1, 4, fill=True, 
                          color='red', alpha=0.2))
ax.text(5, 3.5, 'No experienced\nfor Sunday!', ha='center', fontsize=10, 
        color='red', fontweight='bold')

# Right: Cost breakdown
ax = axes[1]
costs = ['Labor\n(€1,140)', 'Penalty\n(€500)', 'Total\n(€1,640)']
values = [1140, 500, 1640]
colors = [BRAND_COLORS["twoLight"], BRAND_COLORS["threeDark"], BRAND_COLORS["darker"]]
bars = ax.bar(costs, values, color=colors, alpha=0.7)

for bar, val in zip(bars, values):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('Greedy Solution Cost', fontsize=14, fontweight='bold')
ax.grid(True, axis='y', alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-warning
Greedy allocates resources early, creating problems later!
:::

## Local Search Also Struggles

[Because we only ever accept better solutions during search:]{.highlight}

. . .

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Visualize local search getting stuck
fig, axes = plt.subplots(1, 2)

# Left: Solution landscape
ax = axes[0]
x = np.linspace(0, 10, 200)

# Define the cost function - more complex landscape with multiple local minima
def cost_func(x_val):
    return (1600 
            - 120*np.sin(x_val) 
            - 80*np.sin(2.5*x_val) 
            - 60*np.sin(4*x_val) 
            - 40*np.sin(6.5*x_val)
            + 15*np.cos(8*x_val))

y = cost_func(x)

ax.plot(x, y, color=BRAND_COLORS["twoDark"], linewidth=2, alpha=0.7)
ax.fill_between(x, 1200, y, alpha=0.1, color=BRAND_COLORS["twoLight"])

# Mark positions - compute actual y-values from the function
greedy_x = 4.8
greedy_y = cost_func(greedy_x)

# Find actual local minimum around x=4.8
from scipy.optimize import minimize_scalar
local_result = minimize_scalar(cost_func, bounds=(4.0, 6.0), method='bounded')
local_x = local_result.x
local_y = local_result.fun

# Find global minimum
global_result = minimize_scalar(cost_func, bounds=(0, 10), method='bounded')
global_x = global_result.x
global_y = global_result.fun

ax.scatter([greedy_x], [greedy_y], color=BRAND_COLORS["oneDark"], s=200, marker='o', zorder=5, label='Greedy Start')
ax.scatter([local_x], [local_y], color=BRAND_COLORS["threeDark"], s=200, marker='*', zorder=5, label='Local Optimum')
ax.scatter([global_x], [global_y], color=BRAND_COLORS["twoDark"], s=200, marker='*', zorder=5, label='Global Optimum')

# Show local search path
ax.arrow(greedy_x, greedy_y, local_x-greedy_x-0.1, local_y-greedy_y+5,
         head_width=0.2, head_length=5, fc=BRAND_COLORS["oneDark"], ec=BRAND_COLORS["oneDark"], alpha=0.7)

# Show barrier
ax.axvspan(local_x+0.5, global_x-0.5, alpha=0.2, color=BRAND_COLORS["darker"])
ax.text(6, 1700, 'Can\'t climb\nthis hill!', ha='center', fontsize=10, 
        color=BRAND_COLORS["threeDark"], fontweight='bold')

ax.set_xlabel('Solution Space', fontsize=12)
ax.set_ylabel('Total Cost (€)', fontsize=12)
ax.set_title('Local Search Trapped in Local Minimum', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# Right: Neighborhood structure
ax = axes[1]
# Create network of neighbors
from matplotlib.patches import Circle, FancyArrow

center = (0.5, 0.5)
neighbors = [(0.3, 0.7), (0.7, 0.7), (0.3, 0.3), (0.7, 0.3),
             (0.5, 0.8), (0.5, 0.2), (0.2, 0.5), (0.8, 0.5)]

# Draw center
circle = Circle(center, 0.08, color=BRAND_COLORS["twoDark"])
ax.add_patch(circle)
ax.text(center[0], center[1], 'Current\n€1520', ha='center', va='center', 
        fontsize=9, fontweight='bold', color='white')

# Draw neighbors
for i, (x, y) in enumerate(neighbors):
    cost = 1520 + np.random.randint(10, 100)
    circle = Circle((x, y), 0.06, color=BRAND_COLORS["threeLight"])
    ax.add_patch(circle)
    ax.text(x, y, f'€{cost}', ha='center', va='center', fontsize=8)
    
    # Draw edge
    ax.plot([center[0], x], [center[1], y], 'k-', alpha=0.1, linewidth=1)

ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_aspect('equal')
ax.axis('off')
ax.set_title('All Neighbors Worse → Stuck!', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()
```

. . .

[Question:]{.question} What can we do to cope with this situation?

# [Metaheuristic #1: Simulated Annealing]{.flow} {.title}

## Core Concepts

[The fundamental components:]{.highlight}

::: incremental
- **Solution** = One complete schedule/route/plan
- **Neighbor** = A slightly modified version
- **Cost** = How good/bad the solution is
:::

. . .

**The Strategy**

- Always accept improvements
- Sometimes accept worse solutions (the change!)

. . .

[Think of it as strategic risk-taking that decreases over time!]{.highlight}

## The Metallurgy Metaphor

[How annealing steel inspired an optimization algorithm:]{.highlight}

::: columns
::: {.column width="50%"}
**Annealing Metal:**

1. Heat to high temperature
2. Atoms move freely
3. Slowly cool down
4. Forms crystal structure
:::

::: {.column width="50%"}
**Optimization:**

1. Start with high "temperature"
2. Accept bad moves often
3. Gradually reduce temperature
4. Converge to good solution
:::
:::

. . .

::: callout-important
The willingness to temporarily accept worse solutions is what enables finding the summit!
:::

## Temperature Controls Acceptance

[Probability of accepting worse solutions lowers with temp:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(1, 1)

# Cost increases we might encounter (worse solutions)
delta_costs = np.linspace(0, 300, 200)

# Three temperature scenarios
temperatures = [500, 100, 10]
colors = [BRAND_COLORS["threeDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"]]
labels = ['HOT (T=500)', 
          'WARM (T=100)', 
          'COLD (T=10)']
alphas = [0.9, 0.7, 0.5]

for T, color, label, alpha in zip(temperatures, colors, labels, alphas):
    probabilities = np.exp(-delta_costs / T)
    ax.plot(delta_costs, probabilities, linewidth=4, color=color, label=label, alpha=alpha)

# Mark specific examples
example_cost = 150
for T, color in zip(temperatures, colors):
    prob = np.exp(-example_cost / T)
    ax.plot([example_cost], [prob], 'o', markersize=12, color=color, 
            markeredgewidth=2, markeredgecolor='white', zorder=5)
    ax.annotate(f'{prob:.0%}', xy=(example_cost, prob), 
                xytext=(example_cost + 30, prob + 0.05),
                fontsize=11, fontweight='bold', color=color,
                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor=color, linewidth=2),
                arrowprops=dict(arrowstyle='->', color=color, linewidth=2))

# Styling
ax.set_xlabel('Cost Increase (€)', fontsize=14)
ax.set_ylabel('Acceptance Probability', fontsize=14)
ax.set_title('Formula: P(accept) = exp(-Δcost / T)', 
             fontsize=16, fontweight='bold', pad=20)
ax.set_ylim(-0.05, 1.1)
ax.set_xlim(0, 300)
ax.grid(True, alpha=0.3, linestyle='--')
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)

# Add reference line
ax.axvline(x=example_cost, color='gray', linestyle=':', alpha=0.5, linewidth=2)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
We essentially compare the cost of the new schedule to the current cost and decide whether to accept the change based on the temperature and the difference in cost.
:::

## Concept

[How Simulated Annealing Works (Pseudocode)]{.highlight}

```python
def simulated_annealing_concept(current_schedule):
    temperature = 500  # Start "hot" (adventurous)
    best_schedule = current_schedule
    
    while temperature > 1:
        # Step 1: Try a random change (like swapping two shifts)
        new_schedule = make_random_change(current_schedule)
        
        # Step 2: Is it better?
        if cost(new_schedule) < cost(current_schedule):
            current_schedule = new_schedule  # Always accept improvements
        else:
            # NEW: Sometimes accept worse solutions!
            # Hot temperature = more likely to accept
            # Cold temperature = less likely to accept
            if random() < acceptance_probability(temperature):
                current_schedule = new_schedule  # Accept anyway!
        
        # Step 3: Cool down (become less adventurous)
        temperature = temperature * 0.95
        
        # Remember the best we've ever seen
        if cost(current_schedule) < cost(best_schedule):
            best_schedule = current_schedule
    
    return best_schedule
```

## SA in Action: Restaurant Staffing

[A simplified weekend scheduling problem we'll use throughout:]{.highlight}

```{python}
#| echo: true
#| eval: false

# SIMPLIFIED PROBLEM (used across ALL metaheuristics today)
"""
La Étoile's Weekend Challenge:
- 12 servers: 4 experienced (E1-E4), 8 junior (J1-J8)
- 6 shifts: Need 2 servers each
- Everyone works exactly 1 shift
"""
```

. . .

**The initial greedy schedule has the following results:**

. . .

```{python}
#| echo: false
#| eval: true
import numpy as np
import random

# Server costs (per shift, varying shift lengths!)
COSTS = {
    'E1': 375, 'E2': 375, 'E3': 300, 'E4': 300,  # Experienced: €75/hr × 4-5hr
    'J1': 100, 'J2': 100, 'J3': 125, 'J4': 125,  # Junior: €25/hr × 4-5hr
    'J5': 100, 'J6': 100, 'J7': 125, 'J8': 125
}

# Shift requirements & penalties (tighter constraints now!)
SHIFTS = {
    'Fri_Dinner': {'min_exp': 1, 'penalty': 500},
    'Fri_Late':   {'min_exp': 0, 'penalty': 0},
    'Sat_Lunch':  {'min_exp': 1, 'penalty': 400},
    'Sat_Dinner': {'min_exp': 2, 'penalty': 800},
    'Sun_Lunch':  {'min_exp': 1, 'penalty': 400},
    'Sun_Dinner': {'min_exp': 1, 'penalty': 600}
}

# Server preferences (1-10 scale, 10=loves this shift)
# More conflicting preferences to make optimization harder!
PREFERENCES = {
    'E1': [9, 2, 7, 8, 5, 6],  # Loves Fri dinner, hates Fri late
    'E2': [6, 4, 5, 9, 7, 8],  # Prefers Sat/Sun dinners
    'E3': [5, 8, 9, 4, 8, 5],  # Loves lunches and late shift
    'E4': [7, 3, 6, 7, 6, 9],  # Prefers Sun dinner
    'J1': [4, 7, 8, 3, 9, 5],  # Prefers lunches
    'J2': [8, 9, 5, 6, 4, 7],  # Loves late shifts
    'J3': [6, 5, 9, 4, 8, 6],  # Loves Sat lunch
    'J4': [7, 8, 6, 7, 5, 8],  # Flexible
    'J5': [5, 9, 4, 8, 6, 7],  # Loves Fri late, Sat dinner
    'J6': [9, 6, 7, 5, 8, 4],  # Loves Fri dinner
    'J7': [4, 7, 8, 6, 9, 5],  # Loves Sun lunch
    'J8': [6, 8, 5, 7, 6, 9]   # Prefers late/dinner shifts
}

def calculate_cost(schedule):
    """
    Schedule = [[shift1_servers], [shift2_servers], ...]
    Returns: (total_cost, labor, penalties, preference_cost)
    """
    labor_cost = 0
    penalty_cost = 0
    preference_cost = 0
    shift_names = list(SHIFTS.keys())
    
    for shift_idx, servers in enumerate(schedule):
        # Labor costs
        for server in servers:
            labor_cost += COSTS[server]
        
        # Experience penalties
        exp_count = sum(1 for s in servers if s.startswith('E'))
        min_exp = SHIFTS[shift_names[shift_idx]]['min_exp']
        if exp_count < min_exp:
            penalty_cost += SHIFTS[shift_names[shift_idx]]['penalty']
        
        # Preference penalties (unhappiness cost)
        for server in servers:
            pref = PREFERENCES[server][shift_idx]
            preference_cost += (10 - pref) * 30  # €30 per unhappiness point
    
    return labor_cost + penalty_cost + preference_cost, labor_cost, penalty_cost, preference_cost

# Example: Greedy schedule (assign cheapest available, ignoring preferences)
greedy_schedule = [
    ['J1', 'J2'],  # Fri Dinner (need 1 exp - PENALTY!)
    ['J3', 'J4'],  # Fri Late
    ['J5', 'J6'],  # Sat Lunch (need 1 exp - PENALTY!)
    ['J7', 'E1'],  # Sat Dinner (need 2 exp, only have 1 - PENALTY!)
    ['J8', 'E2'],  # Sun Lunch
    ['E3', 'E4']   # Sun Dinner
]

cost, labor, penalty, pref = calculate_cost(greedy_schedule)
print(f"Greedy Schedule Cost: €{cost:,.0f}")
print(f"  Labor: €{labor}, Penalties: €{penalty}, Unhappiness: €{pref}")
```

. . .

::: callout-tip
Let's see how Simulated Annealing can improve the solution!
:::

## Visualizing SA Performance

[How temperature affects the search behavior:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS
import math

# Apply clean brand style
setup_clean_style()

# Helper function: Make a neighbor by swapping two servers
def make_neighbor(schedule):
    """Swap two random servers from different shifts"""
    new_schedule = [shift[:] for shift in schedule]  # Deep copy
    
    # Pick two different shifts
    num_shifts = len(schedule)
    shift1, shift2 = random.sample(range(num_shifts), 2)
    # Pick random servers from each
    pos1, pos2 = random.randint(0, 1), random.randint(0, 1)
    
    # Swap them
    new_schedule[shift1][pos1], new_schedule[shift2][pos2] = \
        new_schedule[shift2][pos2], new_schedule[shift1][pos1]
    
    return new_schedule

# Simulated Annealing Implementation
def simulated_annealing(initial_schedule, max_iterations=500, initial_temp=1000, cooling_rate=0.99):
    """Run SA and track cost history"""
    current = [shift[:] for shift in initial_schedule]
    current_cost = calculate_cost(current)[0]
    
    best = [shift[:] for shift in current]
    best_cost = current_cost
    
    temperature = initial_temp
    cost_history = [current_cost]
    temp_history = [temperature]
    best_history = [best_cost]
    
    random.seed(42)
    
    for iteration in range(max_iterations):
        # Generate neighbor
        neighbor = make_neighbor(current)
        neighbor_cost = calculate_cost(neighbor)[0]
        
        # Acceptance criterion
        delta = neighbor_cost - current_cost
        
        if delta < 0:  # Better solution
            current = neighbor
            current_cost = neighbor_cost
        else:  # Worse solution - maybe accept
            acceptance_prob = math.exp(-delta / temperature) if temperature > 0 else 0
            if random.random() < acceptance_prob:
                current = neighbor
                current_cost = neighbor_cost
        
        # Track best ever seen
        if current_cost < best_cost:
            best = [shift[:] for shift in current]
            best_cost = current_cost
        
        # Cool down
        temperature *= cooling_rate
        
        # Record history
        cost_history.append(current_cost)
        temp_history.append(temperature)
        best_history.append(best_cost)
    
    return best, best_cost, cost_history, temp_history, best_history

# Run SA from greedy starting point
np.random.seed(42)
random.seed(42)
best_schedule, best_cost_sa, costs, temps, best_costs = simulated_annealing(greedy_schedule)

# Create visualization
fig, axes = plt.subplots(2, 1, sharex=True)

greedy_cost_value = calculate_cost(greedy_schedule)[0]
iterations = list(range(len(costs)))

# Top: Cost over time
ax = axes[0]
ax.axhline(y=greedy_cost_value, color=BRAND_COLORS["threeDark"], linestyle='--', 
           linewidth=2, label=f'Greedy Start', alpha=0.7)
ax.plot(iterations, costs, color=BRAND_COLORS["twoLight"], linewidth=2, 
        alpha=0.7, label='SA Current Solution')
ax.plot(iterations, best_costs, color=BRAND_COLORS["twoDark"], linewidth=2, 
        label=f'SA Best')
ax.set_ylabel('Total Cost (€)', fontsize=12)
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)

# Add annotations for phases
total_iters = len(iterations)
ax.axvspan(0, total_iters*0.3, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(total_iters*0.3, total_iters*0.7, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(total_iters*0.7, total_iters, alpha=0.1, color=BRAND_COLORS["twoDark"])

# Bottom: Temperature
ax = axes[1]
ax.plot(iterations, temps, color=BRAND_COLORS["twoDark"], linewidth=3)
ax.axvspan(0, total_iters*0.3, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(total_iters*0.3, total_iters*0.7, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(total_iters*0.7, total_iters, alpha=0.1, color=BRAND_COLORS["twoDark"])
ax.set_xlabel('Iteration', fontsize=12)
ax.set_ylabel('Temperature', fontsize=12)
ax.grid(True, alpha=0.3)

# Add phase labels
ax.text(total_iters*0.15, max(temps)*0.2, 'EXPLORE\n(Accept bad moves)', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["threeDark"])
ax.text(total_iters*0.5, max(temps)*0.2, 'TRANSITION\n(Balance)', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["oneDark"])
ax.text(total_iters*0.85, max(temps)*0.2, 'EXPLOIT\n(Refine best)', 
        ha='center', fontsize=10, fontweight='bold', color=BRAND_COLORS["twoDark"])

plt.tight_layout()
plt.show()
``` 

. . .

::: callout-important
See how SA accepts worse solutions early, enabling escape from local optima!
:::

## Common SA Mistakes

[Avoid these common implementation errors:]{.highlight}

. . .

**Mistake #1: Starting Too Cold**

- If temperature is too low → Acts like greedy (no exploration)
- Fix: Start hot enough to accept bad moves

. . .

**Mistake #2: Cooling Too Quickly**

- If you cool fast → Get stuck early
- Fix: Cool slowly (multiply by 0.95-0.99, not 0.5)

. . .

::: {.callout-warning}
Quick cooling is tempting for speed, but defeats the purpose of SA!
:::

## Temperature Parameter Impact

```{python}
#| echo: false
#| eval: true

# Compare different temperature settings
np.random.seed(42)

# Run SA with different parameters
configs = [
    {'name': 'Too Cold Start', 'temp': 100, 'cooling': 0.99, 'color': BRAND_COLORS["threeDark"]},
    {'name': 'Too Fast Cooling', 'temp': 1000, 'cooling': 0.1, 'color': BRAND_COLORS["oneDark"]},
    {'name': 'Good Balance', 'temp': 1000, 'cooling': 0.99, 'color': BRAND_COLORS["twoDark"]},
]

fig, ax = plt.subplots(1, 1)

greedy_cost_value = calculate_cost(greedy_schedule)[0]

for config in configs:
    random.seed(42)
    _, best_cost, costs, temps, best_costs = simulated_annealing(
        greedy_schedule, 
        max_iterations=500, 
        initial_temp=config['temp'], 
        cooling_rate=config['cooling']
    )
    
    iterations = list(range(len(best_costs)))
    ax.plot(iterations, best_costs, linewidth=3, color=config['color'], 
            label=f"{config['name']}: Final €{best_cost:.0f}", alpha=0.8)

# Add greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle='--', 
           linewidth=2, label=f'Greedy Baseline: €{greedy_cost_value:.0f}', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Best Cost Found (€)', fontsize=14, fontweight='bold')
ax.set_title('Impact of Temperature Parameters on SA Performance (Same problem, different settings)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='best', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
The "Good Balance" explores widely early, then refines carefully. Often you need to balance exploration and exploitation by experimenting with different parameters.
:::

# [Metaheuristic #2: Genetic Algorithms]{.flow} {.title}

## Evolution as Optimization

[How natural selection inspires computational optimization:]{.highlight}

::: columns
::: {.column width="50%"}
**Natural Selection:**

1. Population of individuals
2. Fittest survive & reproduce
3. Offspring inherit traits
4. Mutations create diversity
5. Evolution finds adaptation
:::

::: {.column width="50%"}
**Optimization:**

1. Population of solutions
2. Best solutions selected
3. Crossover combines solutions
4. Mutation adds variation
5. Evolution finds optimum
:::
:::

. . .

::: callout-tip
Just like successful products get more market share, better solutions get more "offspring" in the next generation. It's survival of the fittest, but for schedules, routes, or designs!
:::


```{python}
#| echo: false
#| eval: true

# Genetic Algorithm Implementation (run early so data is available for later slides)
def create_random_schedule():
    """Create a random valid schedule"""
    servers = list(COSTS.keys())
    random.shuffle(servers)
    return [servers[i:i+2] for i in range(0, 12, 2)]

def tournament_selection(population, pop_costs, tournament_size=3):
    """Select parent via tournament selection"""
    tournament = random.sample(list(zip(population, pop_costs)), tournament_size)
    return min(tournament, key=lambda x: x[1])[0]

def crossover(parent1, parent2):
    """Order crossover - maintain valid assignments"""
    # Flatten parents
    p1_flat = [s for shift in parent1 for s in shift]
    p2_flat = [s for shift in parent2 for s in shift]
    
    # Take first 3 shifts from parent1, fill rest from parent2
    child_flat = p1_flat[:6]  # First 3 shifts (6 servers)
    for server in p2_flat:
        if server not in child_flat:
            child_flat.append(server)
    
    # Reconstruct schedule
    return [child_flat[i:i+2] for i in range(0, 12, 2)]

def mutate(schedule, mutation_rate=0.2):
    """Swap two servers with some probability"""
    if random.random() < mutation_rate:
        return make_neighbor(schedule)
    return schedule

def genetic_algorithm(pop_size=20, generations=100, mutation_rate=0.2):
    """Run GA and track best/average fitness"""
    # Initialize population
    population = [create_random_schedule() for _ in range(pop_size)]
    
    best_history = []
    avg_history = []
    best_overall = None
    best_overall_cost = float('inf')
    
    random.seed(42)
    
    for gen in range(generations):
        # Evaluate fitness
        pop_costs = [calculate_cost(ind)[0] for ind in population]
        
        # Track statistics
        best_idx = np.argmin(pop_costs)
        best_history.append(pop_costs[best_idx])
        avg_history.append(np.mean(pop_costs))
        
        if pop_costs[best_idx] < best_overall_cost:
            best_overall = [shift[:] for shift in population[best_idx]]
            best_overall_cost = pop_costs[best_idx]
        
        # Create next generation
        new_population = []
        
        # Elitism: keep best 2
        sorted_pop = sorted(zip(population, pop_costs), key=lambda x: x[1])
        new_population.extend([ind for ind, _ in sorted_pop[:2]])
        
        # Generate offspring
        while len(new_population) < pop_size:
            parent1 = tournament_selection(population, pop_costs)
            parent2 = tournament_selection(population, pop_costs)
            child = crossover(parent1, parent2)
            child = mutate(child, mutation_rate)
            new_population.append(child)
        
        population = new_population
    
    return best_overall, best_overall_cost, best_history, avg_history

# Run GA
np.random.seed(42)
random.seed(42)
ga_best_schedule, ga_best_cost, ga_best_hist, ga_avg_hist = genetic_algorithm(
    pop_size=20, generations=500, mutation_rate=0.2
)

```

## The Genetic Process

[Four stages repeat each generation:]{.highlight}

::: columns
::: {.column width="50%"}
**1. Selection**  

Choose parents based on fitness

**2. Crossover**  

Combine to create children
:::

::: {.column width="50%"}
**3. Mutation**  

Randomly modify children

**4. Replacement**  

New generation replaces old
:::
:::

. . .

::: callout-tip
Let's see each stage in detail with our restaurant problem!
:::

## Stage 1: Selection (Tournament)

[How to choose which schedules get to "reproduce":]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Create realistic population costs
np.random.seed(42)
population_size = 20
costs = np.random.randint(3700, 4600, population_size)
costs = sorted(costs)

fig, axes = plt.subplots(1, 2)

# Left: Full population
ax = axes[0]
colors = [BRAND_COLORS["twoLight"] for _ in range(population_size)]
bars = ax.barh(range(population_size), costs, color=colors, alpha=0.6, edgecolor='black', linewidth=1)

ax.set_ylabel('Individual Schedule ID', fontsize=12)
ax.set_xlabel('Cost (€)', fontsize=12)
ax.set_title('Current Population (20 schedules)', fontsize=14, fontweight='bold')
ax.set_yticks(range(0, population_size, 5))
ax.grid(True, alpha=0.3, axis='x')

# Right: Tournament selection
ax = axes[1]

# Pick 3 random individuals for tournament
tournament_indices = [5, 12, 17]
tournament_costs = [costs[i] for i in tournament_indices]
winner_idx = tournament_indices[np.argmin(tournament_costs)]
winner_cost = min(tournament_costs)

# Show tournament
colors_tournament = ['green' if costs[i] == winner_cost else 'orange' for i in tournament_indices]
ax.barh(range(3), tournament_costs, color=colors_tournament, alpha=0.8, edgecolor='black', linewidth=2)

ax.set_ylabel('Tournament Contestant', fontsize=12)
ax.set_xlabel('Cost (€)', fontsize=12)
ax.set_title('Tournament Selection (size=3)', fontsize=14, fontweight='bold')
ax.set_yticks(range(3))
ax.set_yticklabels([f'Schedule #{i}' for i in tournament_indices])
ax.grid(True, alpha=0.3, axis='x')

# Annotate winner
ax.text(winner_cost + 30, 0, '← WINNER!\nSelected as parent', va='center', fontsize=11, 
        fontweight='bold', color='green')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Random subset of population and selecting the best one based on their fitness.
:::

## Stage 2: Crossover (Recombination)

[Combine two parent schedules to create offspring:]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(1, 1)
ax.set_xlim(0, 14)
ax.set_ylim(0, 10)
ax.axis('off')

# Define shift labels
shifts = ['Fri\nDinner', 'Fri\nLate', 'Sat\nLunch', 'Sat\nDinner', 'Sun\nLunch', 'Sun\nDinner']

# Parent 1 - shown as colored blocks
y_parent1 = 8

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    # Draw colored block
    rect = plt.Rectangle((x, y_parent1), 1.5, 0.8, facecolor=BRAND_COLORS["oneLight"], 
                         edgecolor='black', linewidth=2, alpha=0.7)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_parent1 + 0.4, shift, ha='center', va='center', fontsize=9, fontweight='bold')

# Parent 2 - shown as colored blocks
y_parent2 = 6.5

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    # Draw colored block
    rect = plt.Rectangle((x, y_parent2), 1.5, 0.8, facecolor=BRAND_COLORS["twoLight"], 
                         edgecolor='black', linewidth=2, alpha=0.7)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_parent2 + 0.4, shift, ha='center', va='center', fontsize=9, fontweight='bold')

# Crossover point indicator
crossover_point = 3  # After 3rd shift
x_cross = 1 + crossover_point * 2 - 0.1
ax.plot([x_cross, x_cross], [y_parent2 - 0.5, y_parent1 + 1.2], color=BRAND_COLORS["threeDark"], linewidth=3, alpha=0.7)
ax.text(x_cross + 0.2, y_parent1 + 1.4, 'Cut here', fontsize=11, color=BRAND_COLORS["threeDark"], fontweight='bold')

# Arrows showing inheritance
ax.annotate('', xy=(4, 3.8), xytext=(4, y_parent1 - 0.3),
            arrowprops=dict(arrowstyle='->', lw=2, color=BRAND_COLORS["oneDark"]))
ax.annotate('', xy=(10, 3.8), xytext=(10, y_parent2 - 0.3),
            arrowprops=dict(arrowstyle='->', lw=2, color=BRAND_COLORS["twoDark"]))

# Child - combination
y_child = 2

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    # Color based on which parent
    if i < crossover_point:
        color = BRAND_COLORS["oneLight"]
        label_color = BRAND_COLORS["oneDark"]
    else:
        color = BRAND_COLORS["twoLight"]
        label_color = BRAND_COLORS["twoDark"]
    
    # Draw colored block
    rect = plt.Rectangle((x, y_child), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=3, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_child + 0.4, shift, ha='center', va='center', fontsize=9, fontweight='bold')

# Add explanation
ax.text(7, 0.5, 'First 3 shifts from Parent 1, last 3 from Parent 2', 
        ha='center', fontsize=12, style='italic')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Crossover randomly combines good building blocks from both parents!
:::

## Stage 3: Mutation

[Random changes maintain diversity and explore new solutions:]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(1, 1)
ax.set_xlim(0, 14)
ax.set_ylim(0, 8)
ax.axis('off')

# Define shift labels (these stay the same!)
shifts = ['Fri\nDinner', 'Fri\nLate', 'Sat\nLunch', 'Sat\nDinner', 'Sun\nLunch', 'Sun\nDinner']

# Color palette for each shift - each shift gets its own distinct color
shift_colors = [
    BRAND_COLORS["oneLight"],    
    BRAND_COLORS["oneDark"],     
    BRAND_COLORS["twoLight"],   
    BRAND_COLORS["twoDark"],     
    BRAND_COLORS["threeDark"],   
    BRAND_COLORS["threeLight"]   
]

# Before mutation - original color assignment represents which servers work which shift
y_before = 5.5
ax.text(0.5, y_before + 1.7, 'Before Mutation', fontsize=14, fontweight='bold', ha='left')

# Positions that will swap their server assignments (swap colors)
swap_pos1, swap_pos2 = 1, 4  # Fri Late ↔ Sun Lunch

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    color = shift_colors[i]
    
    rect = plt.Rectangle((x, y_before), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_before + 0.4, shift, ha='center', va='center', 
            fontsize=9, fontweight='bold', color='black')

# Draw swap arrows between the highlighted blocks
x1 = 1 + swap_pos1 * 2 + 0.75
x2 = 1 + swap_pos2 * 2 + 0.75
y_arrow = y_before - 0.5

# Curved arrow showing swap
ax.annotate('', xy=(x2, y_arrow), xytext=(x1, y_arrow),
            arrowprops=dict(arrowstyle='<->', lw=3, color=BRAND_COLORS["threeDark"], 
                          connectionstyle="arc3,rad=.3"))
ax.text((x1 + x2) / 2, y_arrow - 0.8, 'SWAP ASSIGNMENTS!', ha='center', fontsize=12, 
        fontweight='bold', color='red', alpha=0.7)

# After mutation - COLORS are swapped (representing different server assignments)
y_after = 1.5
ax.text(0.5, y_after + 1.7, 'After Mutation', fontsize=14, fontweight='bold', ha='left')

# Create color array with swapped assignments
after_colors = shift_colors.copy()
after_colors[swap_pos1], after_colors[swap_pos2] = after_colors[swap_pos2], after_colors[swap_pos1]

for i, shift in enumerate(shifts):
    x = 1 + i * 2
    color = after_colors[i]  # Color represents the server assignment
    
    rect = plt.Rectangle((x, y_after), 1.5, 0.8, facecolor=color, 
                         edgecolor='black', linewidth=2, alpha=0.8)
    ax.add_patch(rect)
    ax.text(x + 0.75, y_after + 0.4, shift, ha='center', va='center', 
            fontsize=9, fontweight='bold', color='black')

# Add explanation
ax.text(7, 0, 'Mutation rate: 20% (happens to 1 in 5 offspring)', 
        ha='center', fontsize=11, style='italic')

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Mutation adds random exploration, like trying something completely new occasionally!
:::

## Stage 4: Population Evolution

[How the population improves over generations:]{.highlight}

```{python}
#| echo: false
#| eval: true

# Use same plot style as head-to-head comparison
fig, ax = plt.subplots(1, 1)

# Plot GA data
generations = list(range(len(ga_best_hist)))
ax.plot(generations, ga_best_hist, color=BRAND_COLORS["twoDark"], linewidth=3, 
        label=f'GA Best (€{ga_best_cost:.0f})', alpha=0.9)
ax.plot(generations, ga_avg_hist, color=BRAND_COLORS["twoLight"], linewidth=2, 
        linestyle='--', label='GA Population Average', alpha=0.6)

# Greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy Start (€{greedy_cost_value:.0f})', alpha=0.6)

# Annotate phases
ax.axvspan(0, 30, alpha=0.1, color=BRAND_COLORS["threeDark"])
ax.axvspan(30, 70, alpha=0.1, color=BRAND_COLORS["oneDark"])
ax.axvspan(70, len(generations), alpha=0.1, color=BRAND_COLORS["twoDark"])

ax.text(15, max(ga_avg_hist)*0.98, 'EXPLORATION\nHigh diversity', ha='center', 
        fontsize=10, fontweight='bold', color=BRAND_COLORS["threeDark"])
ax.text(50, max(ga_avg_hist)*0.88, 'REFINEMENT\nConverging', ha='center', 
        fontsize=10, fontweight='bold', color=BRAND_COLORS["oneDark"])
ax.text(85, max(ga_avg_hist)*0.78, 'EXPLOITATION\nFine-tuning', ha='center', 
        fontsize=10, fontweight='bold', color=BRAND_COLORS["twoDark"])

ax.set_xlabel('Generation', fontsize=14, fontweight='bold')
ax.set_ylabel('Cost (€)', fontsize=14, fontweight='bold')
ax.set_title('Genetic Algorithm: Population Improvement Over Time', fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='best', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-note
Notice how population average also improves (not just the best)!
:::

## GA vs SA: Head-to-Head

[Comparing exploration strategies on the restaurant problem:]{.highlight}

```{python}
#| echo: false
#| eval: true

# GA already ran earlier - just create comparison visualization
fig, ax = plt.subplots(1, 1)

# Plot both algorithms
generations = list(range(len(ga_best_hist)))
ax.plot(generations, ga_best_hist, color=BRAND_COLORS["twoDark"], linewidth=3, 
        label=f'GA Best (€{ga_best_cost:.0f})', alpha=0.9)
ax.plot(generations, ga_avg_hist, color=BRAND_COLORS["twoLight"], linewidth=2, 
        linestyle='--', label='GA Population Average', alpha=0.6)

# SA already ran - use those results (pad to same length for comparison)
sa_iterations = range(len(best_costs))
ax.plot(sa_iterations, best_costs, color=BRAND_COLORS["oneDark"], linewidth=3,
        label=f'SA Best (€{best_cost_sa:.0f})', alpha=0.9)

# Greedy baseline
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy Start (€{greedy_cost_value:.0f})', alpha=0.6)

ax.set_xlabel('Iteration / Generation', fontsize=14, fontweight='bold')
ax.set_ylabel('Best Cost Found (€)', fontsize=14, fontweight='bold')
ax.set_title('Genetic Algorithm vs Simulated Annealing\n(Same Restaurant Problem)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='best', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
GA maintains population diversity, SA explores single solution path!
:::

## GA Mistakes: Population Issues

[Avoid these population-related errors:]{.highlight}

. . .

**Mistake #1: Everyone Becomes Identical**

- If all solutions look the same → Lost diversity
- Fix: More mutation, bigger population, tournament selection

. . .

**Mistake #2: Too Greedy in Selection**

- Only keeping the very best → Premature convergence  
- Fix: Keep some variety, even if not perfect (elitism of 10-20%)

## GA Mistakes: Implementation

[Technical pitfalls to watch out for:]{.highlight}

. . .

**Mistake #3: Breaking the Rules**

- Crossover might create invalid schedules
- Fix: Always check and repair after crossover/mutation

. . .

**Mistake #4: Evolution Too Slow**

- Population too large or too many generations
- Fix: Start small (50-100), tune based on convergence

# [Metaheuristic #3: Tabu Search]{.flow} {.title}

## Core Idea

[Using memory to avoid cycling through bad solutions:]{.highlight}

::: columns
::: {.column width="50%"}
**Analogy:**

- Keep a list of recent dates
- "Not going back there!"
- Forces you to meet new people
- After time, memory fades
:::

::: {.column width="50%"}
**In Optimization:**

- Recent solutions = "tabu"
- Don't revisit same schedules
- Forces exploration of new areas
- Tabu list has limited size
:::
:::

. . .

::: {.callout-tip}
Like keeping "lessons learned", you remember not to use them again, but after a while, you might reconsider!
:::

## Concept

[How Tabu Search Works (Pseudocode)]{.highlight}

```python
def tabu_search_concept():
    tabu_list = []  # Our "never again" list
    current_solution = initial_schedule
    best_solution = current_solution
    
    while not done:
        # Look at all possible moves
        possible_moves = get_all_neighbor_moves(current_solution)
        
        # Filter out the "forbidden" moves
        allowed_moves = []
        for move in possible_moves:
            if move not in tabu_list:  # Not forbidden
                allowed_moves.append(move)
        
        # Pick the best allowed move (even if worse!)
        best_move = select_best(allowed_moves)
        current_solution = apply(best_move)
        
        # Update best if improved
        if cost(current_solution) < cost(best_solution):
            best_solution = current_solution
        
        # Remember this move (add to tabu list)
        tabu_list.append(best_move)
        if len(tabu_list) > 10:  # Keep list size manageable
            tabu_list.pop(0)  # Forget oldest
    
    return best_solution
```

## Tabu Search on Restaurant Problem

[Real implementation with memory-based exploration:]{.highlight}

```{python}
#| echo: false
#| eval: true

def get_all_neighbors(schedule, sample_size=20):
    """Generate multiple neighbor solutions"""
    neighbors = []
    for _ in range(sample_size):
        neighbors.append(make_neighbor(schedule))
    return neighbors

def schedule_to_tuple(schedule):
    """Convert schedule to hashable tuple for tabu list"""
    return tuple(tuple(shift) for shift in schedule)

def tabu_search(initial_schedule, max_iterations=150, tabu_tenure=15):
    """Tabu Search with short-term memory"""
    current = [shift[:] for shift in initial_schedule]
    current_cost = calculate_cost(current)[0]
    
    best = [shift[:] for shift in current]
    best_cost = current_cost
    
    tabu_list = []
    cost_history = [current_cost]
    best_history = [best_cost]
    
    random.seed(42)
    
    for iteration in range(max_iterations):
        # Generate neighbors
        neighbors = get_all_neighbors(current, sample_size=20)
        
        # Evaluate and filter by tabu status
        best_neighbor = None
        best_neighbor_cost = float('inf')
        
        for neighbor in neighbors:
            neighbor_tuple = schedule_to_tuple(neighbor)
            neighbor_cost = calculate_cost(neighbor)[0]
            
            # Aspiration criterion: accept tabu move if it's better than best ever
            if neighbor_tuple not in tabu_list or neighbor_cost < best_cost:
                if neighbor_cost < best_neighbor_cost:
                    best_neighbor = neighbor
                    best_neighbor_cost = neighbor_cost
        
        # Move to best allowed neighbor (even if worse!)
        if best_neighbor is not None:
            current = best_neighbor
            current_cost = best_neighbor_cost
            
            # Add to tabu list
            tabu_list.append(schedule_to_tuple(current))
            if len(tabu_list) > tabu_tenure:
                tabu_list.pop(0)
            
            # Update best
            if current_cost < best_cost:
                best = [shift[:] for shift in current]
                best_cost = current_cost
        
        cost_history.append(current_cost)
        best_history.append(best_cost)
    
    return best, best_cost, cost_history, best_history

# Run Tabu Search
np.random.seed(42)
random.seed(42)
tabu_best, tabu_best_cost, tabu_costs, tabu_best_hist = tabu_search(
    greedy_schedule, max_iterations=150, tabu_tenure=15
)

# Visualize Tabu Search performance
fig, ax = plt.subplots(1, 1)

iterations = list(range(len(tabu_costs)))
ax.plot(iterations, tabu_costs, color=BRAND_COLORS["twoLight"], linewidth=1, 
        alpha=0.5, label='Tabu Current Solution')
ax.plot(iterations, tabu_best_hist, color=BRAND_COLORS["oneDark"], linewidth=3,
        label=f'Tabu Best (€{tabu_best_cost:.0f})', alpha=0.9)

# Add greedy baseline and SA/GA results for comparison
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy (€{greedy_cost_value:.0f})', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Cost (€)', fontsize=14, fontweight='bold')
ax.set_title('Tabu Search on Restaurant Staffing Problem\n(Memory prevents cycling back to poor solutions)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

. . .

::: callout-tip
Tabu Search's memory prevents revisiting bad solutions!
:::

# [Metaheuristic #4: Ant Colony Optimization]{.flow} {.title}

## The Concept

[How ants find the shortest path to food:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Visualize ACO pheromone trails
fig, axes = plt.subplots(1, 3)

# Create nodes for TSP
np.random.seed(123)
n_nodes = 8
node_x = np.random.uniform(0, 10, n_nodes)
node_y = np.random.uniform(0, 10, n_nodes)

titles = ['Initial: Equal Pheromones', 
          'After 10 Iterations: Trails Forming',
          'After 50 Iterations: Converged']

for idx, (ax, title) in enumerate(zip(axes, titles)):
    # Draw edges with pheromone intensity
    for i in range(n_nodes):
        for j in range(i+1, n_nodes):
            if idx == 0:
                # Initial: all equal
                alpha = 0.2
                width = 1
            elif idx == 1:
                # Forming: some stronger
                dist = np.sqrt((node_x[i]-node_x[j])**2 + (node_y[i]-node_y[j])**2)
                alpha = 0.1 + 0.5 * np.exp(-dist/5)
                width = alpha * 5
            else:
                # Converged: clear path
                # Define good path
                good_edges = [(0,1), (1,3), (3,5), (5,7), (7,6), (6,4), (4,2), (2,0)]
                if (i,j) in good_edges or (j,i) in good_edges:
                    alpha = 0.8
                    width = 5
                else:
                    alpha = 0.1
                    width = 0.5
            
            ax.plot([node_x[i], node_x[j]], [node_y[i], node_y[j]], 
                   color=BRAND_COLORS["darker"], alpha=alpha, linewidth=width)
    
    # Draw nodes
    ax.scatter(node_x, node_y, s=200, c=BRAND_COLORS["oneDark"], zorder=5)
    for i, (x, y) in enumerate(zip(node_x, node_y)):
        ax.text(x, y, str(i), ha='center', va='center', color='white', fontweight='bold')
    
    ax.set_title(title, fontsize=12, fontweight='bold')
    ax.set_xlim(-1, 11)
    ax.set_ylim(-1, 11)
    ax.set_aspect('equal')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

[Ants deposit pheromones, creating emergent intelligence!]{.highlight}

---

## ACO on Restaurant Problem

[Pheromone-guided construction of schedules:]{.highlight}

```{python}
#| echo: false
#| eval: true

def ant_colony_optimization(n_ants=20, n_iterations=100, evaporation=0.5, alpha=1.0, beta=2.0):
    """
    ACO adapted for scheduling problem
    Pheromones represent desirability of server-shift assignments
    """
    # Initialize pheromones for each (server, shift) pair
    servers = list(COSTS.keys())
    shifts = list(SHIFTS.keys())
    pheromones = {}
    for server in servers:
        for shift_idx in range(len(shifts)):
            pheromones[(server, shift_idx)] = 1.0
    
    best_schedule = None
    best_cost = float('inf')
    cost_history = []
    
    random.seed(42)
    np.random.seed(42)
    
    for iteration in range(n_iterations):
        # Each ant constructs a solution
        iteration_schedules = []
        iteration_costs = []
        
        for ant in range(n_ants):
            # Construct schedule shift by shift
            available_servers = servers[:]
            schedule = []
            
            for shift_idx in range(len(shifts)):
                # Select 2 servers for this shift based on pheromones
                shift_servers = []
                
                for _ in range(2):
                    if not available_servers:
                        break
                    
                    # Calculate probabilities based on pheromones and heuristic
                    probabilities = []
                    for server in available_servers:
                        pheromone = pheromones[(server, shift_idx)]
                        # Heuristic: prefer experienced servers for high-penalty shifts
                        is_exp = 1 if server.startswith('E') else 0
                        penalty = SHIFTS[shifts[shift_idx]]['penalty']
                        heuristic = 1 + (is_exp * penalty / 1000)  # Higher for exp + high penalty
                        
                        prob = (pheromone ** alpha) * (heuristic ** beta)
                        probabilities.append(prob)
                    
                    # Normalize probabilities
                    total = sum(probabilities)
                    if total > 0:
                        probabilities = [p / total for p in probabilities]
                    else:
                        probabilities = [1/len(available_servers)] * len(available_servers)
                    
                    # Select server
                    selected_server = np.random.choice(available_servers, p=probabilities)
                    shift_servers.append(selected_server)
                    available_servers.remove(selected_server)
                
                schedule.append(shift_servers)
            
            # Evaluate solution
            cost = calculate_cost(schedule)[0]
            iteration_schedules.append(schedule)
            iteration_costs.append(cost)
            
            # Track best
            if cost < best_cost:
                best_schedule = [shift[:] for shift in schedule]
                best_cost = cost
        
        cost_history.append(best_cost)
        
        # Evaporate pheromones
        for key in pheromones:
            pheromones[key] *= (1 - evaporation)
        
        # Deposit pheromones (stronger for better solutions)
        for schedule, cost in zip(iteration_schedules, iteration_costs):
            deposit_amount = 1000 / cost  # Better solutions deposit more
            for shift_idx, servers_in_shift in enumerate(schedule):
                for server in servers_in_shift:
                    pheromones[(server, shift_idx)] += deposit_amount
    
    return best_schedule, best_cost, cost_history

# Run ACO
np.random.seed(42)
random.seed(42)
aco_best, aco_best_cost, aco_history = ant_colony_optimization(
    n_ants=20, n_iterations=100, evaporation=0.3, alpha=1.0, beta=2.0
)

# Visualize ACO performance
fig, ax = plt.subplots(1, 1, figsize=(12, 7))

iterations = list(range(len(aco_history)))
ax.plot(iterations, aco_history, color=BRAND_COLORS["threeDark"], linewidth=3,
        label=f'ACO Best (€{aco_best_cost:.0f})', alpha=0.9)

# Add other algorithms for comparison
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, 
           label=f'Greedy (€{greedy_cost_value:.0f})', alpha=0.6)
ax.axhline(y=best_cost_sa, color=BRAND_COLORS["twoDark"], linestyle='--', linewidth=2,
           label=f'SA (€{best_cost_sa:.0f})', alpha=0.6)
ax.axhline(y=ga_best_cost, color=BRAND_COLORS["oneDark"], linestyle='--', linewidth=2,
           label=f'GA (€{ga_best_cost:.0f})', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=14, fontweight='bold')
ax.set_ylabel('Best Cost Found (€)', fontsize=14, fontweight='bold')
ax.set_title('Ant Colony Optimization on Restaurant Staffing\n(Pheromones guide ants toward good server-shift assignments)', 
             fontsize=16, fontweight='bold', pad=15)
ax.legend(fontsize=12, loc='upper right', framealpha=0.95)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\n{'='*60}")
print(f"All Algorithms Comparison:")
print(f"{'='*60}")
print(f"Greedy:      €{greedy_cost_value:,.0f}  (baseline)")
print(f"SA:          €{best_cost_sa:,.0f}  ({100*(greedy_cost_value-best_cost_sa)/greedy_cost_value:.1f}% better)")
print(f"GA:          €{ga_best_cost:,.0f}  ({100*(greedy_cost_value-ga_best_cost)/greedy_cost_value:.1f}% better)")
print(f"Tabu Search: €{tabu_best_cost:,.0f}  ({100*(greedy_cost_value-tabu_best_cost)/greedy_cost_value:.1f}% better)")
print(f"ACO:         €{aco_best_cost:,.0f}  ({100*(greedy_cost_value-aco_best_cost)/greedy_cost_value:.1f}% better)")
```

[ACO's collective intelligence emerges from simple ant behavior!]{.highlight}

## Try It Yourself!

[Put your knowledge into practice with ACO:]{.highlight}

::: {.callout-note}
In **Tutorial 9.1**, you'll implement ACO for Bean Counter's delivery routing. You'll see how digital ants find optimal paths!
:::

## ACO: The Pheromone Evaporation Trick

[Why forgetting old paths helps find better ones:]{.highlight}

```python
#| echo: true
#| eval: false

# CONCEPT: Why Pheromones Work
def pheromone_update_concept():
    """
    The ant colony's learning mechanism
    """
    # Step 1: Evaporation (forgetting old paths)
    # Like how old customer reviews become less relevant
    for path in all_paths:
        pheromone[path] = pheromone[path] * 0.5  # Fade away
    
    # Step 2: Reinforcement (strengthening good paths)  
    # Like how popular restaurants get more customers
    for ant_route in this_iteration:
        if route_is_short:
            add_more_pheromone(route)  # Attract more ants!
```

. . .

## Why Evaporation Matters

[The power of forgetting in optimization:]{.highlight}

::: {.callout-important}
Without evaporation, the first decent path found becomes permanent. With evaporation, the colony can adapt when conditions change - just like businesses must forget outdated "best practices"!
:::

# [Decision Framework]{.flow} {.title}

## When to Use Which Metaheuristic?

[A practical decision guide for algorithm selection:]{.highlight}

```{python}
#| echo: false
#| eval: true

import pandas as pd

# Create comprehensive comparison table
comparison_data = {
    'Method': ['Random', 'Greedy', 'Local Search', 'Simulated Annealing', 
               'Genetic Algorithm', 'Tabu Search', 'Ant Colony'],
    'Time': ['⚡⚡⚡⚡', '⚡⚡⚡', '⚡⚡', '⚡⚡', '⚡', '⚡⚡', '⚡'],
    'Quality': ['⭐', '⭐⭐', '⭐⭐⭐', '⭐⭐⭐⭐', '⭐⭐⭐⭐', '⭐⭐⭐', '⭐⭐⭐⭐'],
    'Complexity': ['Trivial', 'Simple', 'Medium', 'Medium', 'High', 'Medium', 'High'],
    'Best For': ['Baseline', 'Quick decisions', 'Improvement', 'Single solution',
                 'Population-based', 'Avoiding cycles', 'Path problems'],
    'Parameters': ['None', '1-2', '2-3', '3-4', '5-6', '2-3', '4-5']
}

df = pd.DataFrame(comparison_data)

# Style the dataframe
styled_df = df.style.set_properties(**{
    'text-align': 'center',
    'font-size': '11pt',
})

from IPython.display import HTML, display
display(HTML(df.to_html(index=False, classes='table table-striped')))
```

. . .

[Choose based on: time available, solution quality needed, and problem structure]{.highlight}

---

## All Four Metaheuristics: Side-by-Side

[How do they compare on our restaurant problem?]{.highlight}

```{python}
#| echo: false
#| eval: true

# Create comprehensive 4-way comparison
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Top Left: Convergence comparison
ax = axes[0, 0]
max_len = max(len(best_costs), len(ga_best_hist), len(tabu_best_hist), len(aco_history))

# Pad all to same length
def pad_to_length(lst, target_len):
    if len(lst) >= target_len:
        return lst[:target_len]
    return lst + [lst[-1]] * (target_len - len(lst))

sa_padded = pad_to_length(best_costs, max_len)
ga_padded = pad_to_length(ga_best_hist, max_len)
tabu_padded = pad_to_length(tabu_best_hist, max_len)
aco_padded = pad_to_length(aco_history, max_len)

iterations = list(range(max_len))
ax.plot(iterations, sa_padded, color=BRAND_COLORS["twoDark"], linewidth=3, label='Simulated Annealing', alpha=0.9)
ax.plot(iterations, ga_padded, color=BRAND_COLORS["oneDark"], linewidth=3, label='Genetic Algorithm', alpha=0.9)
ax.plot(iterations, tabu_padded, color=BRAND_COLORS["threeDark"], linewidth=3, label='Tabu Search', alpha=0.9)
ax.plot(iterations, aco_padded, color=BRAND_COLORS["twoLight"], linewidth=3, label='Ant Colony', alpha=0.9)
ax.axhline(y=greedy_cost_value, color='gray', linestyle=':', linewidth=2, label='Greedy', alpha=0.6)

ax.set_xlabel('Iteration', fontsize=13, fontweight='bold')
ax.set_ylabel('Best Cost (€)', fontsize=13, fontweight='bold')
ax.set_title('Convergence Speed Comparison', fontsize=15, fontweight='bold')
ax.legend(fontsize=11, loc='upper right')
ax.grid(True, alpha=0.3)

# Top Right: Final results bar chart
ax = axes[0, 1]
algorithms = ['Greedy', 'SA', 'GA', 'Tabu', 'ACO']
costs = [greedy_cost_value, best_cost_sa, ga_best_cost, tabu_best_cost, aco_best_cost]
colors = ['gray', BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], 
          BRAND_COLORS["threeDark"], BRAND_COLORS["twoLight"]]

bars = ax.barh(algorithms, costs, color=colors, alpha=0.8, edgecolor='black', linewidth=2)
ax.set_xlabel('Total Cost (€)', fontsize=13, fontweight='bold')
ax.set_title('Final Solution Quality', fontsize=15, fontweight='bold')
ax.grid(True, alpha=0.3, axis='x')

# Add cost labels
for i, (bar, cost) in enumerate(zip(bars, costs)):
    improvement = 100 * (greedy_cost_value - cost) / greedy_cost_value if i > 0 else 0
    label = f'€{cost:.0f}' if i == 0 else f'€{cost:.0f} ({improvement:.1f}% better)'
    ax.text(cost + 50, i, label, va='center', fontsize=10, fontweight='bold')

# Bottom Left: Exploration patterns (conceptual)
ax = axes[1, 0]
categories = ['Single\nSolution', 'Population\nBased', 'Memory\nBased', 'Collective\nIntelligence']
sa_score = [5, 1, 2, 1]
ga_score = [1, 5, 2, 3]
tabu_score = [4, 1, 5, 1]
aco_score = [2, 4, 3, 5]

x = np.arange(len(categories))
width = 0.2

ax.bar(x - 1.5*width, sa_score, width, label='SA', color=BRAND_COLORS["twoDark"], alpha=0.8)
ax.bar(x - 0.5*width, ga_score, width, label='GA', color=BRAND_COLORS["oneDark"], alpha=0.8)
ax.bar(x + 0.5*width, tabu_score, width, label='Tabu', color=BRAND_COLORS["threeDark"], alpha=0.8)
ax.bar(x + 1.5*width, aco_score, width, label='ACO', color=BRAND_COLORS["twoLight"], alpha=0.8)

ax.set_ylabel('Strength (1-5)', fontsize=13, fontweight='bold')
ax.set_title('Algorithm Characteristics', fontsize=15, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(categories, fontsize=10)
ax.set_ylim(0, 6)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3, axis='y')

# Bottom Right: Parameter complexity
ax = axes[1, 1]
algorithm_names = ['SA', 'GA', 'Tabu', 'ACO']
param_counts = [3, 5, 2, 4]
impl_complexity = [2, 4, 3, 5]  # Implementation complexity (1-5)

x_pos = np.arange(len(algorithm_names))
ax.scatter(param_counts, impl_complexity, s=[500, 500, 500, 500], 
           c=[BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], 
              BRAND_COLORS["threeDark"], BRAND_COLORS["twoLight"]], 
           alpha=0.7, edgecolors='black', linewidth=2)

for i, name in enumerate(algorithm_names):
    ax.annotate(name, (param_counts[i], impl_complexity[i]), 
                fontsize=13, fontweight='bold', ha='center', va='center')

ax.set_xlabel('Number of Parameters to Tune', fontsize=13, fontweight='bold')
ax.set_ylabel('Implementation Complexity (1-5)', fontsize=13, fontweight='bold')
ax.set_title('Ease of Use vs Flexibility', fontsize=15, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.set_xlim(1, 6)
ax.set_ylim(1, 6)

# Add regions
ax.axhspan(1, 3, alpha=0.05, color='green')
ax.text(5.5, 2, 'Easy', fontsize=10, color='green', fontweight='bold')
ax.axhspan(4, 6, alpha=0.05, color='red')
ax.text(5.5, 5, 'Complex', fontsize=10, color='red', fontweight='bold')

plt.tight_layout()
plt.show()
```

[Each algorithm excels in different aspects - choose based on your priorities!]{.highlight}

## Algorithm Selection: The No Free Lunch Theorem

[Why there's no universal best algorithm:]{.highlight}

::: {.callout-note}
## No Universal Best
"No Free Lunch Theorem": No single algorithm is best for all problems. Your choice must match your problem structure:

- **Path/Network Problems** → ACO (pheromones for paths)
- **Scheduling Problems** → SA or Tabu (neighborhood swaps)
- **Complex Design** → GA (population diversity)
- **Continuous Optimization** → PSO (particle dynamics)
:::

## Implementation Strategy: Start Simple

[The recommended progression for solving optimization problems:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(12, 8))

# Create decision flow
# Start
ax.add_patch(plt.Rectangle((4.5, 8.5), 3, 1, fill=True, 
                          facecolor=BRAND_COLORS["oneLight"], edgecolor='black', linewidth=2))
ax.text(6, 9, 'START HERE', ha='center', va='center', fontsize=12, fontweight='bold')

# Time check
ax.add_patch(plt.Rectangle((1, 6.5), 3, 1, fill=True, 
                          facecolor='lightyellow', edgecolor='black', linewidth=1))
ax.text(2.5, 7, 'Time < 1 min?', ha='center', va='center', fontsize=11)

ax.add_patch(plt.Rectangle((8, 6.5), 3, 1, fill=True, 
                          facecolor='lightyellow', edgecolor='black', linewidth=1))
ax.text(9.5, 7, 'Problem type?', ha='center', va='center', fontsize=11)

# Recommendations
ax.add_patch(plt.Rectangle((0, 4), 2, 1, fill=True, 
                          facecolor='lightgreen', edgecolor='green', linewidth=2))
ax.text(1, 4.5, 'Use Greedy', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((2.5, 4), 2.5, 1, fill=True, 
                          facecolor='lightblue', edgecolor='blue', linewidth=2))
ax.text(3.75, 4.5, 'Greedy + Local', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((6, 4), 2, 1, fill=True, 
                          facecolor='orange', edgecolor='darkorange', linewidth=2))
ax.text(7, 4.5, 'Use SA', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((8.5, 4), 2, 1, fill=True, 
                          facecolor='lightcoral', edgecolor='red', linewidth=2))
ax.text(9.5, 4.5, 'Use GA', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((11, 4), 2, 1, fill=True, 
                          facecolor='plum', edgecolor='purple', linewidth=2))
ax.text(12, 4.5, 'Use ACO', ha='center', va='center', fontsize=10, fontweight='bold')

# Draw arrows
# From start
ax.arrow(6, 8.5, -3.3, -1.3, head_width=0.1, head_length=0.1, fc='black', ec='black')
ax.arrow(6, 8.5, 3.3, -1.3, head_width=0.1, head_length=0.1, fc='black', ec='black')

# From time check
ax.arrow(1.5, 6.5, -0.4, -1.3, head_width=0.1, head_length=0.1, fc='green', ec='green')
ax.text(1, 5.5, 'YES', ha='center', fontsize=9, color='green', fontweight='bold')

ax.arrow(3.5, 6.5, 0.2, -1.3, head_width=0.1, head_length=0.1, fc='blue', ec='blue')
ax.text(4, 5.5, 'NO', ha='center', fontsize=9, color='blue', fontweight='bold')

# From problem type
ax.arrow(8.5, 6.5, -1.4, -1.3, head_width=0.1, head_length=0.1, fc='orange', ec='orange')
ax.text(7.5, 5.5, 'Simple', ha='center', fontsize=9, color='orange')

ax.arrow(9.5, 6.5, 0, -1.3, head_width=0.1, head_length=0.1, fc='red', ec='red')
ax.text(9.5, 5.5, 'Complex', ha='center', fontsize=9, color='red')

ax.arrow(10.5, 6.5, 1.4, -1.3, head_width=0.1, head_length=0.1, fc='purple', ec='purple')
ax.text(11.5, 5.5, 'Routing', ha='center', fontsize=9, color='purple')

# Additional notes
ax.text(6, 2.5, 'Always start simple and add complexity only if needed!', 
        ha='center', fontsize=12, style='italic',
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

ax.text(6, 1.5, 'Use AI tools (ChatGPT/Copilot) to implement chosen method', 
        ha='center', fontsize=11, color='blue')

ax.set_xlim(-0.5, 13.5)
ax.set_ylim(0, 10)
ax.axis('off')
ax.set_title('Metaheuristic Selection Guide', fontsize=16, fontweight='bold', pad=20)

plt.tight_layout()
plt.show()
```

## Implementation Strategy: Practical Tips

[Essential guidelines for successful implementation:]{.highlight}

::: {.incremental}
1. **Start Simple**: Always try greedy first as baseline
2. **Profile Your Problem**: Understand constraints before choosing
3. **Tune Incrementally**: Don't optimize all parameters at once
   - SA: Initial temp ≈ max expected Δ
   - GA: Population ≈ 10 × variables
   - Tabu: Tenure ≈ √problem_size
4. **Track Progress**: Monitor convergence to know when to stop
5. **Hybrid Approaches**: Combine methods (e.g., GA + Local Search)
6. **Use AI Assistance**: Bridge the "expert gap" with GenAI
:::

. . .

::: {.callout-tip}
## Pro Tip
Most real-world problems are solved with greedy + local search. Only use metaheuristics when these fail!
:::

# [Mission Briefing]{.flow} {.title}

## Now It's Your Turn!

::: {.callout-important}
## Tutorial Practice
**Tutorial 9.1**: Implement these algorithms for Bean Counter's problems  
**Tutorial 9.2**: Apply them to the restaurant staffing competition  

You'll code the full versions and see these concepts in action!
:::

## Your Restaurant Challenge

[Apply what you've learned to solve La Étoile's complex problem:]{.highlight}

**Scenario**: La Étoile needs weekend staffing schedule

**Resources**:
- 18 servers (6 experienced @ €75/hr, 12 junior @ €25/hr)
- 6 shifts with **different lengths** (4-6 hours each)
- Large penalties (€0-€1200 per missing experienced)
- Server preferences (1-10 scale, affects quality)

**Three Cost Components to Balance**:
1. Labor cost (hourly rate × shift hours)
2. Experience penalties (strategic choices)
3. Preference penalties (staff happiness)

**Your Tools**:
1. Smart greedy (consider all factors)
2. Local search (preference-aware swaps)
3. Simulated annealing (escape local optima)
4. Genetic algorithm (evolve schedules)

. . .

[Remember: This is genuinely challenging - even greedy won't find the optimal!]{.highlight}

## Summary: From Local Silos to Global Success

[The transformation metaheuristics enable:]{.highlight}

::: columns
::: {.column width="50%"}
**The Journey**
- Started trapped in fog (local optima)
- Learned why greedy climbers fail
- Discovered intelligent escape mechanisms
- Mastered four metaheuristic strategies
- Connected algorithms to business thinking
:::

::: {.column width="50%"}
**The Transformation**
- From department silos → system thinking
- From local peaks → global optimum
- From rigid rules → adaptive exploration
- From single solutions → population wisdom
- From expert-only → AI-accessible tools
:::
:::

. . .

::: {.callout-tip}
## The Management Lesson
Just as SA accepts temporary downhill moves to find the summit, successful organizations accept short-term disruptions (new CRM, process changes) to achieve long-term excellence. 

**Remember**: The sum of optimized silos ≠ an optimized system!
:::

. . .

[You now have both the algorithms AND the mindset to solve complex optimization challenges!]{.success}

## Your Metaheuristics Cheat Sheet

[Quick reference for algorithm selection:]{.highlight}

| Situation | Use This | Because |
|-----------|----------|---------|
| Need answer in < 1 min | Smart Greedy | Consider all 3 costs upfront |
| Multiple cost components | Simulated Annealing | Balances competing objectives |
| Complex preferences | Genetic Algorithm | Evolves good compromises |
| Keep revisiting same bad solutions | Tabu Search | Memory prevents cycling |
| Varying constraints per shift | Local Search + SA | Adapt to different requirements |
| Don't know how to code it | GenAI + Template | Bridges the expert gap |

. . .

[Remember: Perfect is the enemy of good. Start simple, iterate, improve!]{.highlight}

## Break Time!

[Let's take a break before diving into tutorials!]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(figsize=(10, 8))

# Restaurant scene
# Tables
tables_x = [2, 5, 8, 2, 5, 8]
tables_y = [6, 6, 6, 3, 3, 3]
for x, y in zip(tables_x, tables_y):
    rect = plt.Rectangle((x-0.7, y-0.5), 1.4, 1, 
                         facecolor=BRAND_COLORS["oneLight"], edgecolor=BRAND_COLORS["darker"], linewidth=2)
    ax.add_patch(rect)
    ax.text(x, y, '🍽️', ha='center', va='center', fontsize=20)

# Servers with optimization paths
np.random.seed(456)
colors = [BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"], BRAND_COLORS["twoDark"]]
methods = ['Greedy Path', 'SA Path', 'GA Best']

for idx, (color, method) in enumerate(zip(colors, methods)):
    # Create different paths
    if idx == 0:  # Greedy - straight lines
        path_x = [1, 2, 5, 8, 8]
        path_y = [1, 3, 3, 3, 6]
    elif idx == 1:  # SA - wandering
        path_x = [1, 2.5, 4, 5, 7, 8]
        path_y = [1, 2, 4, 6, 5, 6]
    else:  # GA - optimal
        path_x = [1, 2, 2, 5, 5, 8, 8]
        path_y = [1, 3, 6, 6, 3, 3, 6]
    
    ax.plot(path_x, path_y, color=color, linewidth=2, alpha=0.6, label=method)
    ax.scatter(path_x[-1], path_y[-1], color=color, s=100, marker='o', zorder=5)

# Title and labels
ax.text(5, 8, "La Étoile Restaurant", fontsize=18, fontweight='bold', ha='center')
ax.text(5, 7.3, 'Optimized Staffing Routes', fontsize=12, ha='center', style='italic')

ax.legend(loc='lower right', fontsize=10)
ax.set_xlim(0, 10)
ax.set_ylim(0, 9)
ax.axis('off')

plt.tight_layout()
plt.show()
```

[Time to practice with real problems!]{.flow}

## Genetic Algorithm Implementation

[The complete GA algorithm in Python:]{.highlight}

```{python}
#| echo: true
#| eval: false

# CONCEPT: How Genetic Algorithms Work (Simplified)
def genetic_algorithm_concept():
    """
    Evolution-inspired optimization
    """
    # Step 1: Create initial population (like random product designs)
    population = [create_random_schedule() for _ in range(50)]
    
    for generation in range(100):
        # Step 2: Evaluate fitness (like market testing)
        # Better schedules = higher fitness
        fitness_scores = [1/cost(schedule) for schedule in population]
        
        # Step 3: Selection (survival of the fittest)
        # Keep the best performers
        survivors = select_best_half(population)
        
        # Step 4: Crossover (combine successful features)
        # Like combining features from two successful products
        child1 = combine_schedules(parent1, parent2)
        
        # Step 5: Mutation (innovation)
        # Random small changes for diversity
        if random() < 0.1:  # 10% chance
            randomly_change(child1)
    
        # The cycle continues: evolve toward excellence!
        new_population = next_generation
    
    return best_schedule_ever_found

print("GA = Innovation through recombination and experimentation!")
```

# [Practical Implementation]{.flow} {.title}

## Using AI Tools Effectively: The Expert Gap

[How GenAI bridges the gap between business knowledge and technical implementation:]{.highlight}

::: {.callout-important}
## The Revolution
[The breakthrough that democratizes optimization:]{.highlight}

**The Problem**: Business managers understand constraints but can't code. Data scientists can code but don't understand the business.

**The Solution**: GenAI bridges this "expert gap" by translating business requirements into working code!
:::

::: columns
::: {.column width="50%"}
**The 5-Element Prompt Template:**
```text
ROLE: Expert in OR and Python metaheuristics

PROBLEM: Restaurant staff scheduling
- Variables: 18 staff (6 exp @ €75/hr, 12 jr @ €25/hr)
- 6 shifts with VARYING lengths: [5,4,4,6,5,6] hours
- Representation: {shift_id: [3 server_ids]}

CONSTRAINTS:
- Coverage: Exactly 3 staff per shift
- Skill: Need 1+ experienced per shift
- Assignment: Each server works exactly once

COSTS (3 components):
- Labor: rate × hours (varies by shift!)
- Experience penalty: [€800,0,500,1200,600,1000]
- Preferences: (10-pref)×€20 per assignment

ALGORITHM: Implement SA with:
- Neighbor: Swap considering preferences
- Initial temp: 500, cooling: 0.98
- Return: Best schedule + cost
```
:::

::: {.column width="50%"}
**Why This Works:**

✅ **Clear role** sets AI expertise  
✅ **Problem structure** defines scope  
✅ **Hard vs soft** constraints separated  
✅ **Penalties** quantify trade-offs  
✅ **Algorithm specifics** prevent generic code  

**Bad Prompt Example:**
```text
"Make a scheduler with metaheuristics"
```

❌ No problem structure  
❌ No constraints  
❌ No algorithm choice  
❌ AI will produce useless generic code  

[GenAI makes optimization accessible to non-programmers!]{.highlight}
:::
:::

## Debugging Metaheuristics: Strategy

[Essential debugging strategies for complex algorithms:]{.highlight}

```python
#| echo: true
#| eval: false

# CONCEPT: How to Debug Your Metaheuristic
def debug_tips():
    """
    Common problems and solutions
    """
    if solution_not_improving:
        # Problem: Stuck in local optimum
        # Fix: Increase temperature (SA) or mutation (GA)
        
    if all_solutions_look_same:
        # Problem: Lost diversity
        # Fix: Start with more random solutions
        
    if takes_forever:
        # Problem: Too many iterations
        # Fix: Better stopping criteria
        
    # You'll practice debugging in the tutorials!
```

## Real-World Considerations

[Practical issues when deploying metaheuristics:]{.highlight}

::: columns
::: {.column width="50%"}
**Computational Budget**
- Wall-clock time matters
- Memory constraints
- Parallel processing opportunities
- Cloud vs local execution

**Solution Quality Requirements**
- "Good enough" vs optimal
- Consistency vs best possible
- Explainability needs
:::

::: {.column width="50%"}
**Problem Characteristics**
- Static vs dynamic
- Deterministic vs stochastic
- Single vs multi-objective
- Hard vs soft constraints

**Implementation Reality**
- Development time
- Maintenance burden
- Team expertise
- Integration complexity
:::
:::

# [Advanced Topics]{.flow} {.title}

## Hybrid Metaheuristics

[Combining methods for superior performance:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(12, 6))

# Create hybrid approach visualization
methods = ['Greedy\nStart', 'Local\nSearch', 'SA\nEscape', 'GA\nDiversify', 'Final\nSolution']
x_pos = np.arange(len(methods))
costs = [1640, 1520, 1450, 1400, 1380]
colors = [BRAND_COLORS["darker"], BRAND_COLORS["oneLight"], BRAND_COLORS["twoLight"], 
          BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"]]

bars = ax.bar(x_pos, costs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)

# Add arrows between stages
for i in range(len(methods)-1):
    ax.annotate('', xy=(i+1, costs[i+1]+20), xytext=(i+0.2, costs[i]-20),
                arrowprops=dict(arrowstyle='->', lw=2, color='black'))

ax.set_xlabel('Optimization Stage', fontsize=12)
ax.set_ylabel('Solution Cost (€)', fontsize=12)
ax.set_title('Hybrid Approach: Combining Methods', fontsize=14, fontweight='bold')
ax.set_xticks(x_pos)
ax.set_xticklabels(methods)
ax.set_ylim(1300, 1700)

# Add improvement labels
for i in range(1, len(costs)):
    improvement = costs[i-1] - costs[i]
    ax.text(i-0.5, 1650, f'-€{improvement}', ha='center', fontsize=10, 
            color=BRAND_COLORS["twoDark"], fontweight='bold')

plt.tight_layout()
plt.show()
```

[Combine methods sequentially for best results!]{.highlight}

## Parameter Tuning: Basic Strategies

[Start with these proven approaches:]{.highlight}

::: columns
::: {.column width="50%"}
**Grid Search**
```python
temps = [100, 500, 1000, 2000]
coolings = [0.9, 0.95, 0.99]
for T in temps:
    for alpha in coolings:
        run_SA(T, alpha)
```

**Adaptive Parameters**
```python
# Self-adjusting temperature
if no_improvement > 50:
    temperature *= 1.5  # Reheat
```
:::

::: {.column width="50%"}
**Rules of Thumb**
- SA: T₀ ≈ max expected delta
- GA: pop_size ≈ 10 × variables
- Tabu: tenure ≈ √problem_size
- Mutation: 1/chromosome_length

**Performance Metrics**
- Convergence speed
- Solution quality
- Robustness (variance)
- Computational time
:::
:::

## Real-World Case Studies

[How major companies use metaheuristics in production:]{.highlight}

### Case Study 1: Amazon's Last-Mile Delivery

::: columns
::: {.column width="50%"}
**The Problem:**
- 30-40% of delivery trucks returning empty
- Massive fuel waste and emissions
- Complex dynamic routing with time windows

**The Solution (ACO):**
- Digital ants explore route combinations
- Pheromones reinforce efficient paths
- Dynamic adaptation to traffic/delays
:::

::: {.column width="50%"}
**The Results:**
- **27% reduction** in empty miles
- **$43M annual savings** in fuel costs
- **15% faster** average delivery times
- **22% reduction** in CO₂ emissions

[ACO's pheromone trails naturally optimize network paths!]{.highlight}
:::
:::

## Case Study 2: Hospital Nurse Scheduling

[Combining GA and SA for complex staff scheduling:]{.highlight}

```{python}
#| echo: false
#| eval: true

import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Left: Performance comparison
ax = axes[0]
methods = ['Manual', 'Greedy', 'SA', 'GA', 'Hybrid\n(GA+SA)']
satisfaction = [45, 52, 68, 71, 85]  # Employee satisfaction %
coverage = [78, 95, 92, 93, 98]  # Shift coverage %

x = np.arange(len(methods))
width = 0.35

bars1 = ax.bar(x - width/2, satisfaction, width, label='Staff Satisfaction %', 
               color=BRAND_COLORS["oneDark"], alpha=0.8)
bars2 = ax.bar(x + width/2, coverage, width, label='Coverage Quality %',
               color=BRAND_COLORS["twoDark"], alpha=0.8)

ax.set_xlabel('Scheduling Method', fontsize=11)
ax.set_ylabel('Performance (%)', fontsize=11)
ax.set_title('Hospital Scheduling: Method Comparison', fontsize=13, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(methods, fontsize=10)
ax.legend()
ax.grid(axis='y', alpha=0.3)

# Add value labels
for bar in bars1:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.0f}%', ha='center', va='bottom', fontsize=9)
for bar in bars2:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.0f}%', ha='center', va='bottom', fontsize=9)

# Right: Cost breakdown
ax = axes[1]
categories = ['Labor\nCost', 'Overtime\nPenalty', 'Turnover\nCost', 'Total\nSavings']
manual_cost = [100, 100, 100, 0]
optimized_cost = [95, 40, 25, 140]
colors = [BRAND_COLORS["darker"], BRAND_COLORS["threeDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"]]

x = np.arange(len(categories))
bars = ax.bar(x, manual_cost, color='lightgray', alpha=0.5, label='Manual')
bars2 = ax.bar(x, optimized_cost, color=colors, alpha=0.8, label='GA+SA')

ax.set_ylabel('Relative Cost (Manual = 100)', fontsize=11)
ax.set_title('Cost Impact of Optimization', fontsize=13, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(categories)
ax.axhline(y=100, color='black', linestyle='--', alpha=0.3)
ax.legend()

plt.tight_layout()
plt.show()
```

**Key Results**: 37% reduction in scheduling time, 25% reduction in violations, 85% staff satisfaction (up from 45%)

## Competition Strategies

[Your roadmap for tackling the complex restaurant problem:]{.highlight}

1. **Understand Complexity**: Study shift hours, penalties, preferences (5 min)
2. **Smart Greedy**: Design preference-aware baseline (10 min)  
3. **Choose Your Weapon**: Pick ONE metaheuristic that handles all 3 costs (15 min)
4. **Fine-tune**: Balance labor vs penalties vs preferences (15 min)
5. **Document Trade-offs**: Explain your strategic choices (5 min)

. . .

::: {.callout-warning}
## Competition Tip
This problem has REAL complexity! Focus on balancing all three cost components rather than perfecting just one.
:::

# [Summary & Resources]{.flow} {.title}

## Key Concepts to Remember

[The essential takeaways from this lecture:]{.highlight}

::: {.incremental}
- **Local Optima**: Simple methods get trapped
- **Acceptance Probability**: P = exp(-Δ/T) enables escape
- **Population Search**: Parallel exploration beats sequential
- **Memory**: Prevents cycling and guides search
- **Hybrid Approaches**: Combine methods for best results
- **AI Tools**: Implementation helpers, not decision makers
:::

## Your Optimization Hierarchy

[When to escalate to more complex methods:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(10, 8))

# Create pyramid
levels = [
    ('Random', 0, 5, BRAND_COLORS["darker"]),
    ('Greedy', 1, 4, BRAND_COLORS["oneLight"]),
    ('Local Search', 2, 3, BRAND_COLORS["twoLight"]),
    ('Metaheuristics', 3, 2, BRAND_COLORS["oneDark"]),
    ('Exact Methods', 4, 1, BRAND_COLORS["twoDark"])
]

for name, bottom, width, color in levels:
    # Draw trapezoid
    left = (5 - width/2)
    right = (5 + width/2)
    vertices = [(left, bottom), (right, bottom), 
                (right-0.5, bottom+1), (left+0.5, bottom+1)]
    poly = plt.Polygon(vertices, facecolor=color, edgecolor='black', 
                       alpha=0.7, linewidth=2)
    ax.add_patch(poly)
    
    # Add text
    ax.text(5, bottom + 0.5, name, ha='center', va='center', 
            fontsize=12, fontweight='bold', color='white' if name != 'Random' else 'black')

# Add labels
ax.text(1, 0.5, '⚡ FAST', fontsize=10, fontweight='bold', color='green')
ax.text(1, 4.5, '🎯 OPTIMAL', fontsize=10, fontweight='bold', color='red')
ax.text(9, 0.5, '😊 SIMPLE', fontsize=10, fontweight='bold', color='blue')
ax.text(9, 4.5, '🤯 COMPLEX', fontsize=10, fontweight='bold', color='purple')

ax.set_xlim(0, 10)
ax.set_ylim(0, 6)
ax.axis('off')
ax.set_title('Always Start at the Bottom!', fontsize=16, fontweight='bold', pad=20)

plt.tight_layout()
plt.show()
```

## Additional Resources

[Expand your knowledge with these curated resources:]{.highlight}

::: columns
::: {.column width="50%"}
**Learn More:**
- [Essentials of Metaheuristics](https://cs.gmu.edu/~sean/book/metaheuristics/) (free book)
- [Google OR-Tools](https://developers.google.com/optimization)
- [DEAP Python Library](https://deap.readthedocs.io/) for GA
- [SimPy](https://simpy.readthedocs.io/) for simulation

**Practice Problems:**
- Vehicle Routing (VRP)
- Job Shop Scheduling
- Knapsack variants
- Portfolio optimization
:::

::: {.column width="50%"}
**AI Assistant Prompts:**
```text
# Template for any problem:
"I need to solve [problem type] with:
- Variables: [list them]
- Constraints: [list them]  
- Objective: [minimize/maximize what]
- Data: [provide sample]

Implement [specific algorithm] with:
- [Parameter 1]: [value]
- [Parameter 2]: [value]
Please include comments."
```
:::
:::

## Final Thoughts

[The journey from local to global optimization:]{.highlight}

> "All models are wrong, but some are useful" - George Box

. . .

> "Perfect is the enemy of good" - Voltaire

. . .

> "Start where you are. Use what you have. Do what you can." - Arthur Ashe

. . .

[You now have a complete optimization toolkit. Use it wisely!]{.success}

## Break!

[Great work! Time for a well-deserved break!]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(10, 8))

# Fun visualization of all methods working together
np.random.seed(789)

# Create solution landscape
x = np.linspace(0, 10, 100)
y = 1500 - 100*np.sin(x) - 50*np.sin(3*x) - 30*np.sin(5*x)

ax.fill_between(x, 1200, y, alpha=0.1, color='blue')
ax.plot(x, y, 'b-', linewidth=2, alpha=0.5)

# Show different algorithm paths
# Random jumps
random_x = np.random.uniform(0, 10, 10)
random_y = [1500 - 100*np.sin(xi) - 50*np.sin(3*xi) - 30*np.sin(5*xi) + np.random.randn()*20 
            for xi in random_x]
ax.scatter(random_x, random_y, color='gray', s=30, alpha=0.5, label='Random')

# Greedy path
greedy_x = [2]
greedy_y = [1500 - 100*np.sin(2) - 50*np.sin(6) - 30*np.sin(10)]
ax.scatter(greedy_x, greedy_y, color='orange', s=100, marker='o', label='Greedy')

# Local search
local_x = [3.5]
local_y = [1420]
ax.scatter(local_x, local_y, color='red', s=100, marker='s', label='Local Search')

# SA path
sa_x = np.linspace(3.5, 7.5, 20)
sa_y = [1420 - (xi-3.5)*20 + np.random.randn()*10 for xi in sa_x]
ax.plot(sa_x, sa_y, 'b-', alpha=0.5, linewidth=2, label='SA Path')

# GA population
ga_x = np.random.normal(7.5, 0.5, 10)
ga_y = [1380 + np.random.randn()*5 for _ in ga_x]
ax.scatter(ga_x, ga_y, color='green', s=50, alpha=0.7, label='GA Population')

# Global optimum
ax.scatter([7.5], [1350], color='gold', s=300, marker='*', 
          edgecolor='black', linewidth=2, zorder=10, label='Global Optimum')

ax.set_xlabel('Solution Space', fontsize=12)
ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('The Complete Optimization Journey', fontsize=16, fontweight='bold')
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)
ax.set_ylim(1300, 1700)

# Add annotations
ax.annotate('Start', xy=(2, 1600), xytext=(1, 1650),
            arrowprops=dict(arrowstyle='->', color='orange'),
            fontsize=10, color='orange')
ax.annotate('Trapped!', xy=(3.5, 1420), xytext=(2.5, 1350),
            arrowprops=dict(arrowstyle='->', color='red'),
            fontsize=10, color='red')
ax.annotate('Escape!', xy=(5.5, 1400), xytext=(5.5, 1500),
            arrowprops=dict(arrowstyle='->', color='blue'),
            fontsize=10, color='blue')
ax.annotate('Success!', xy=(7.5, 1350), xytext=(8.5, 1450),
            arrowprops=dict(arrowstyle='->', color='gold'),
            fontsize=12, color='gold', fontweight='bold')

plt.tight_layout()
plt.show()
```

[Ready to optimize? Let's tackle the restaurant challenge!]{.flow}
