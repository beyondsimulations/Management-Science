---
title: "Introduction to Metaheuristics"
subtitle: "Lecture 9 - Management Science"
author: "Dr. Tobias Vlćek"
format:
  revealjs:
    footer: " {{< meta title >}} | {{< meta author >}} | [Home](lec_09_metaheuristics.qmd)"
    output-file: lec_09_presentation.html
---

# [Introduction]{.flow} {.title}

## **[Client Briefing: La Étoile]{.invert-font}** {background-image="https://unsplash.com/photos/Vd0_Htlb-Kk/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8Mjh8fHJlc3RhdXJhbnQlMjBtaWNoZWxpbnxlbnwwfHx8fDE3NjMyOTQ2OTR8MA&force=true&w=2400" background-size="cover"}

. . .

[Restaurant Manager's Crisis:]{.invert-font}

["I need to schedule my [18 servers across 6 shifts]{.highlight} this weekend. Shifts have [different lengths (4-6 hours)]{.highlight}, and if I don't have enough experienced servers on busy shifts, we face [penalties ranging from €150 to €400]{.highlight} per missing experienced server!"]{.invert-font .fragment}

## The Staffing Challenge

[A restaurant facing a weekend scheduling crisis:]{.highlight}

**La Étoile's Problem:**

::: {.incremental}
- 18 servers available (6 experienced @ €75/hr, 12 junior @ €25/hr)
- 6 shifts with **varying lengths** (4-6 hours each)
- Each shift needs 3 servers (at least 1 experienced)
- Server **preferences** matter (1-10 scale, affects quality)
:::

. . .

[Question:]{.question} How to balance labor costs, penalties, AND staff?

## The Cost Impact: Why This Matters

[The financial stakes are significant with these large penalties:]{.highlight}

::: {.incremental}
- **Minimum Labor Cost**: ~€3,500 (everyone works once)
- **Experience Penalties**: €0-€1,200 per missing experienced server
- **Preference Penalties**: €0-€180 per unhappy assignment
- **Worst Case**: Over €7,000 if poorly scheduled!
- **Best Case**: ??? with smart optimization
:::

. . .

:::{.callout-important}
Potentially up to **€3,500 difference** between good and bad scheduling!
:::

## Restaurant Staffing: The Numbers

[The real-world complexity we're dealing with:]{.highlight}

```{python}
#| echo: false
#| eval: true

import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, create_plot, BRAND_COLORS, PLOT_COLORS

# Apply clean brand style
setup_clean_style()

# Calculate the combinatorial explosion
from math import comb

# Problem parameters with new complexity
n_servers = 18
n_shifts = 6
servers_per_shift = 3
shift_hours = [5, 4, 4, 6, 5, 6]  # Varying shift lengths
penalties = [800, 0, 500, 1200, 600, 1000]  # Large penalties per shift

# Calculate possibilities
ways_per_shift = comb(18, 3)
total_ways = ways_per_shift ** 6

# Create visualization
fig, axes = plt.subplots(1, 3)

# Left: Shift complexity
ax = axes[0]
shift_names = ['Fri D', 'Fri L', 'Sat L', 'Sat D', 'Sun L', 'Sun D']
x = range(len(shift_names))
width = 0.35
bars1 = ax.bar([i - width/2 for i in x], shift_hours, width, 
               label='Hours', color=BRAND_COLORS["oneDark"], alpha=0.7)
bars2 = ax.bar([i + width/2 for i in x], [p/100 for p in penalties], width,
               label='Penalty (€100s)', color=BRAND_COLORS["threeDark"], alpha=0.7)
ax.set_xlabel('Shift', fontsize=12)
ax.set_ylabel('Value', fontsize=12)
ax.set_title('Varying Complexity by Shift', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(shift_names)

# Add value labels
for bar, val in zip(bars1, shift_hours):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{val}h', ha='center', va='bottom', fontsize=10, fontweight='bold')
for bar, val in zip(bars2, penalties):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=10, fontweight='bold')

# Middle: Constraint satisfaction
ax = axes[1]
categories = ['Total\nServers', 'Experienced\nNeeded', 'Experienced\nAvailable']
values = [18, 8, 6]
colors = [BRAND_COLORS["twoDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"]]
bars = ax.bar(categories, values, color=colors, alpha=0.7)
ax.set_ylabel('Count', fontsize=12)
ax.set_title('The Constraint Violation', fontsize=14, fontweight='bold')
ax.axhline(y=6, color='red', linestyle='--', linewidth=2, alpha=0.5)
ax.text(1, 6.5, 'Shortage!', ha='center', fontsize=11, color='red', fontweight='bold')

# Add value labels on bars
for bar, val in zip(bars, values):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

# Right: Three cost components
ax = axes[2]
components = ['Labor\nCost', 'Experience\nPenalties', 'Preference\nPenalties']
typical_costs = [3500, 1600, 800]  # Typical costs in euros
colors = [BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"], BRAND_COLORS["threeDark"]]
bars = ax.bar(components, typical_costs, color=colors, alpha=0.7)
ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('Three-Way Cost Optimization', fontsize=14, fontweight='bold')

# Add value labels
for bar, val in zip(bars, typical_costs):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
```

. . .

::: callout-warning
With varying shifts, preferences, and penalties, this is will be a real challenge!
:::

## Today's Objectives

[What you'll understand after this lecture:]{.highlight}

::: {.incremental}
1. **Why local search fails** - The local optima trap
2. **Escape mechanisms** - How to accept worse solutions strategically
3. **Four powerful metaheuristics** - SA, GA, Tabu Search, ACO
4. **Selection criteria** - When to use which algorithm
:::

## Hiking in Fog

[Remember the concept from our lecture?]{.highlight}

::: incremental
- **Goal**: Find the highest peak in a mountain range
- **Challenge**: You're hiking in thick fog (can only see 10 feet)
- **Position**: Your X,Y coordinates = your decisions
- **Altitude**: Your current solution quality
- **Problem**: You might climb a small hill and think it's the summit!
:::

. . .

::: callout-tip
This metaphor will guide us through all metaheuristics today!
:::

## Recap: Local Optima

[Real problems often have thousands of local optima!]{.highlight}

```{python}
#| eval: true
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.append('../helpers')
from plot_utils import BRAND_COLORS, setup_clean_style

setup_clean_style()

# Create a complex optimization landscape with many local optima
fig, ax = plt.subplots()

x = np.linspace(0, 20, 1000)
# Build a complex function with many peaks and valleys
# Start with a base trend
y = 5 + 0.1*x
# Add multiple sine/cosine waves of different frequencies
y += 1.5*np.sin(0.5*x)  # Long wavelength
y += 0.8*np.sin(2*x)     # Medium wavelength
y += 0.4*np.sin(5*x)     # Short wavelength
y += 0.3*np.cos(8*x)     # Even shorter
y += 0.2*np.sin(12*x)    # Very short wavelength
# Add some Gaussian valleys for local minima
y -= 0.8*np.exp(-(x-3)**2/0.3)   # Small local minimum
y -= 1.2*np.exp(-(x-7)**2/0.4)   # Medium local minimum
y -= 0.9*np.exp(-(x-11)**2/0.3)  # Another local minimum
y -= 5*np.exp(-(x-16)**2/0.5)    # Deep global minimum

ax.plot(x, y, color=BRAND_COLORS["twoDark"], linewidth=2, alpha=0.8)

# Find and mark several local minima
local_minima_x = [2.0, 7.27, 11.34, 13.55]
local_minima_labels = ['Local 1', 'Local 2', 'Local 3', 'Local 4']

for x_loc, label in zip(local_minima_x, local_minima_labels):
    y_loc = 5 + 0.1*x_loc
    y_loc += 1.5*np.sin(0.5*x_loc) + 0.8*np.sin(2*x_loc) + 0.4*np.sin(5*x_loc)
    y_loc += 0.3*np.cos(8*x_loc) + 0.2*np.sin(12*x_loc)
    y_loc -= 0.8*np.exp(-(x_loc-3)**2/0.3)
    y_loc -= 1.2*np.exp(-(x_loc-7)**2/0.4)
    y_loc -= 0.9*np.exp(-(x_loc-11)**2/0.3)
    y_loc -= 5*np.exp(-(x_loc-16)**2/0.5)

    ax.scatter([x_loc], [y_loc], color=BRAND_COLORS["threeDark"], s=200, zorder=3)

# Mark the global minimum
x_global = 16.05
y_global = 5 + 0.1*x_global
y_global += 1.5*np.sin(0.5*x_global) + 0.8*np.sin(2*x_global) + 0.4*np.sin(5*x_global)
y_global += 0.3*np.cos(8*x_global) + 0.2*np.sin(12*x_global)
y_global -= 0.8*np.exp(-(x_global-3)**2/0.3)
y_global -= 1.2*np.exp(-(x_global-7)**2/0.4)
y_global -= 0.9*np.exp(-(x_global-11)**2/0.3)
y_global -= 5*np.exp(-(x_global-16)**2/0.5)

ax.scatter([x_global], [y_global], color=BRAND_COLORS["oneDark"], s=200, zorder=4)
ax.annotate('GLOBAL\nMINIMUM', xy=(x_global, y_global), xytext=(x_global, y_global - 2),
            fontsize=11, ha='center', fontweight='bold',
            arrowprops=dict(arrowstyle='->', color=BRAND_COLORS["oneDark"], lw=2))

# Add shaded regions to show quality differences
ax.axhspan(ymin=ax.get_ylim()[0], ymax=y_global + 0.5, alpha=0.1, color='green', label='Excellent')
ax.axhspan(ymin=y_global + 0.5, ymax=4, alpha=0.1, color='yellow', label='Good')
ax.axhspan(ymin=4, ymax=6, alpha=0.1, color='orange', label='Mediocre')
ax.axhspan(ymin=6, ymax=ax.get_ylim()[1], alpha=0.1, color='red', label='Poor')

ax.set_xlabel('Solution Space (Different Route Configurations)', fontsize=12)
ax.set_ylabel('Total Distance (km)', fontsize=12)
ax.grid(True, alpha=0.3)

# Add text box with key insight
plt.tight_layout()
plt.show()
```

. . .

[Question:]{.question} Any idea on how to escape local optima?


# [Why Simple Methods Fail]{.flow} {.title}

## The Business Silo Problem

[Why department-level optimization fails at the company level:]{.highlight}

::: columns
::: {.column width="50%"}
**Technical View: Local Optima**
- Algorithm climbs nearest hill
- Gets stuck on "foothill"
- Can't see the mountain beyond
- Every move looks worse
- Believes it found the best solution
:::

::: {.column width="50%"}
**Business View: Department Silos**
- Sales optimizes sales metrics
- Engineering optimizes quality
- Finance optimizes costs
- Each department "wins"
- **But company performance suffers!**
:::
:::

. . .

::: {.callout-warning}
## Theory of Constraints Insight
A company is like connected pipes. Optimizing one section (Sales) while ignoring the bottleneck (Engineering) floods the system and makes everything worse. 

**Key Lesson**: Sum of local bests ≠ Global best
:::

## Why Greedy Gets Stuck

[Visualizing how greedy algorithms trap themselves:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Simulate greedy staffing
np.random.seed(42)

# Create schedule visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Left: Greedy assignment
ax = axes[0]
shifts = ['Fri L', 'Fri D', 'Sat L', 'Sat D', 'Sun L', 'Sun D']
experienced_assignment = [2, 1, 1, 1, 1, 0]  # Greedy uses best first
junior_assignment = [1, 2, 2, 2, 2, 3]

x = np.arange(len(shifts))
width = 0.35

bars1 = ax.bar(x - width/2, experienced_assignment, width, label='Experienced', 
               color=BRAND_COLORS["oneDark"], alpha=0.8)
bars2 = ax.bar(x + width/2, junior_assignment, width, label='Junior',
               color=BRAND_COLORS["twoLight"], alpha=0.8)

ax.set_xlabel('Shift', fontsize=12)
ax.set_ylabel('Servers Assigned', fontsize=12)
ax.set_title('Greedy Assignment (Front-loaded)', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(shifts)
ax.legend()
ax.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Min Experienced Required')

# Highlight problem
ax.add_patch(plt.Rectangle((4.5, -0.5), 1, 4, fill=True, 
                          color='red', alpha=0.2))
ax.text(5, 3.5, 'No experienced\nfor Sunday!', ha='center', fontsize=10, 
        color='red', fontweight='bold')

# Right: Cost breakdown
ax = axes[1]
costs = ['Labor\n(€1,140)', 'Penalty\n(€500)', 'Total\n(€1,640)']
values = [1140, 500, 1640]
colors = [BRAND_COLORS["twoLight"], BRAND_COLORS["threeDark"], BRAND_COLORS["darker"]]
bars = ax.bar(costs, values, color=colors, alpha=0.7)

for bar, val in zip(bars, values):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'€{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')

ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('Greedy Solution Cost', fontsize=14, fontweight='bold')
ax.grid(True, axis='y', alpha=0.3)

plt.tight_layout()
plt.show()
```

[Greedy allocates resources early, creating problems later!]{.warning}

## Local Search Also Struggles

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Visualize local search getting stuck
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Left: Solution landscape
ax = axes[0]
x = np.linspace(0, 10, 200)
y = 1600 - 100*np.sin(x) - 50*np.sin(3*x) - 30*np.sin(5*x)

ax.plot(x, y, color=BRAND_COLORS["twoDark"], linewidth=2, alpha=0.7)
ax.fill_between(x, 1200, y, alpha=0.1, color=BRAND_COLORS["twoLight"])

# Mark positions
greedy_x, greedy_y = 3.5, 1640
local_x, local_y = 4.8, 1520  
global_x, global_y = 7.5, 1380

ax.scatter([greedy_x], [greedy_y], color=BRAND_COLORS["oneDark"], s=200, marker='o', zorder=5, label='Greedy Start')
ax.scatter([local_x], [local_y], color=BRAND_COLORS["threeDark"], s=200, marker='*', zorder=5, label='Local Optimum')
ax.scatter([global_x], [global_y], color=BRAND_COLORS["twoDark"], s=200, marker='*', zorder=5, label='Global Optimum')

# Show local search path
ax.arrow(greedy_x, greedy_y, local_x-greedy_x-0.1, local_y-greedy_y+5,
         head_width=0.2, head_length=5, fc=BRAND_COLORS["oneDark"], ec=BRAND_COLORS["oneDark"], alpha=0.7)

# Show barrier
ax.axvspan(local_x+0.5, global_x-0.5, alpha=0.2, color=BRAND_COLORS["darker"])
ax.text(6, 1700, 'Can\'t climb\nthis hill!', ha='center', fontsize=10, 
        color=BRAND_COLORS["threeDark"], fontweight='bold')

ax.set_xlabel('Solution Space', fontsize=12)
ax.set_ylabel('Total Cost (€)', fontsize=12)
ax.set_title('Local Search Trapped in Local Minimum', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# Right: Neighborhood structure
ax = axes[1]
# Create network of neighbors
from matplotlib.patches import Circle, FancyArrow

center = (0.5, 0.5)
neighbors = [(0.3, 0.7), (0.7, 0.7), (0.3, 0.3), (0.7, 0.3),
             (0.5, 0.8), (0.5, 0.2), (0.2, 0.5), (0.8, 0.5)]

# Draw center
circle = Circle(center, 0.08, color=BRAND_COLORS["threeDark"], alpha=0.7)
ax.add_patch(circle)
ax.text(center[0], center[1], 'Current\n€1520', ha='center', va='center', 
        fontsize=9, fontweight='bold', color='white')

# Draw neighbors
for i, (x, y) in enumerate(neighbors):
    cost = 1520 + np.random.randint(10, 100)
    circle = Circle((x, y), 0.06, color=BRAND_COLORS["darker"], alpha=0.3)
    ax.add_patch(circle)
    ax.text(x, y, f'€{cost}', ha='center', va='center', fontsize=8)
    
    # Draw edge
    ax.plot([center[0], x], [center[1], y], 'k-', alpha=0.2, linewidth=1)

ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_aspect('equal')
ax.axis('off')
ax.set_title('All Neighbors Worse → Stuck!', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()
```

[We need mechanisms to accept temporary degradation!]{.highlight}

# [Mathematical Foundations]{.flow} {.title}

## Core Concepts: The Toolbox

[The fundamental components of all metaheuristics:]{.highlight}

::: columns
::: {.column width="50%"}
**What We're Working With**
- **Solution** = One complete schedule/route/plan
- **Neighbor** = A slightly modified version
- **Cost** = How good/bad the solution is
- **Temperature** = How adventurous we are

**The Strategy**
- Always accept improvements ✓
- Sometimes accept worse solutions (the trick!)
- Start adventurous, become conservative
:::

::: {.column width="50%"}
**Business Parallel**
- **Startup Phase**: Try risky pivots (high temp)
- **Growth Phase**: Selective risks (medium temp)
- **Mature Phase**: Only proven improvements (low temp)

**Why It Works**
- Escapes local traps
- Explores broadly first
- Exploits good areas later
- Balances risk and reward
:::
:::

. . .

[Think of it as strategic risk-taking that decreases over time!]{.highlight}

# [Metaheuristic #1: Simulated Annealing]{.flow} {.title}

## The Metallurgy Metaphor

[How annealing steel inspired a powerful optimization algorithm:]{.highlight}

::: columns
::: {.column width="50%"}
**Annealing Metal:**
1. Heat to high temperature
2. Atoms move freely
3. Slowly cool down
4. Forms perfect crystal structure

**Key insight**: Temperature controls randomness
:::

::: {.column width="50%"}
**Optimization:**
1. Start with high "temperature"
2. Accept bad moves often
3. Gradually reduce temperature
4. Converge to good solution

**Key insight**: Escape local optima early
:::
:::

. . .

[The Key Insight:]{.highlight}

**Hot temperature** = Accept almost any change (exploring)  
**Warm temperature** = Sometimes accept worse (selective)  
**Cold temperature** = Only accept improvements (exploiting)

. . .

[The willingness to temporarily accept worse solutions is what enables finding the true summit!]{.highlight}

## Temperature Controls Acceptance

[The probability of accepting worse solutions decreases with temperature:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

temperatures = [1000, 100, 10]
titles = ['Hot (T=1000): Accept Almost Anything', 
          'Warm (T=100): Getting Pickier', 
          'Cold (T=10): Only Improvements']

for ax, T, title in zip(axes, temperatures, titles):
    delta_costs = np.linspace(-500, 500, 100)
    probabilities = np.exp(-np.maximum(0, delta_costs) / T)
    
    ax.plot(delta_costs, probabilities, linewidth=3, color=BRAND_COLORS["twoDark"])
    ax.fill_between(delta_costs, 0, probabilities, alpha=0.3, color=BRAND_COLORS["twoLight"])
    ax.set_xlabel('Cost Change (Δ)', fontsize=11)
    ax.set_ylabel('Acceptance Probability', fontsize=11)
    ax.set_title(title, fontsize=12, fontweight='bold')
    ax.set_ylim(0, 1.1)
    ax.grid(True, alpha=0.3)
    ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)
    ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.3)
    
    # Add annotations with acceptance probabilities
    if T == 1000:
        ax.text(200, 0.82, f'P = {np.exp(-200/T):.2f}', 
                ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))
        ax.plot([200], [np.exp(-200/T)], 'ro', markersize=8)
    elif T == 100:
        ax.text(200, 0.14, f'P = {np.exp(-200/T):.2f}', 
                ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='orange', alpha=0.3))
        ax.plot([200], [np.exp(-200/T)], 'ro', markersize=8)
    else:
        ax.text(200, 0.05, f'P ≈ 0', 
                ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))

plt.tight_layout()
plt.show()
```

## Simulated Annealing: Implementation

[The core algorithm in Python:]{.highlight}

```python
#| echo: true
#| eval: false

# CONCEPT: How Simulated Annealing Works (Pseudocode)
def simulated_annealing_concept(current_schedule):
    """
    The 'smart hiking' algorithm that can go downhill
    """
    temperature = 1000  # Start "hot" (very adventurous)
    best_schedule = current_schedule
    
    while temperature > 1:
        # Step 1: Try a random change (like swapping two shifts)
        new_schedule = make_random_change(current_schedule)
        
        # Step 2: Is it better?
        if cost(new_schedule) < cost(current_schedule):
            current_schedule = new_schedule  # Always accept improvements
        else:
            # THE MAGIC: Sometimes accept worse solutions!
            # Hot temperature = more likely to accept
            # Cold temperature = less likely to accept
            if random() < acceptance_probability(temperature):
                current_schedule = new_schedule  # Accept anyway!
        
        # Step 3: Cool down (become less adventurous)
        temperature = temperature * 0.95
        
        # Remember the best we've ever seen
        if cost(current_schedule) < cost(best_schedule):
            best_schedule = current_schedule
    
    return best_schedule

print("Key insight: Accepting temporary setbacks enables long-term success!")
```

## SA in Action: Restaurant Staffing

[Calculating the cost of a staffing schedule:]{.highlight}

```{python}
#| echo: true
#| eval: false

# CONCEPT: The Restaurant Scheduling Problem with Real Complexity
"""
What we're trying to solve:
- 18 servers (6 experienced @ €75/hr, 12 junior @ €25/hr)
- 6 shifts with DIFFERENT lengths: [5, 4, 4, 6, 5, 6] hours
- Large penalties per shift: [€800, €0, €500, €1200, €600, €1000]
- Server preferences (1-10): affects quality & happiness
- THREE cost components to minimize!

Why it's REALLY hard now:
- Can't just assign all experienced to early shifts (greedy fails)
- Need to balance cost vs coverage
- Too many combinations to check all
"""

def restaurant_cost_concept(schedule, shift_hours, penalties, preferences):
    """
    Calculate THREE cost components with varying complexity
    """
    labor_cost = 0
    penalty_cost = 0
    preference_cost = 0
    
    for shift_idx, shift_servers in enumerate(schedule):
        # Component 1: Labor (varies by shift length!)
        hours = shift_hours[shift_idx]  # 4-6 hours
        for server in shift_servers:
            if is_experienced(server):
                labor_cost += 75 * hours  # €75/hr
            else:
                labor_cost += 25 * hours  # €25/hr
        
        # Component 2: Experience penalties (strategic choices)
        if count_experienced(shift_servers) < required:
            penalty_cost += penalties[shift_idx]  # €0-€1200
        
        # Component 3: Preference penalties (happiness matters!)
        for server in shift_servers:
            pref = preferences[server][shift_idx]  # 1-10 scale
            preference_cost += (10 - pref) * 20  # €0-€180 per assignment
    
    return labor_cost + penalty_cost + preference_cost

def make_neighbor(schedule, preferences):
    """
    Create a 'neighbor' by swapping two servers
    Smart: Consider preferences when swapping!
    """
    # Pick two shifts and swap servers
    # Prefer swaps that improve preferences
    return schedule_with_preference_aware_swap

print("The challenge: Balance THREE competing objectives across varying shifts!")
```

## Visualizing SA Performance

[How temperature affects the search behavior:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Simulate SA performance on restaurant problem
np.random.seed(456)

# Run simulated annealing (simplified for visualization)
iterations = range(0, 101, 5)
greedy_cost = [1640] * len(iterations)
sa_costs = []
temperatures = []
best_costs = []

current_cost = 1640
best_cost = 1640
temp = 1000

for i in iterations:
    temp = 1000 * (0.95 ** i)
    temperatures.append(temp)
    
    # Simulate cost evolution
    if i < 20:
        # High temp: exploring wildly
        current_cost = 1640 + np.random.randn() * 100
    elif i < 60:
        # Medium temp: converging
        current_cost = 1540 - (i-20) * 2 + np.random.randn() * 30
    else:
        # Low temp: fine-tuning
        current_cost = 1420 + np.random.randn() * 10
    
    current_cost = max(1380, min(1700, current_cost))
    best_cost = min(best_cost, current_cost)
    sa_costs.append(current_cost)
    best_costs.append(best_cost)

fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)

# Top: Cost over time
ax = axes[0]
ax.plot(iterations, greedy_cost, color=BRAND_COLORS["threeDark"], linestyle='--', linewidth=2, label='Greedy (stuck)', alpha=0.7)
ax.plot(iterations, sa_costs, color=BRAND_COLORS["twoLight"], linewidth=1, alpha=0.5, label='SA Current')
ax.plot(iterations, best_costs, color=BRAND_COLORS["twoDark"], linewidth=3, label='SA Best')
ax.fill_between(iterations, greedy_cost, best_costs, 
                 where=[b < g for b, g in zip(best_costs, greedy_cost)],
                 color=BRAND_COLORS["twoDark"], alpha=0.2, label='Improvement')
ax.set_ylabel('Total Cost (€)', fontsize=12)
ax.set_title('Simulated Annealing Escapes Local Optimum', fontsize=14, fontweight='bold')
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)
ax.set_ylim(1350, 1750)

# Add annotations for phases
ax.axvspan(0, 20, alpha=0.1, color=BRAND_COLORS["threeDark"], label='Exploration')
ax.axvspan(20, 60, alpha=0.1, color=BRAND_COLORS["oneDark"], label='Transition')
ax.axvspan(60, 100, alpha=0.1, color=BRAND_COLORS["twoDark"], label='Exploitation')

# Bottom: Temperature
ax = axes[1]
ax.plot(iterations, temperatures, color=BRAND_COLORS["twoDark"], linewidth=3)
ax.fill_between(iterations, 0, temperatures, color=BRAND_COLORS["twoLight"], alpha=0.3)
ax.set_xlabel('Iteration', fontsize=12)
ax.set_ylabel('Temperature', fontsize=12)
ax.set_title('Cooling Schedule (Geometric: T = T₀ × 0.95ᵗ)', fontsize=12)
ax.grid(True, alpha=0.3)
ax.set_yscale('log')

# Add phase labels
ax.text(10, 500, 'EXPLORE\n(Accept bad)', ha='center', fontsize=10, fontweight='bold', color='red')
ax.text(40, 50, 'TRANSITION\n(Balance)', ha='center', fontsize=10, fontweight='bold', color='orange')
ax.text(80, 5, 'EXPLOIT\n(Refine)', ha='center', fontsize=10, fontweight='bold', color='blue')

plt.tight_layout()
plt.show()
```

[Notice: SA accepts worse solutions early, enabling escape from local optima!]{.highlight}

## Common SA Mistakes: Implementation

[Avoid these common implementation errors:]{.highlight}

**Mistake #1: Starting Too Cold**
- If temperature is too low → Acts like greedy (no exploration)
- Fix: Start hot enough to accept bad moves (test with 50% acceptance rate initially)

**Mistake #2: Cooling Too Quickly**
- If you cool fast → Get stuck early
- Fix: Cool slowly (multiply by 0.95-0.99, not 0.5)

. . .

::: {.callout-warning}
Quick cooling is tempting for speed, but defeats the purpose of SA!
:::

## Common SA Mistakes: Conceptual

[Understanding why SA works prevents these errors:]{.highlight}

**Mistake #3: Forgetting the Best**
- Current solution might get worse near the end
- Fix: Always track the best ever found separately from current

**Mistake #4: Not Understanding "Why"**
- SA works because it escapes local traps through controlled randomness
- Without bad move acceptance, it's just expensive hill climbing!

. . .

::: {.callout-note}
In Tutorial 9.2, you'll tune these parameters for the restaurant problem!
:::

# [Metaheuristic #2: Genetic Algorithms]{.flow} {.title}

## Evolution as Optimization

[How natural selection inspires computational optimization:]{.highlight}

::: columns
::: {.column width="50%"}
**Natural Selection:**
1. Population of individuals
2. Fittest survive & reproduce
3. Offspring inherit traits
4. Mutations create diversity
5. Evolution finds adaptation

**Darwin's insight**: Survival of the fittest
:::

::: {.column width="50%"}
**Optimization:**
1. Population of solutions
2. Best solutions selected
3. Crossover combines solutions
4. Mutation adds variation
5. Evolution finds optimum

**Our insight**: Parallel exploration
:::
:::

. . .

[The Business Analogy:]{.highlight}

Just like successful products get more market share, better solutions get more "offspring" in the next generation. It's survival of the fittest - but for schedules, routes, or designs!

## The Genetic Process

[The four stages of genetic algorithm evolution:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# 1. Selection
ax = axes[0, 0]
fitness_scores = [1380, 1420, 1460, 1500, 1540, 1580, 1620, 1660, 1700, 1740]
colors = [BRAND_COLORS["oneDark"] if f <= 1500 else BRAND_COLORS["threeDark"] for f in fitness_scores]
bars = ax.bar(range(10), fitness_scores, color=colors, alpha=0.7)
ax.set_title('1. Selection: Tournament Selection', fontsize=12, fontweight='bold')
ax.set_ylabel('Cost (€)')
ax.set_xlabel('Solution in Population')
ax.axhline(y=1500, color='red', linestyle='--', label='Selection threshold')
ax.legend()

# Highlight tournament
ax.add_patch(plt.Rectangle((2.5, 1350), 3, 400, fill=False, 
                          edgecolor=BRAND_COLORS["twoDark"], linewidth=3))
ax.text(4, 1750, 'Tournament\n(pick best)', ha='center', color=BRAND_COLORS["twoDark"], fontweight='bold')

# 2. Crossover
ax = axes[0, 1]
ax.axis('off')
ax.text(0.5, 0.85, 'Parent 1: [[0,1,2], [3,4,5], ...]', fontsize=11, ha='center', 
        bbox=dict(boxstyle='round', facecolor=BRAND_COLORS["oneLight"]))
ax.text(0.5, 0.70, 'Parent 2: [[6,7,8], [9,10,11], ...]', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor=BRAND_COLORS["twoLight"]))
ax.arrow(0.5, 0.65, 0, -0.1, head_width=0.02, head_length=0.02, fc='black', ec='black')
ax.text(0.5, 0.45, 'Uniform Crossover (50% each)', fontsize=10, ha='center', style='italic')
ax.text(0.5, 0.30, 'Child: [[0,1,2], [9,10,11], ...]', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor='yellow'))
ax.set_title('2. Crossover: Combine Good Solutions', fontsize=12, fontweight='bold')

# 3. Mutation
ax = axes[1, 0]
ax.axis('off')
ax.text(0.5, 0.7, 'Before: [[0,1,2], [3,4,5]]', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor=BRAND_COLORS["oneLight"]))
ax.arrow(0.5, 0.6, 0, -0.1, head_width=0.02, head_length=0.02, fc='black', ec='black')
ax.text(0.5, 0.4, 'After: [[0,4,2], [3,1,5]]', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor='orange'))
ax.text(0.5, 0.25, 'Swap servers between shifts!', fontsize=10, ha='center', color='red')
ax.set_title('3. Mutation: Explore New Solutions', fontsize=12, fontweight='bold')
ax.text(0.5, 0.1, f'Probability = {0.1:.0%}', fontsize=10, ha='center', style='italic')

# 4. Population Evolution
ax = axes[1, 1]
generations = range(0, 101, 10)
best = [1640, 1580, 1520, 1480, 1450, 1430, 1415, 1405, 1395, 1385, 1380]
average = [1750, 1650, 1580, 1520, 1480, 1450, 1430, 1420, 1410, 1400, 1395]
worst = [1900, 1750, 1650, 1580, 1540, 1500, 1480, 1460, 1450, 1440, 1430]

ax.plot(generations, best, 'g-', linewidth=3, label='Best', marker='o')
ax.plot(generations, average, 'b-', linewidth=2, label='Average', marker='s')
ax.plot(generations, worst, 'r-', linewidth=1, label='Worst', marker='^', alpha=0.5)
ax.set_xlabel('Generation', fontsize=11)
ax.set_ylabel('Cost (€)', fontsize=11)
ax.set_title('4. Population Evolution', fontsize=12, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

[Evolution drives the population toward better solutions!]{.highlight}

## GA vs SA: Head-to-Head

[Comparing exploration strategies of both algorithms:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Compare GA and SA performance
np.random.seed(789)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Left: Convergence comparison
ax = axes[0]
iterations = range(0, 101, 5)

# SA performance (from earlier)
sa_best = []
temp = 1000
current = 1640
best_sa = 1640
for i in iterations:
    temp *= 0.95
    if i < 40:
        current = 1640 - i*5 + np.random.randn() * 30
    else:
        current = 1440 - (i-40) + np.random.randn() * 10
    current = max(1380, min(1700, current))
    best_sa = min(best_sa, current)
    sa_best.append(best_sa)

# GA performance
ga_best = []
ga_avg = []
for i in iterations:
    if i < 30:
        best = 1640 - i*6
        avg = 1750 - i*3
    else:
        best = 1460 - (i-30)*1.2
        avg = 1550 - (i-30)*0.8
    ga_best.append(max(1380, best + np.random.randn() * 5))
    ga_avg.append(max(1450, avg + np.random.randn() * 10))

ax.plot(iterations, sa_best, color=BRAND_COLORS["oneDark"], linewidth=3, label='SA (single solution)')
ax.plot(iterations, ga_best, color=BRAND_COLORS["twoDark"], linewidth=3, label='GA (best in population)')
ax.plot(iterations, ga_avg, color=BRAND_COLORS["twoLight"], linewidth=1, alpha=0.5, label='GA (population average)')
ax.set_xlabel('Iteration', fontsize=12)
ax.set_ylabel('Best Cost Found (€)', fontsize=12)
ax.set_title('Convergence Comparison', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)
ax.set_ylim(1350, 1700)

# Right: Exploration patterns
ax = axes[1]
# Create 2D landscape
x = np.linspace(0, 10, 100)
y = np.linspace(0, 10, 100)
X, Y = np.meshgrid(x, y)
Z = 1500 + 100*np.sin(X/2) + 100*np.cos(Y/2) + 50*np.sin(X*Y/10)

contour = ax.contour(X, Y, Z, levels=15, alpha=0.3)
ax.clabel(contour, inline=True, fontsize=8)

# SA path (single wandering path)
sa_x = [2]
sa_y = [2]
for _ in range(30):
    sa_x.append(sa_x[-1] + np.random.randn() * 0.5)
    sa_y.append(sa_y[-1] + np.random.randn() * 0.5)

ax.plot(sa_x, sa_y, color=BRAND_COLORS["oneDark"], linewidth=2, alpha=0.7, label='SA path')
ax.scatter(sa_x[-1], sa_y[-1], color=BRAND_COLORS["oneDark"], s=100, marker='*')

# GA population (multiple points converging)
ga_pop_x = np.random.uniform(0, 10, 20)
ga_pop_y = np.random.uniform(0, 10, 20)
ax.scatter(ga_pop_x, ga_pop_y, color=BRAND_COLORS["twoDark"], s=50, alpha=0.5, label='GA population')
# Show convergence
ax.scatter([7], [7], color=BRAND_COLORS["twoDark"], s=200, marker='*', label='GA convergence')

ax.set_xlabel('Solution Dimension 1', fontsize=12)
ax.set_ylabel('Solution Dimension 2', fontsize=12)
ax.set_title('Exploration Patterns', fontsize=14, fontweight='bold')
ax.legend()
ax.set_xlim(0, 10)
ax.set_ylim(0, 10)

plt.tight_layout()
plt.show()
```

[SA explores sequentially, GA explores in parallel!]{.highlight}

## Common GA Mistakes: Population Issues

[Avoid these population-related errors:]{.highlight}

**Mistake #1: Everyone Becomes Identical**
- If all solutions look the same → Lost diversity
- Fix: More mutation, bigger population, tournament selection

**Mistake #2: Too Greedy in Selection**
- Only keeping the very best → Premature convergence  
- Fix: Keep some variety, even if not perfect (elitism of 10-20%)

. . .

::: {.callout-warning}
Diversity loss is the #1 killer of genetic algorithms!
:::

## Common GA Mistakes: Implementation Issues

[Technical pitfalls to watch out for:]{.highlight}

**Mistake #3: Breaking the Rules**
- Crossover might create invalid schedules
- Fix: Always check and repair after crossover/mutation

**Mistake #4: Evolution Too Slow**
- Population too large or too many generations
- Fix: Start small (50-100), tune based on convergence

. . .

::: {.callout-tip}
You'll encounter and fix these issues in Tutorial 9.1!
:::

# [More Metaheuristics]{.flow} {.title}

## Metaheuristic #3: Tabu Search

[Using memory to avoid cycling through bad solutions:]{.highlight}

::: columns
::: {.column width="50%"}
**The Concept:**
- Keep a "forbidden" list of recent moves
- Never repeat the same mistake twice (for a while)
- Forces exploration of new territory
- Eventually forgives old moves (short-term memory)
:::

::: {.column width="50%"}
**Business Parallel:**
- "Lessons learned" database
- "We tried that strategy - it failed"
- "That supplier was unreliable"
- Institutional memory prevents repeating mistakes!
:::
:::

. . .

[Tabu = Smart organizations that learn from history!]{.highlight}

## Tabu Search: Implementation

[The algorithm that remembers its mistakes:]{.highlight}

```python
#| echo: true
#| eval: false

def tabu_search_concept():
    """
    The algorithm with memory - avoids repeating mistakes
    """
    tabu_list = []  # Our "never again" list
    current_solution = initial_schedule
    best_solution = current_solution
    
    while not done:
        # Look at all possible moves
        possible_moves = get_all_neighbor_moves(current_solution)
        
        # Filter out the "forbidden" moves
        allowed_moves = []
        for move in possible_moves:
            if move not in tabu_list:  # Not forbidden
                allowed_moves.append(move)
        
        # Pick the best allowed move (even if worse!)
        best_move = select_best(allowed_moves)
        current_solution = apply(best_move)
        
        # Update best if improved
        if cost(current_solution) < cost(best_solution):
            best_solution = current_solution
        
        # Remember this move (add to tabu list)
        tabu_list.append(best_move)
        if len(tabu_list) > 10:  # Keep list size manageable
            tabu_list.pop(0)  # Forget oldest
    
    return best_solution
```

## Ant Colony Optimization: The Concept

[How ants find the shortest path to food:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

# Visualize ACO pheromone trails
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Create nodes for TSP
np.random.seed(123)
n_nodes = 8
node_x = np.random.uniform(0, 10, n_nodes)
node_y = np.random.uniform(0, 10, n_nodes)

titles = ['Initial: Equal Pheromones', 
          'After 10 Iterations: Trails Forming',
          'After 50 Iterations: Converged']

for idx, (ax, title) in enumerate(zip(axes, titles)):
    # Draw edges with pheromone intensity
    for i in range(n_nodes):
        for j in range(i+1, n_nodes):
            if idx == 0:
                # Initial: all equal
                alpha = 0.2
                width = 1
            elif idx == 1:
                # Forming: some stronger
                dist = np.sqrt((node_x[i]-node_x[j])**2 + (node_y[i]-node_y[j])**2)
                alpha = 0.1 + 0.5 * np.exp(-dist/5)
                width = alpha * 5
            else:
                # Converged: clear path
                # Define good path
                good_edges = [(0,1), (1,3), (3,5), (5,7), (7,6), (6,4), (4,2), (2,0)]
                if (i,j) in good_edges or (j,i) in good_edges:
                    alpha = 0.8
                    width = 5
                else:
                    alpha = 0.1
                    width = 0.5
            
            ax.plot([node_x[i], node_x[j]], [node_y[i], node_y[j]], 
                   color=BRAND_COLORS["darker"], alpha=alpha, linewidth=width)
    
    # Draw nodes
    ax.scatter(node_x, node_y, s=200, c=BRAND_COLORS["oneDark"], zorder=5)
    for i, (x, y) in enumerate(zip(node_x, node_y)):
        ax.text(x, y, str(i), ha='center', va='center', color='white', fontweight='bold')
    
    ax.set_title(title, fontsize=12, fontweight='bold')
    ax.set_xlim(-1, 11)
    ax.set_ylim(-1, 11)
    ax.set_aspect('equal')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

[Ants deposit pheromones, creating emergent intelligence!]{.highlight}

## Try It Yourself!

[Put your knowledge into practice with ACO:]{.highlight}

::: {.callout-note}
In **Tutorial 9.1**, you'll implement ACO for Bean Counter's delivery routing. You'll see how digital ants find optimal paths!
:::

## ACO: The Pheromone Evaporation Trick

[Why forgetting old paths helps find better ones:]{.highlight}

```python
#| echo: true
#| eval: false

# CONCEPT: Why Pheromones Work
def pheromone_update_concept():
    """
    The ant colony's learning mechanism
    """
    # Step 1: Evaporation (forgetting old paths)
    # Like how old customer reviews become less relevant
    for path in all_paths:
        pheromone[path] = pheromone[path] * 0.5  # Fade away
    
    # Step 2: Reinforcement (strengthening good paths)  
    # Like how popular restaurants get more customers
    for ant_route in this_iteration:
        if route_is_short:
            add_more_pheromone(route)  # Attract more ants!
```

. . .

## Why Evaporation Matters

[The power of forgetting in optimization:]{.highlight}

::: {.callout-important}
Without evaporation, the first decent path found becomes permanent. With evaporation, the colony can adapt when conditions change - just like businesses must forget outdated "best practices"!
:::

# [Decision Framework]{.flow} {.title}

## When to Use Which Metaheuristic?

[A practical decision guide for algorithm selection:]{.highlight}

```{python}
#| echo: false
#| eval: true

import pandas as pd

# Create comprehensive comparison table
comparison_data = {
    'Method': ['Random', 'Greedy', 'Local Search', 'Simulated Annealing', 
               'Genetic Algorithm', 'Tabu Search', 'Ant Colony'],
    'Time': ['⚡⚡⚡⚡', '⚡⚡⚡', '⚡⚡', '⚡⚡', '⚡', '⚡⚡', '⚡'],
    'Quality': ['⭐', '⭐⭐', '⭐⭐⭐', '⭐⭐⭐⭐', '⭐⭐⭐⭐', '⭐⭐⭐', '⭐⭐⭐⭐'],
    'Complexity': ['Trivial', 'Simple', 'Medium', 'Medium', 'High', 'Medium', 'High'],
    'Best For': ['Baseline', 'Quick decisions', 'Improvement', 'Single solution',
                 'Population-based', 'Avoiding cycles', 'Path problems'],
    'Parameters': ['None', '1-2', '2-3', '3-4', '5-6', '2-3', '4-5']
}

df = pd.DataFrame(comparison_data)

# Style the dataframe
styled_df = df.style.set_properties(**{
    'text-align': 'center',
    'font-size': '11pt',
})

from IPython.display import HTML, display
display(HTML(df.to_html(index=False, classes='table table-striped')))
```

. . .

[Choose based on: time available, solution quality needed, and problem structure]{.highlight}

## Algorithm Selection: The No Free Lunch Theorem

[Why there's no universal best algorithm:]{.highlight}

::: {.callout-note}
## No Universal Best
"No Free Lunch Theorem": No single algorithm is best for all problems. Your choice must match your problem structure:

- **Path/Network Problems** → ACO (pheromones for paths)
- **Scheduling Problems** → SA or Tabu (neighborhood swaps)
- **Complex Design** → GA (population diversity)
- **Continuous Optimization** → PSO (particle dynamics)
:::

## Implementation Strategy: Start Simple

[The recommended progression for solving optimization problems:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(12, 8))

# Create decision flow
# Start
ax.add_patch(plt.Rectangle((4.5, 8.5), 3, 1, fill=True, 
                          facecolor=BRAND_COLORS["oneLight"], edgecolor='black', linewidth=2))
ax.text(6, 9, 'START HERE', ha='center', va='center', fontsize=12, fontweight='bold')

# Time check
ax.add_patch(plt.Rectangle((1, 6.5), 3, 1, fill=True, 
                          facecolor='lightyellow', edgecolor='black', linewidth=1))
ax.text(2.5, 7, 'Time < 1 min?', ha='center', va='center', fontsize=11)

ax.add_patch(plt.Rectangle((8, 6.5), 3, 1, fill=True, 
                          facecolor='lightyellow', edgecolor='black', linewidth=1))
ax.text(9.5, 7, 'Problem type?', ha='center', va='center', fontsize=11)

# Recommendations
ax.add_patch(plt.Rectangle((0, 4), 2, 1, fill=True, 
                          facecolor='lightgreen', edgecolor='green', linewidth=2))
ax.text(1, 4.5, 'Use Greedy', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((2.5, 4), 2.5, 1, fill=True, 
                          facecolor='lightblue', edgecolor='blue', linewidth=2))
ax.text(3.75, 4.5, 'Greedy + Local', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((6, 4), 2, 1, fill=True, 
                          facecolor='orange', edgecolor='darkorange', linewidth=2))
ax.text(7, 4.5, 'Use SA', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((8.5, 4), 2, 1, fill=True, 
                          facecolor='lightcoral', edgecolor='red', linewidth=2))
ax.text(9.5, 4.5, 'Use GA', ha='center', va='center', fontsize=10, fontweight='bold')

ax.add_patch(plt.Rectangle((11, 4), 2, 1, fill=True, 
                          facecolor='plum', edgecolor='purple', linewidth=2))
ax.text(12, 4.5, 'Use ACO', ha='center', va='center', fontsize=10, fontweight='bold')

# Draw arrows
# From start
ax.arrow(6, 8.5, -3.3, -1.3, head_width=0.1, head_length=0.1, fc='black', ec='black')
ax.arrow(6, 8.5, 3.3, -1.3, head_width=0.1, head_length=0.1, fc='black', ec='black')

# From time check
ax.arrow(1.5, 6.5, -0.4, -1.3, head_width=0.1, head_length=0.1, fc='green', ec='green')
ax.text(1, 5.5, 'YES', ha='center', fontsize=9, color='green', fontweight='bold')

ax.arrow(3.5, 6.5, 0.2, -1.3, head_width=0.1, head_length=0.1, fc='blue', ec='blue')
ax.text(4, 5.5, 'NO', ha='center', fontsize=9, color='blue', fontweight='bold')

# From problem type
ax.arrow(8.5, 6.5, -1.4, -1.3, head_width=0.1, head_length=0.1, fc='orange', ec='orange')
ax.text(7.5, 5.5, 'Simple', ha='center', fontsize=9, color='orange')

ax.arrow(9.5, 6.5, 0, -1.3, head_width=0.1, head_length=0.1, fc='red', ec='red')
ax.text(9.5, 5.5, 'Complex', ha='center', fontsize=9, color='red')

ax.arrow(10.5, 6.5, 1.4, -1.3, head_width=0.1, head_length=0.1, fc='purple', ec='purple')
ax.text(11.5, 5.5, 'Routing', ha='center', fontsize=9, color='purple')

# Additional notes
ax.text(6, 2.5, 'Always start simple and add complexity only if needed!', 
        ha='center', fontsize=12, style='italic',
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

ax.text(6, 1.5, 'Use AI tools (ChatGPT/Copilot) to implement chosen method', 
        ha='center', fontsize=11, color='blue')

ax.set_xlim(-0.5, 13.5)
ax.set_ylim(0, 10)
ax.axis('off')
ax.set_title('Metaheuristic Selection Guide', fontsize=16, fontweight='bold', pad=20)

plt.tight_layout()
plt.show()
```

## Implementation Strategy: Practical Tips

[Essential guidelines for successful implementation:]{.highlight}

::: {.incremental}
1. **Start Simple**: Always try greedy first as baseline
2. **Profile Your Problem**: Understand constraints before choosing
3. **Tune Incrementally**: Don't optimize all parameters at once
   - SA: Initial temp ≈ max expected Δ
   - GA: Population ≈ 10 × variables
   - Tabu: Tenure ≈ √problem_size
4. **Track Progress**: Monitor convergence to know when to stop
5. **Hybrid Approaches**: Combine methods (e.g., GA + Local Search)
6. **Use AI Assistance**: Bridge the "expert gap" with GenAI
:::

. . .

::: {.callout-tip}
## Pro Tip
Most real-world problems are solved with greedy + local search. Only use metaheuristics when these fail!
:::

# [Mission Briefing]{.flow} {.title}

## Now It's Your Turn!

::: {.callout-important}
## Tutorial Practice
**Tutorial 9.1**: Implement these algorithms for Bean Counter's problems  
**Tutorial 9.2**: Apply them to the restaurant staffing competition  

You'll code the full versions and see these concepts in action!
:::

## Your Restaurant Challenge

[Apply what you've learned to solve La Étoile's complex problem:]{.highlight}

**Scenario**: La Étoile needs weekend staffing schedule

**Resources**:
- 18 servers (6 experienced @ €75/hr, 12 junior @ €25/hr)
- 6 shifts with **different lengths** (4-6 hours each)
- Large penalties (€0-€1200 per missing experienced)
- Server preferences (1-10 scale, affects quality)

**Three Cost Components to Balance**:
1. Labor cost (hourly rate × shift hours)
2. Experience penalties (strategic choices)
3. Preference penalties (staff happiness)

**Your Tools**:
1. Smart greedy (consider all factors)
2. Local search (preference-aware swaps)
3. Simulated annealing (escape local optima)
4. Genetic algorithm (evolve schedules)

. . .

[Remember: This is genuinely challenging - even greedy won't find the optimal!]{.highlight}

## Summary: From Local Silos to Global Success

[The transformation metaheuristics enable:]{.highlight}

::: columns
::: {.column width="50%"}
**The Journey**
- Started trapped in fog (local optima)
- Learned why greedy climbers fail
- Discovered intelligent escape mechanisms
- Mastered four metaheuristic strategies
- Connected algorithms to business thinking
:::

::: {.column width="50%"}
**The Transformation**
- From department silos → system thinking
- From local peaks → global optimum
- From rigid rules → adaptive exploration
- From single solutions → population wisdom
- From expert-only → AI-accessible tools
:::
:::

. . .

::: {.callout-tip}
## The Management Lesson
Just as SA accepts temporary downhill moves to find the summit, successful organizations accept short-term disruptions (new CRM, process changes) to achieve long-term excellence. 

**Remember**: The sum of optimized silos ≠ an optimized system!
:::

. . .

[You now have both the algorithms AND the mindset to solve complex optimization challenges!]{.success}

## Your Metaheuristics Cheat Sheet

[Quick reference for algorithm selection:]{.highlight}

| Situation | Use This | Because |
|-----------|----------|---------|
| Need answer in < 1 min | Smart Greedy | Consider all 3 costs upfront |
| Multiple cost components | Simulated Annealing | Balances competing objectives |
| Complex preferences | Genetic Algorithm | Evolves good compromises |
| Keep revisiting same bad solutions | Tabu Search | Memory prevents cycling |
| Varying constraints per shift | Local Search + SA | Adapt to different requirements |
| Don't know how to code it | GenAI + Template | Bridges the expert gap |

. . .

[Remember: Perfect is the enemy of good. Start simple, iterate, improve!]{.highlight}

## Break Time!

[Let's take a break before diving into tutorials!]{.highlight}

```{python}
#| echo: false
#| eval: true

fig, ax = plt.subplots(figsize=(10, 8))

# Restaurant scene
# Tables
tables_x = [2, 5, 8, 2, 5, 8]
tables_y = [6, 6, 6, 3, 3, 3]
for x, y in zip(tables_x, tables_y):
    rect = plt.Rectangle((x-0.7, y-0.5), 1.4, 1, 
                         facecolor=BRAND_COLORS["oneLight"], edgecolor=BRAND_COLORS["darker"], linewidth=2)
    ax.add_patch(rect)
    ax.text(x, y, '🍽️', ha='center', va='center', fontsize=20)

# Servers with optimization paths
np.random.seed(456)
colors = [BRAND_COLORS["oneDark"], BRAND_COLORS["threeDark"], BRAND_COLORS["twoDark"]]
methods = ['Greedy Path', 'SA Path', 'GA Best']

for idx, (color, method) in enumerate(zip(colors, methods)):
    # Create different paths
    if idx == 0:  # Greedy - straight lines
        path_x = [1, 2, 5, 8, 8]
        path_y = [1, 3, 3, 3, 6]
    elif idx == 1:  # SA - wandering
        path_x = [1, 2.5, 4, 5, 7, 8]
        path_y = [1, 2, 4, 6, 5, 6]
    else:  # GA - optimal
        path_x = [1, 2, 2, 5, 5, 8, 8]
        path_y = [1, 3, 6, 6, 3, 3, 6]
    
    ax.plot(path_x, path_y, color=color, linewidth=2, alpha=0.6, label=method)
    ax.scatter(path_x[-1], path_y[-1], color=color, s=100, marker='o', zorder=5)

# Title and labels
ax.text(5, 8, "La Étoile Restaurant", fontsize=18, fontweight='bold', ha='center')
ax.text(5, 7.3, 'Optimized Staffing Routes', fontsize=12, ha='center', style='italic')

ax.legend(loc='lower right', fontsize=10)
ax.set_xlim(0, 10)
ax.set_ylim(0, 9)
ax.axis('off')

plt.tight_layout()
plt.show()
```

[Time to practice with real problems!]{.flow}

## Genetic Algorithm Implementation

[The complete GA algorithm in Python:]{.highlight}

```{python}
#| echo: true
#| eval: false

# CONCEPT: How Genetic Algorithms Work (Simplified)
def genetic_algorithm_concept():
    """
    Evolution-inspired optimization
    """
    # Step 1: Create initial population (like random product designs)
    population = [create_random_schedule() for _ in range(50)]
    
    for generation in range(100):
        # Step 2: Evaluate fitness (like market testing)
        # Better schedules = higher fitness
        fitness_scores = [1/cost(schedule) for schedule in population]
        
        # Step 3: Selection (survival of the fittest)
        # Keep the best performers
        survivors = select_best_half(population)
        
        # Step 4: Crossover (combine successful features)
        # Like combining features from two successful products
        child1 = combine_schedules(parent1, parent2)
        
        # Step 5: Mutation (innovation)
        # Random small changes for diversity
        if random() < 0.1:  # 10% chance
            randomly_change(child1)
    
        # The cycle continues: evolve toward excellence!
        new_population = next_generation
    
    return best_schedule_ever_found

print("GA = Innovation through recombination and experimentation!")
```

# [Practical Implementation]{.flow} {.title}

## Using AI Tools Effectively: The Expert Gap

[How GenAI bridges the gap between business knowledge and technical implementation:]{.highlight}

::: {.callout-important}
## The Revolution
[The breakthrough that democratizes optimization:]{.highlight}

**The Problem**: Business managers understand constraints but can't code. Data scientists can code but don't understand the business.

**The Solution**: GenAI bridges this "expert gap" by translating business requirements into working code!
:::

::: columns
::: {.column width="50%"}
**The 5-Element Prompt Template:**
```text
ROLE: Expert in OR and Python metaheuristics

PROBLEM: Restaurant staff scheduling
- Variables: 18 staff (6 exp @ €75/hr, 12 jr @ €25/hr)
- 6 shifts with VARYING lengths: [5,4,4,6,5,6] hours
- Representation: {shift_id: [3 server_ids]}

CONSTRAINTS:
- Coverage: Exactly 3 staff per shift
- Skill: Need 1+ experienced per shift
- Assignment: Each server works exactly once

COSTS (3 components):
- Labor: rate × hours (varies by shift!)
- Experience penalty: [€800,0,500,1200,600,1000]
- Preferences: (10-pref)×€20 per assignment

ALGORITHM: Implement SA with:
- Neighbor: Swap considering preferences
- Initial temp: 500, cooling: 0.98
- Return: Best schedule + cost
```
:::

::: {.column width="50%"}
**Why This Works:**

✅ **Clear role** sets AI expertise  
✅ **Problem structure** defines scope  
✅ **Hard vs soft** constraints separated  
✅ **Penalties** quantify trade-offs  
✅ **Algorithm specifics** prevent generic code  

**Bad Prompt Example:**
```text
"Make a scheduler with metaheuristics"
```

❌ No problem structure  
❌ No constraints  
❌ No algorithm choice  
❌ AI will produce useless generic code  

[GenAI makes optimization accessible to non-programmers!]{.highlight}
:::
:::

## Debugging Metaheuristics: Strategy

[Essential debugging strategies for complex algorithms:]{.highlight}

```python
#| echo: true
#| eval: false

# CONCEPT: How to Debug Your Metaheuristic
def debug_tips():
    """
    Common problems and solutions
    """
    if solution_not_improving:
        # Problem: Stuck in local optimum
        # Fix: Increase temperature (SA) or mutation (GA)
        
    if all_solutions_look_same:
        # Problem: Lost diversity
        # Fix: Start with more random solutions
        
    if takes_forever:
        # Problem: Too many iterations
        # Fix: Better stopping criteria
        
    # You'll practice debugging in the tutorials!
```

## Real-World Considerations

[Practical issues when deploying metaheuristics:]{.highlight}

::: columns
::: {.column width="50%"}
**Computational Budget**
- Wall-clock time matters
- Memory constraints
- Parallel processing opportunities
- Cloud vs local execution

**Solution Quality Requirements**
- "Good enough" vs optimal
- Consistency vs best possible
- Explainability needs
:::

::: {.column width="50%"}
**Problem Characteristics**
- Static vs dynamic
- Deterministic vs stochastic
- Single vs multi-objective
- Hard vs soft constraints

**Implementation Reality**
- Development time
- Maintenance burden
- Team expertise
- Integration complexity
:::
:::

# [Advanced Topics]{.flow} {.title}

## Hybrid Metaheuristics

[Combining methods for superior performance:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(12, 6))

# Create hybrid approach visualization
methods = ['Greedy\nStart', 'Local\nSearch', 'SA\nEscape', 'GA\nDiversify', 'Final\nSolution']
x_pos = np.arange(len(methods))
costs = [1640, 1520, 1450, 1400, 1380]
colors = [BRAND_COLORS["darker"], BRAND_COLORS["oneLight"], BRAND_COLORS["twoLight"], 
          BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"]]

bars = ax.bar(x_pos, costs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)

# Add arrows between stages
for i in range(len(methods)-1):
    ax.annotate('', xy=(i+1, costs[i+1]+20), xytext=(i+0.2, costs[i]-20),
                arrowprops=dict(arrowstyle='->', lw=2, color='black'))

ax.set_xlabel('Optimization Stage', fontsize=12)
ax.set_ylabel('Solution Cost (€)', fontsize=12)
ax.set_title('Hybrid Approach: Combining Methods', fontsize=14, fontweight='bold')
ax.set_xticks(x_pos)
ax.set_xticklabels(methods)
ax.set_ylim(1300, 1700)

# Add improvement labels
for i in range(1, len(costs)):
    improvement = costs[i-1] - costs[i]
    ax.text(i-0.5, 1650, f'-€{improvement}', ha='center', fontsize=10, 
            color=BRAND_COLORS["twoDark"], fontweight='bold')

plt.tight_layout()
plt.show()
```

[Combine methods sequentially for best results!]{.highlight}

## Parameter Tuning: Basic Strategies

[Start with these proven approaches:]{.highlight}

::: columns
::: {.column width="50%"}
**Grid Search**
```python
temps = [100, 500, 1000, 2000]
coolings = [0.9, 0.95, 0.99]
for T in temps:
    for alpha in coolings:
        run_SA(T, alpha)
```

**Adaptive Parameters**
```python
# Self-adjusting temperature
if no_improvement > 50:
    temperature *= 1.5  # Reheat
```
:::

::: {.column width="50%"}
**Rules of Thumb**
- SA: T₀ ≈ max expected delta
- GA: pop_size ≈ 10 × variables
- Tabu: tenure ≈ √problem_size
- Mutation: 1/chromosome_length

**Performance Metrics**
- Convergence speed
- Solution quality
- Robustness (variance)
- Computational time
:::
:::

## Real-World Case Studies

[How major companies use metaheuristics in production:]{.highlight}

### Case Study 1: Amazon's Last-Mile Delivery

::: columns
::: {.column width="50%"}
**The Problem:**
- 30-40% of delivery trucks returning empty
- Massive fuel waste and emissions
- Complex dynamic routing with time windows

**The Solution (ACO):**
- Digital ants explore route combinations
- Pheromones reinforce efficient paths
- Dynamic adaptation to traffic/delays
:::

::: {.column width="50%"}
**The Results:**
- **27% reduction** in empty miles
- **$43M annual savings** in fuel costs
- **15% faster** average delivery times
- **22% reduction** in CO₂ emissions

[ACO's pheromone trails naturally optimize network paths!]{.highlight}
:::
:::

## Case Study 2: Hospital Nurse Scheduling

[Combining GA and SA for complex staff scheduling:]{.highlight}

```{python}
#| echo: false
#| eval: true

import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Left: Performance comparison
ax = axes[0]
methods = ['Manual', 'Greedy', 'SA', 'GA', 'Hybrid\n(GA+SA)']
satisfaction = [45, 52, 68, 71, 85]  # Employee satisfaction %
coverage = [78, 95, 92, 93, 98]  # Shift coverage %

x = np.arange(len(methods))
width = 0.35

bars1 = ax.bar(x - width/2, satisfaction, width, label='Staff Satisfaction %', 
               color=BRAND_COLORS["oneDark"], alpha=0.8)
bars2 = ax.bar(x + width/2, coverage, width, label='Coverage Quality %',
               color=BRAND_COLORS["twoDark"], alpha=0.8)

ax.set_xlabel('Scheduling Method', fontsize=11)
ax.set_ylabel('Performance (%)', fontsize=11)
ax.set_title('Hospital Scheduling: Method Comparison', fontsize=13, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(methods, fontsize=10)
ax.legend()
ax.grid(axis='y', alpha=0.3)

# Add value labels
for bar in bars1:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.0f}%', ha='center', va='bottom', fontsize=9)
for bar in bars2:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.0f}%', ha='center', va='bottom', fontsize=9)

# Right: Cost breakdown
ax = axes[1]
categories = ['Labor\nCost', 'Overtime\nPenalty', 'Turnover\nCost', 'Total\nSavings']
manual_cost = [100, 100, 100, 0]
optimized_cost = [95, 40, 25, 140]
colors = [BRAND_COLORS["darker"], BRAND_COLORS["threeDark"], BRAND_COLORS["oneDark"], BRAND_COLORS["twoDark"]]

x = np.arange(len(categories))
bars = ax.bar(x, manual_cost, color='lightgray', alpha=0.5, label='Manual')
bars2 = ax.bar(x, optimized_cost, color=colors, alpha=0.8, label='GA+SA')

ax.set_ylabel('Relative Cost (Manual = 100)', fontsize=11)
ax.set_title('Cost Impact of Optimization', fontsize=13, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(categories)
ax.axhline(y=100, color='black', linestyle='--', alpha=0.3)
ax.legend()

plt.tight_layout()
plt.show()
```

**Key Results**: 37% reduction in scheduling time, 25% reduction in violations, 85% staff satisfaction (up from 45%)

## Competition Strategies

[Your roadmap for tackling the complex restaurant problem:]{.highlight}

1. **Understand Complexity**: Study shift hours, penalties, preferences (5 min)
2. **Smart Greedy**: Design preference-aware baseline (10 min)  
3. **Choose Your Weapon**: Pick ONE metaheuristic that handles all 3 costs (15 min)
4. **Fine-tune**: Balance labor vs penalties vs preferences (15 min)
5. **Document Trade-offs**: Explain your strategic choices (5 min)

. . .

::: {.callout-warning}
## Competition Tip
This problem has REAL complexity! Focus on balancing all three cost components rather than perfecting just one.
:::

# [Summary & Resources]{.flow} {.title}

## Key Concepts to Remember

[The essential takeaways from this lecture:]{.highlight}

::: {.incremental}
- **Local Optima**: Simple methods get trapped
- **Acceptance Probability**: P = exp(-Δ/T) enables escape
- **Population Search**: Parallel exploration beats sequential
- **Memory**: Prevents cycling and guides search
- **Hybrid Approaches**: Combine methods for best results
- **AI Tools**: Implementation helpers, not decision makers
:::

## Your Optimization Hierarchy

[When to escalate to more complex methods:]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(10, 8))

# Create pyramid
levels = [
    ('Random', 0, 5, BRAND_COLORS["darker"]),
    ('Greedy', 1, 4, BRAND_COLORS["oneLight"]),
    ('Local Search', 2, 3, BRAND_COLORS["twoLight"]),
    ('Metaheuristics', 3, 2, BRAND_COLORS["oneDark"]),
    ('Exact Methods', 4, 1, BRAND_COLORS["twoDark"])
]

for name, bottom, width, color in levels:
    # Draw trapezoid
    left = (5 - width/2)
    right = (5 + width/2)
    vertices = [(left, bottom), (right, bottom), 
                (right-0.5, bottom+1), (left+0.5, bottom+1)]
    poly = plt.Polygon(vertices, facecolor=color, edgecolor='black', 
                       alpha=0.7, linewidth=2)
    ax.add_patch(poly)
    
    # Add text
    ax.text(5, bottom + 0.5, name, ha='center', va='center', 
            fontsize=12, fontweight='bold', color='white' if name != 'Random' else 'black')

# Add labels
ax.text(1, 0.5, '⚡ FAST', fontsize=10, fontweight='bold', color='green')
ax.text(1, 4.5, '🎯 OPTIMAL', fontsize=10, fontweight='bold', color='red')
ax.text(9, 0.5, '😊 SIMPLE', fontsize=10, fontweight='bold', color='blue')
ax.text(9, 4.5, '🤯 COMPLEX', fontsize=10, fontweight='bold', color='purple')

ax.set_xlim(0, 10)
ax.set_ylim(0, 6)
ax.axis('off')
ax.set_title('Always Start at the Bottom!', fontsize=16, fontweight='bold', pad=20)

plt.tight_layout()
plt.show()
```

## Additional Resources

[Expand your knowledge with these curated resources:]{.highlight}

::: columns
::: {.column width="50%"}
**Learn More:**
- [Essentials of Metaheuristics](https://cs.gmu.edu/~sean/book/metaheuristics/) (free book)
- [Google OR-Tools](https://developers.google.com/optimization)
- [DEAP Python Library](https://deap.readthedocs.io/) for GA
- [SimPy](https://simpy.readthedocs.io/) for simulation

**Practice Problems:**
- Vehicle Routing (VRP)
- Job Shop Scheduling
- Knapsack variants
- Portfolio optimization
:::

::: {.column width="50%"}
**AI Assistant Prompts:**
```text
# Template for any problem:
"I need to solve [problem type] with:
- Variables: [list them]
- Constraints: [list them]  
- Objective: [minimize/maximize what]
- Data: [provide sample]

Implement [specific algorithm] with:
- [Parameter 1]: [value]
- [Parameter 2]: [value]
Please include comments."
```
:::
:::

## Final Thoughts

[The journey from local to global optimization:]{.highlight}

> "All models are wrong, but some are useful" - George Box

. . .

> "Perfect is the enemy of good" - Voltaire

. . .

> "Start where you are. Use what you have. Do what you can." - Arthur Ashe

. . .

[You now have a complete optimization toolkit. Use it wisely!]{.success}

## Break!

[Great work! Time for a well-deserved break!]{.highlight}

```{python}
#| echo: false
#| eval: true

import sys
sys.path.append('../helpers')
from plot_utils import setup_clean_style, BRAND_COLORS

# Apply clean brand style
setup_clean_style()

fig, ax = plt.subplots(figsize=(10, 8))

# Fun visualization of all methods working together
np.random.seed(789)

# Create solution landscape
x = np.linspace(0, 10, 100)
y = 1500 - 100*np.sin(x) - 50*np.sin(3*x) - 30*np.sin(5*x)

ax.fill_between(x, 1200, y, alpha=0.1, color='blue')
ax.plot(x, y, 'b-', linewidth=2, alpha=0.5)

# Show different algorithm paths
# Random jumps
random_x = np.random.uniform(0, 10, 10)
random_y = [1500 - 100*np.sin(xi) - 50*np.sin(3*xi) - 30*np.sin(5*xi) + np.random.randn()*20 
            for xi in random_x]
ax.scatter(random_x, random_y, color='gray', s=30, alpha=0.5, label='Random')

# Greedy path
greedy_x = [2]
greedy_y = [1500 - 100*np.sin(2) - 50*np.sin(6) - 30*np.sin(10)]
ax.scatter(greedy_x, greedy_y, color='orange', s=100, marker='o', label='Greedy')

# Local search
local_x = [3.5]
local_y = [1420]
ax.scatter(local_x, local_y, color='red', s=100, marker='s', label='Local Search')

# SA path
sa_x = np.linspace(3.5, 7.5, 20)
sa_y = [1420 - (xi-3.5)*20 + np.random.randn()*10 for xi in sa_x]
ax.plot(sa_x, sa_y, 'b-', alpha=0.5, linewidth=2, label='SA Path')

# GA population
ga_x = np.random.normal(7.5, 0.5, 10)
ga_y = [1380 + np.random.randn()*5 for _ in ga_x]
ax.scatter(ga_x, ga_y, color='green', s=50, alpha=0.7, label='GA Population')

# Global optimum
ax.scatter([7.5], [1350], color='gold', s=300, marker='*', 
          edgecolor='black', linewidth=2, zorder=10, label='Global Optimum')

ax.set_xlabel('Solution Space', fontsize=12)
ax.set_ylabel('Cost (€)', fontsize=12)
ax.set_title('The Complete Optimization Journey', fontsize=16, fontweight='bold')
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)
ax.set_ylim(1300, 1700)

# Add annotations
ax.annotate('Start', xy=(2, 1600), xytext=(1, 1650),
            arrowprops=dict(arrowstyle='->', color='orange'),
            fontsize=10, color='orange')
ax.annotate('Trapped!', xy=(3.5, 1420), xytext=(2.5, 1350),
            arrowprops=dict(arrowstyle='->', color='red'),
            fontsize=10, color='red')
ax.annotate('Escape!', xy=(5.5, 1400), xytext=(5.5, 1500),
            arrowprops=dict(arrowstyle='->', color='blue'),
            fontsize=10, color='blue')
ax.annotate('Success!', xy=(7.5, 1350), xytext=(8.5, 1450),
            arrowprops=dict(arrowstyle='->', color='gold'),
            fontsize=12, color='gold', fontweight='bold')

plt.tight_layout()
plt.show()
```

[Ready to optimize? Let's tackle the restaurant challenge!]{.flow}
